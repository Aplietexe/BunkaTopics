[{"topic_id": "bt-0", "name": " Defensive Strategies", "lemma_name": null, "term_id": ["Defenses", "Attacks", "Examples", "Anomaly Detection", "security", "anomaly", "robustness", "detection", "Optimal Transport", "Detectors", "box", "ML", "magnets", "resource", "Sense", "Corruption", "detector", "Controllers", "Subspaces", "Regularization", "infty", "examples", "Output", "Fisher", "scoring", "State", "Host", "relevance", "Transformations", "Norm", "Gradient", "GANs", "class", "system", "weights", "Class", "intelligence", "management", "Memory", "feature extraction", "impact", "platform", "Evaluation", "Scale", "Flows", "Augmentation", "DNNs", "Don", "multi", "parameter", "Performance", "Networks", "Rules", "extraction", "context", "distribution", "multivariate", "data", "Guarantees", "Signals", "dataset", "Classifiers", "Thresholding", "PDEs", "classifiers", "CUR", "GAN", "Gradients", "Approach", "Algorithms", "Image", "datasets", "Stochastic", "Systems", "Identification", "survey", "Machine Learning", "Theory", "order", "Transfer", "information", "classification", "End", "task", "applications", "Structure", "scale", "systems", "Methods", "feature", "Decision", "Survey", "model", "Risk", "Features", "Models", "Deep Learning", "training", "methods", "Classification"], "x_centroid": 6.953191894955105, "y_centroid": 0.5379808023182624, "size": 225, "top_doc_id": null, "top_doc_content": ["The model of an anomaly detector for HiLumi LHC magnets based on\n  Recurrent Neural Networks and adaptive quantization", "Subspace Attack: Exploiting Promising Subspaces for Query-Efficient\n  Black-box Attacks", "Obfuscated Gradients Give a False Sense of Security: Circumventing\n  Defenses to Adversarial Examples", "Explainable multi-class anomaly detection on functional data", "Identification of Attack-Specific Signatures in Adversarial Examples", "Copycat CNN: Are Random Non-Labeled Data Enough to Steal Knowledge from\n  Black-box Models?", "Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100", "On the security relevance of weights in deep learning", "Stochastic Combinatorial Ensembles for Defending Against Adversarial\n  Examples", "Online and Distributed Robust Regressions under Adversarial Data\n  Corruption", "Ensemble Adversarial Training: Attacks and Defenses", "Feature Analysis for ML-based IIoT Intrusion Detection", "Hybridization of Capsule and LSTM Networks for unsupervised anomaly\n  detection on multivariate data", "Adversarial Robustness Assessment: Why both $L_0$ and $L_\\infty$ Attacks\n  Are Necessary", "Anomaly detection and classification for streaming data using PDEs", "Fast Feature Reduction in intrusion detection datasets", "An Analisys of Application Logs with Splunk : developing an App for the\n  synthetic analysis of data and security incidents", "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks,\n  and Defenses", "Regularization with Latent Space Virtual Adversarial Training", "Anomaly Detection in Particulate Matter Sensor using Hypothesis Pruning\n  Generative Adversarial Network", "Increasing the adversarial robustness and explainability of capsule\n  networks with $\\gamma$-capsules", "Capture the Bot: Using Adversarial Examples to Improve CAPTCHA\n  Robustness to Bot Attacks", "Host-based anomaly detection using Eigentraces feature extraction and\n  one-class classification on system call trace data", "Robustness to Adversarial Attacks in Learning-Enabled Controllers", "Adversarial Risk via Optimal Transport and Optimal Couplings", "Robust Optimal Classification Trees Against Adversarial Examples", "Anomaly Detection in Multi-Agent Trajectories for Automated Driving", "AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing\n  Flows", "Optimal Transport as a Defense Against Adversarial Attacks", "NBcoded: network attack classifiers based on Encoder and Naive Bayes\n  model for resource limited devices", "Fooling Object Detectors: Adversarial Attacks by Half-Neighbor Masks", "Transferable Clean-Label Poisoning Attacks on Deep Neural Nets", "DPatch: An Adversarial Patch Attack on Object Detectors", "Classification Auto-Encoder based Detector against Diverse Data\n  Poisoning Attacks", "ARMS: Automated rules management system for fraud detection", "Learning Defense Transformers for Counterattacking Adversarial Examples", "Adversarial Attacks and Defenses in Physiological Computing: A\n  Systematic Review", "Adversarial Deep Learning for Over-the-Air Spectrum Poisoning Attacks", "And/or trade-off in artificial neurons: impact on adversarial robustness", "Anomaly Detection using Autoencoders in High Performance Computing\n  Systems", "InFlow: Robust outlier detection utilizing Normalizing Flows"], "top_term_id": null, "convex_hull": {"x_coordinates": [7.417285442352294, 7.339509814291588, 7.249298423584278, 7.150501478549493, 7.0469691875063445, 6.942551758773966, 6.8410994006714745, 6.74646040691996, 6.661137475443116, 6.583931414158632, 6.513011950873824, 6.446548813396032, 6.382989085867883, 6.322987424101214, 6.268253203277178, 6.220502344251939, 6.181450767881655, 6.152814395022487, 6.136309146530595, 6.133650943262136, 6.146555706073277, 6.176315297741863, 6.221854445878122, 6.281276860511795, 6.352685443241874, 6.434183095667356, 6.523849456982886, 6.619596324684971, 6.71926183725769, 6.820683818049436, 6.921836328875188, 7.021557987204805, 7.119025468851772, 7.213416230928392, 7.303907730546954, 7.389677424819758, 7.4699027708590995, 7.543704949946942, 7.605537258944949, 7.6419265960040175, 7.648522993162949, 7.636247870855358, 7.617322241196862, 7.602116805396347, 7.590003032532179, 7.576304126291505, 7.556336989958384, 7.525418526816882, 7.4794362702137365, 7.417285442352293], "y_coordinates": [1.345616817474365, 1.4092472959211426, 1.4583946984414438, 1.4926586312065873, 1.511638700387889, 1.5149345121566684, 1.5021456726842422, 1.4728729062260506, 1.4275027360770565, 1.3685835097715535, 1.2990321120713846, 1.2217654277383965, 1.1395143160751597, 1.053528997648554, 0.9643522829896771, 0.8725225923848631, 0.7785783461204437, 0.683057964482752, 0.5864998677581211, 0.48944247623288306, 0.3924242101933716, 0.29639473713981734, 0.20459934819664147, 0.12107954899237908, 0.04987762916347939, -0.004964121653609495, -0.04012084382999273, -0.0574440416639595, -0.06105691867453525, -0.05509239740184295, -0.043179464750135024, -0.02574918258382677, -0.0019821608896416266, 0.02894388031004764, 0.06785122099286814, 0.11556214113644751, 0.17289892071841262, 0.2406744435958232, 0.318922218100724, 0.4063164205601271, 0.5009458989431519, 0.600206758195599, 0.7014361509894084, 0.8021928767236443, 0.9013533208277558, 0.9982788060307669, 1.092331409780121, 1.182873209523261, 1.2686993545610417, 1.3456168174743648]}}, {"topic_id": "bt-1", "name": " Wasserstein Kernel Regression", "lemma_name": null, "term_id": ["Wasserstein", "kernel", "Regression", "distance", "Hilbert", "Squares", "Unsupervised Learning", "process", "Experts", "compression", "spaces", "Kernel", "Efficient Approximation", "processes", "dimensionality", "Processes", "Kernels", "samples", "dimension", "measure", "concentration", "regression", "Bounds", "latent", "functions", "Rules", "Functions", "multivariate", "inference", "Rates", "Units", "CUR", "information", "shift", "Capacity", "latent dynamics", "computation", "neighborhood", "Comments", "network models", "optimisation", "Consistency", "component analysis", "component", "discrimination", "distances", "regression models", "Linear", "variation", "estimators", "Notes", "PCA", "approximations", "Models", "models", "Approximation", "dimensionality reduction", "mixture", "kernels", "Review", "predictor", "Classes", "Gaussian Processes", "Measure", "Acceleration", "Sketches", "classifier", "programming", "ell", "records", "P", "Distance", "Inverse Problems", "testing", "Implementation", "matrix", "space", "Overview", "calibration", "Benefits", "events", "Solutions", "Introduction", "Inverse", "View", "uncertainty quantification", "vectors", "description", "vector", "Layers", "parameter", "Points", "selection", "data", "Problems", "method", "estimation", "ODEs", "Markov", "Sets", "Manipulation", "Calibration", "distribution", "matrices", "augmentation", "modelling", "dynamics", "Thresholding", "techniques", "Domain", "Loss Functions", "Rate", "error", "Inference", "distributions", "Gradients", "reduction", "quantification", "Modeling", "analysis", "Rank", "sparse", "state", "approximation", "algorithms", "simulations", "Challenges", "datasets", "descent", "Labels", "uncertainty", "resolution", "application", "Identification", "order", "gradient", "optimization", "network", "Neural Networks", "noise", "identification", "Optimization", "Applications", "view", "Datasets", "Machine", "methods", "function", "Generalization", "performance", "applications", "model", "classification", "loss", "systems"], "x_centroid": 5.864618154441786, "y_centroid": 6.331825877135655, "size": 318, "top_doc_id": null, "top_doc_content": ["DeepParticle: learning invariant measure by a deep neural network\n  minimizing Wasserstein distance on data generated from an interacting\n  particle method", "Reproducing kernel Hilbert spaces on manifolds: Sobolev and Diffusion\n  spaces", "Optimal Rates for Spectral Algorithms with Least-Squares Regression over\n  Hilbert Spaces", "Controlling Wasserstein distances by Kernel norms with application to\n  Compressive Statistical Learning", "Schema matching using Gaussian mixture models with Wasserstein distance", "Structured Bayesian Gaussian process latent variable model: applications\n  to data-driven dimensionality reduction and high-dimensional inversion", "Metric on random dynamical systems with vector-valued reproducing kernel\n  Hilbert spaces", "A gradient-based variable selection for binary classification in\n  reproducing kernel Hilbert space", "On efficient algorithms for computing near-best polynomial\n  approximations to high-dimensional, Hilbert-valued functions from limited\n  samples", "Local moment matching: A unified methodology for symmetric functional\n  estimation and distribution estimation under Wasserstein distance", "Local intrinsic dimensionality estimators based on concentration of\n  measure", "Deterministic error bounds for kernel-based learning techniques under\n  bounded noise", "Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models", "Unsupervised Learning by Competing Hidden Units", "Complex-Valued Gaussian Processes for Regression", "On the Vapnik-Chervonenkis dimension of products of intervals in\n  $\\mathbb{R}^d$", "Efficient Approximation of Gromov-Wasserstein Distance using Importance Sparsification", "Exact Sampling from Determinantal Point Processes", "KSM: Fast Multiple Task Adaption via Kernel-wise Soft Mask Learning", "Sparse Gaussian Processes via Parametric Families of Compactly-supported\n  Kernels", "Variational multiple shooting for Bayesian ODEs with Gaussian processes", "Kernel and Rich Regimes in Overparametrized Models", "Pluralistic Image Completion with Probabilistic Mixture-of-Experts", "Lossless compression with state space models using bits back coding", "Lossy compression of matrices by black-box optimisation of mixed-integer\n  non-linear programming", "Unsupervised Learning through Temporal Smoothing and Entropy\n  Maximization", "Scalable GAM using sparse variational Gaussian processes", "Kronecker Determinantal Point Processes", "Efficient Non-parametric Bayesian Hawkes Processes", "On learning parametric distributions from quantized samples", "On statistical learning via the lens of compression", "A hidden process regression model for functional data description.\n  Application to curve discrimination", "Dropout Regularization in Hierarchical Mixture of Experts", "Rectified Gaussian Scale Mixtures and the Sparse Non-Negative Least\n  Squares Problem", "On Coresets for Logistic Regression", "Batch simulations and uncertainty quantification in Gaussian process\n  surrogate approximate Bayesian computation", "Variable selection for Gaussian process regression through a sparse\n  projection", "Biomechanical surrogate modelling using stabilized vectorial greedy\n  kernel methods", "Composite Goodness-of-fit Tests with Kernels", "Equivalence of distance-based and RKHS-based statistics in hypothesis\n  testing", "Mixed neural network Gaussian processes", "Stochastic Low-Rank Kernel Learning for Regression", "Estimating the intrinsic dimension of datasets by a minimal neighborhood\n  information", "Speeding up the binary Gaussian process classification", "Wasserstein-based Projections with Applications to Inverse Problems", "Robust Regression via Hard Thresholding", "Sparse Linear Regression via Generalized Orthogonal Least-Squares", "Principled learning method for Wasserstein distributionally robust\n  optimization with local perturbations", "Conditional Contrastive Learning with Kernel", "Unsupervised Learning with Truncated Gaussian Graphical Models", "On Coresets For Regularized Regression", "Robust Elastic Net Regression", "Collapsing of dimensionality", "Greedy Block Coordinate Descent for Large Scale Gaussian Process\n  Regression", "On the Representation Collapse of Sparse Mixture of Experts", "Efficient Approximation of Expected Hypervolume Improvement using\n  Gauss-Hermite Quadrature", "Factorized Structured Regression for Large-Scale Varying Coefficient\n  Models", "Robust SVM Optimization in Banach spaces"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.4627480506897, 6.391541340811859, 6.305160479250767, 6.207918496864886, 6.104128424512675, 5.998103293052596, 5.894156133343109, 5.796599976242675, 5.710244310601617, 5.64196617955777, 5.586238091140351, 5.534734783643968, 5.48243636613108, 5.4264700814358156, 5.363999621320863, 5.292193271379839, 5.211010707450525, 5.127935510483614, 5.051706166396382, 4.991061161106097, 4.9547389805300295, 4.951478110585452, 4.986527742387732, 5.0505251467561285, 5.131567665188757, 5.224322002574642, 5.325549730552872, 5.432013323256049, 5.54047525481677, 5.647697999367638, 5.7505027029416995, 5.849710304941211, 5.95263407065551, 6.067038511782046, 6.1750155086181, 6.256311051345398, 6.34235413454433, 6.418480769461624, 6.461419126266505, 6.486908009065263, 6.518746967382958, 6.560750636019674, 6.6021238178361665, 6.6317376424841, 6.638463239615139, 6.617337925691962, 6.587731995625157, 6.555879939068764, 6.516154208914201, 6.462748050689699], "y_coordinates": [7.031037330627443, 7.151637455584597, 7.272792098407638, 7.385159822775829, 7.479399192368423, 7.546168770864685, 7.576127121943871, 7.559932809285241, 7.4909705357169685, 7.3971606749508725, 7.2950610658471255, 7.1921438807044105, 7.0911285117090825, 6.991646995526637, 6.893278959046217, 6.795603930407144, 6.69814143352281, 6.600249257091236, 6.50125821414794, 6.400499117728441, 6.297302780868257, 6.191000016602907, 6.082824301541263, 5.981976787728765, 5.897746234209632, 5.829203149106815, 5.7721596050995005, 5.722426271094129, 5.675813815997142, 5.628132908714977, 5.575268857806249, 5.518195322190865, 5.466145194635032, 5.429295556410268, 5.451075597464064, 5.536508368517118, 5.614649254553694, 5.701011229264337, 5.805453467177953, 5.920753952788895, 6.036148061547672, 6.148095615841974, 6.258337819394319, 6.368736497127097, 6.481153473962695, 6.595014880225808, 6.704369598222632, 6.810611912057143, 6.91805135141484, 7.031037330627442]}}, {"topic_id": "bt-10", "name": " Network PDEs & Flows", "lemma_name": null, "term_id": ["networks", "PDEs", "Flows", "transport", "equations", "layer", "sampling", "Ratio", "convolution", "solution", "ReLU", "Functions", "ODEs", "Point", "weights", "Geometry", "Neural Networks", "sparsity", "Distribution", "flows", "topology", "differentiation", "approximation", "problems", "training", "generalization", "Structure", "convergence", "Error", "Depth", "method", "Representations", "Units", "Separation", "Autoencoders", "Langevin", "autoencoder", "resonance", "latent dynamics", "segment", "grid", "Phase", "basis", "opportunities", "points", "neighborhood", "changes", "recipe", "chaos", "Categories", "parameters", "Manifolds", "parameterization", "Remedies", "variants", "guarantees", "Sketching", "field", "speech recognition", "PPO", "function approximation", "Fisher", "law", "NP", "learning algorithms", "Transformations", "approximations", "Functionals", "activation function", "Forests", "implications", "function", "Generalization", "Gradients", "physics", "Data", "sparse", "representations", "datasets", "descent", "types", "Convolutions", "Gaussian Processes", "Sampling", "difference", "entropy", "Terms", "Sparse", "programming", "stochastic gradient", "Priors", "Workloads", "Time", "regularization", "computing", "bounds", "Perception", "operator", "rate", "rank", "RNNs", "memory", "concentration", "Networks", "learning", "stochastic", "space", "representation", "inference", "Modeling", "calibration", "Benefits", "activation", "Impact", "latent", "signal", "Solutions", "source", "sample", "fields", "Introduction", "norm", "Analysis", "encoder", "Modelling", "type", "discovery", "Layers", "network", "Features", "Sets", "constraints", "distribution", "matrices", "feedback", "software", "inverse problems", "modelling", "brain", "series", "Signals", "Losses", "Tasks", "recovery", "complexity", "processing", "Policy", "methods", "Convergence", "error", "Search", "Physics", "channel", "learning approach", "approaches", "graph", "Guarantees", "state", "theory", "algorithms", "inverse", "process", "Self", "modeling", "Case", "level", "CUR", "Labels", "functions", "Identification", "survey", "machine learning", "Theory", "problem", "order", "Transfer", "gradient", "framework", "Optimization", "Constraints", "Evaluation", "regression", "view", "recognition", "Training", "optimization", "information", "selection", "time series", "Study", "speech", "performance"], "x_centroid": 5.125214801437553, "y_centroid": 5.068918584407061, "size": 348, "top_doc_id": null, "top_doc_content": ["Learning the solution operator of parametric partial differential\n  equations with physics-informed DeepOnets", "A semigroup method for high dimensional elliptic PDEs and eigenvalue\n  problems based on neural networks", "Error bounds for deep ReLU networks using the Kolmogorov--Arnold\n  superposition theorem", "On the stable recovery of deep structured linear networks under sparsity\n  constraints", "Optimal transport weights for causal inference", "A priori generalization error for two-layer ReLU neural network through\n  minimum norm solution", "Recovery Guarantees for One-hidden-layer Neural Networks", "Sparsely constrained neural networks for model discovery of PDEs", "Universality and approximation bounds for echo state networks with\n  random weights", "Error bounds for approximations with deep ReLU neural networks in\n  $W^{s,p}$ norms", "PAGP: A physics-assisted Gaussian process framework with active learning\n  for forward and inverse problems of partial differential equations", "Robust normalizing flows using Bernstein-type polynomials", "Local minima in training of neural networks", "Oil Spill SAR Image Segmentation via Probability Distribution Modelling", "Robust Classification using Hidden Markov Models and Mixtures of\n  Normalizing Flows", "Adaptive Block Floating-Point for Analog Deep Learning Hardware", "You May Not Need Ratio Clipping in PPO", "Deformed semicircle law and concentration of nonlinear random matrices\n  for ultra-wide neural networks", "Structured (De)composable Representations Trained with Neural Networks", "Theoretical guarantees for sampling and inference in generative models\n  with latent diffusions", "Generating Neural Networks with Neural Networks", "New pointwise convolution in Deep Neural Networks through Extremely Fast\n  and Non Parametric Transforms", "Deep least-squares methods: an unsupervised learning-based numerical\n  method for solving elliptic PDEs", "Rodent: Relevance determination in differential equations", "1-Dimensional polynomial neural networks for audio signal related\n  problems", "Latent Variable Modelling with Hyperbolic Normalizing Flows", "Explainable nonlinear modelling of multiple time series with invertible\n  neural networks", "Overcoming Challenges in Fixed Point Training of Deep Convolutional\n  Networks", "Universal Function Approximation by Deep Neural Nets with Bounded Width\n  and ReLU Activations", "Flatten-T Swish: a thresholded ReLU-Swish-like activation function for\n  deep learning", "CENN: Conservative energy method based on neural networks with\n  subdomains for solving variational problems involving heterogeneous and\n  complex geometries", "A Max-Sum algorithm for training discrete neural networks", "A unified view of generative models for networks: models, methods,\n  opportunities, and challenges", "Doing the impossible: Why neural networks can be trained at all", "Pathological spectra of the Fisher information metric and its variants\n  in deep neural networks", "Iterative training of neural networks for intra prediction", "On the complexity of the optimal transport problem with graph-structured\n  cost", "Sparse approximation in learning via neural ODEs", "ErfAct and Pserf: Non-monotonic Smooth Trainable Activation Functions", "Stable Neural Flows", "Log-Likelihood Ratio Minimizing Flows: Towards Robust and Quantifiable\n  Neural Distribution Alignment", "Revise Saturated Activation Functions", "Deep learning and differential equations for modeling changes in\n  individual-level latent dynamics between observation periods", "Critical Point-Finding Methods Reveal Gradient-Flat Regions of Deep\n  Network Losses", "Solving the functional Eigen-Problem using Neural Networks", "Post-training deep neural network pruning via layer-wise calibration", "A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical Representation Learning", "Transfer entropy-based feedback improves performance in artificial\n  neural networks", "Accelerated replica exchange stochastic gradient Langevin diffusion\n  enhanced Bayesian DeepONet for solving noisy parametric PDEs", "Convolutional Normalizing Flows", "Factored couplings in multi-marginal optimal transport via difference of\n  convex programming", "Geometry of the Loss Landscape in Overparameterized Neural Networks:\n  Symmetries and Invariances", "Ensembled sparse-input hierarchical networks for high-dimensional\n  datasets", "Relaxing Bijectivity Constraints with Continuously Indexed Normalising\n  Flows", "6DCNN with roto-translational convolution filters for volumetric data\n  processing", "Structure-preserving neural networks", "Optimal Fine-Grained N:M sparsity for Activations and Neural Gradients", "LogitBoost autoregressive networks", "Stochastic gradient descent performs variational inference, converges to\n  limit cycles for deep networks", "Geometry of Optimization and Implicit Regularization in Deep Learning", "Complexity for deep neural networks and other characteristics of deep\n  feature representations", "Asymptotic convergence rate of Dropout on shallow linear neural networks", "On Robust Classification using Contractive Hamiltonian Neural ODEs", "Stochastic resonance neurons in artificial neural networks", "Convergence of gradient descent for deep neural networks", "Most Activation Functions Can Win the Lottery Without Excessive Depth", "Making transport more robust and interpretable by moving data through a\n  small number of anchor points", "Multi-segment preserving sampling for deep manifold sampler", "Towards Data-driven LQR with Koopmanizing Flows", "Realization Theory Of Recurrent Neural ODEs Using Polynomial System Embeddings", "Learning emergent PDEs in a learned emergent space", "Continuous normalizing flows on manifolds", "GrADE: A graph based data-driven solver for time-dependent nonlinear\n  partial differential equations", "Hierarchical regularization networks for sparsification based learning\n  on noisy datasets", "Operator Inference and Physics-Informed Learning of Low-Dimensional\n  Models for Incompressible Flows"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.134860038757324, 4.201699657839174, 4.295750309500495, 4.391447104135001, 4.479815935644702, 4.562960278449282, 4.643185780130098, 4.722798088268507, 4.80410285044586, 4.88940571424351, 4.9810123272428095, 5.081116122731364, 5.188583599494177, 5.298478070568577, 5.406025909891413, 5.508494918281329, 5.601153982869711, 5.672295880646341, 5.732630972326402, 5.783502422003114, 5.821924145601306, 5.872713913971651, 5.932226831757133, 5.980387492251918, 5.996973552880307, 5.961928569935787, 5.875801984888779, 5.778005871701598, 5.686809776405329, 5.598235818343396, 5.5077528613328335, 5.413510538449409, 5.315755260703693, 5.214789323588328, 5.110915022595965, 5.00443458455795, 4.895643898342336, 4.784801623206991, 4.671897296688153, 4.561844032445608, 4.454173641993888, 4.358959569655874, 4.301724161042393, 4.268422372219177, 4.241261538529188, 4.209673932827786, 4.169236852201905, 4.1319611332112265, 4.114838062686838, 4.134860038757323], "y_coordinates": [4.9754910469055185, 4.896586315856718, 4.824282659976959, 4.742982667752423, 4.650171383566875, 4.55206894008378, 4.455054891097608, 4.3655087904028305, 4.2898101917939195, 4.234338649065344, 4.205473716011575, 4.209222884706044, 4.240562744335731, 4.281859905559642, 4.319217033851656, 4.3630987301270245, 4.428032305854733, 4.514650958570879, 4.6104358522014754, 4.708922256101728, 4.814054696475746, 4.926406544510774, 5.042049010879402, 5.154829740277491, 5.25857649234718, 5.347162603109414, 5.420122337036884, 5.487685680609963, 5.554617431502234, 5.619866237844191, 5.682227777900146, 5.741070851620425, 5.796212529130497, 5.847481828099805, 5.8947077661977945, 5.937637288886275, 5.968441448690751, 5.968515817309873, 5.955996143892654, 5.937284422178865, 5.898760813424896, 5.846020300773814, 5.751154432555345, 5.636581804565406, 5.526716350241849, 5.419118721413032, 5.304015163803966, 5.1858598986084266, 5.073426885220428, 4.975491046905517]}}, {"topic_id": "bt-11", "name": " Reinforcement Learning", "lemma_name": null, "term_id": ["reinforcement", "reinforcement learning", "Reinforcement Learning", "agent", "Policy", "Manipulation", "robot", "Robots", "Rewards", "soccer", "Experience", "Abstraction", "UAVs", "actions", "vehicle", "Cost", "Exploration", "control", "Dynamics", "Demonstrations", "Agents", "policies", "Humans", "learning", "reward", "Experiments", "games", "Signals", "Separation", "Baseline", "States", "Autoencoders", "Curriculum Learning", "Critics", "competition", "semantics", "opportunities", "Corruption", "optics", "region", "placement", "conditions", "Vulnerability", "trajectory", "robotics", "scoring", "Trajectory", "scheduling", "Goals", "Shot", "Occlusion", "policy", "case", "Environments", "Programming", "Sampling", "entropy", "tuning", "Sparse", "environments", "feature extraction", "Sensing", "POMDPs", "Alternative", "representation learning", "tasks", "Lessons", "Teaching", "value", "Perception", "Trust", "Synthesis", "results", "Strategies", "signal", "Sequence", "self", "View", "optimization", "Performance", "Tuning", "extraction", "comparison", "Communication", "Error", "Uncertainty", "Approach", "Processes", "Tasks", "evaluation", "Convergence", "Survey", "Errors", "state", "approximation", "transfer", "Self", "design", "Challenges", "Risk", "Stochastic", "uncertainty", "Information", "Systems", "Web", "Problems", "Theory", "problem", "Transfer", "Making", "representation", "approach", "Attention", "Evaluation", "function", "Scale", "Study", "problems", "Transformers", "scale", "Methods", "feature", "Application", "Data", "Guarantees", "Decision"], "x_centroid": 9.52028520008516, "y_centroid": 3.946670555504116, "size": 338, "top_doc_id": null, "top_doc_content": ["Towards optimized actions in critical situations of soccer games with\n  deep reinforcement learning", "Towards on-sky adaptive optics control using reinforcement learning", "Definition and evaluation of model-free coordination of electrical\n  vehicle charging with reinforcement learning", "Continuous control with deep reinforcement learning", "Scalable trust-region method for deep reinforcement learning using\n  Kronecker-factored approximation", "User profile-driven large-scale multi-agent learning from demonstration\n  in federated human-robot collaborative environments", "Simulating multi-exit evacuation using deep reinforcement learning", "Driving Policy Transfer via Modularity and Abstraction", "Reinforcement Learning for Linear Quadratic Control is Vulnerable Under\n  Cost Manipulation", "Reinforcement learning reward function in unmanned aerial vehicle\n  control tasks", "Learning for Multi-robot Cooperation in Partially Observable Stochastic\n  Environments with Macro-actions", "Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems", "Angrier Birds: Bayesian reinforcement learning", "Lyapunov-based uncertainty-aware safe reinforcement learning", "Corruption-robust exploration in episodic reinforcement learning", "From self-tuning regulators to reinforcement learning and back again", "Cooperative Multi-Agent Reinforcement Learning with Hypergraph\n  Convolution", "Learning Self-Correctable Policies and Value Functions from\n  Demonstrations with Negative Sampling", "Traffic signal control optimization under severe incident conditions\n  using Genetic Algorithm", "PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable\n  Physics", "Unsupervised Feature Learning for Manipulation with Contrastive Domain\n  Randomization", "Provably Safe Model-Based Meta Reinforcement Learning: An\n  Abstraction-Based Approach", "Policy Learning for Malaria Control", "Model-based Reinforcement Learning for Continuous Control with Posterior\n  Sampling", "Remember and Forget Experience Replay for Multi-Agent Reinforcement\n  Learning", "Self learning robot using real-time neural networks", "Preference-Based Learning for User-Guided HZD Gait Generation on Bipedal\n  Walking Robots", "Locally Persistent Exploration in Continuous Control Tasks with Sparse\n  Rewards", "Jamming-Resilient Path Planning for Multiple UAVs via Deep Reinforcement\n  Learning", "Solving reward-collecting problems with UAVs: a comparison of online\n  optimization and Q-learning", "Exploration in Deep Reinforcement Learning: A Survey", "Reinforcement Learning with Perturbed Rewards", "Provable RL with Exogenous Distractors via Multistep Inverse Dynamics", "Data-driven Actuator Selection for Artificial Muscle-Powered Robots", "Evolution Gym: A Large-Scale Benchmark for Evolving Soft Robots", "Experience-Embedded Visual Foresight", "Evaluation of creating scoring opportunities for teammates in soccer via trajectory prediction", "Dynamics-Aware Comparison of Learned Reward Functions", "Exploration in Action Space", "Boosting Trust Region Policy Optimization by Normalizing Flows Policy", "Planning from Images with Deep Latent Gaussian Process Dynamics", "Learning Multi-agent Communication under Limited-bandwidth Restriction\n  for Internet Packet Routing", "Sample-Efficient Reinforcement Learning with loglog(T) Switching Cost", "Provably Efficient Q-Learning with Low Switching Cost", "Self-Imitation Learning for Robot Tasks with Sparse and Delayed Rewards", "On learning agent-based models from data", "Scalable sim-to-real transfer of soft robot designs", "Applying Policy Iteration for Training Recurrent Neural Networks", "Disturbing Reinforcement Learning Agents with Corrupted Rewards", "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement\n  Learning", "QVMix and QVMix-Max: Extending the Deep Quality-Value Family of\n  Algorithms to Cooperative Multi-Agent Reinforcement Learning", "Negative Update Intervals in Deep Multi-Agent Reinforcement Learning", "Energy-aware optimization of UAV base stations placement via\n  decentralized multi-agent Q-learning", "Curious Exploration via Structured World Models Yields Zero-Shot Object Manipulation", "Learning to reinforcement learn", "Distributed Cooperative Multi-Agent Reinforcement Learning with Directed\n  Coordination Graph", "Reinforcement Learning with Non-uniform State Representations for\n  Adaptive Search", "CTRMs: Learning to Construct Cooperative Timed Roadmaps for Multi-agent\n  Path Planning in Continuous Spaces", "Gaze-Informed Multi-Objective Imitation Learning from Human\n  Demonstrations"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.614712715148928, 8.56605381290325, 8.536089937279534, 8.52407477428489, 8.529262009926416, 8.550905330211231, 8.588258421146442, 8.640574968739156, 8.707108658996482, 8.787164289576856, 8.880772459577397, 8.986146589839677, 9.09891032428698, 9.214563593323913, 9.32860632735509, 9.43653845678512, 9.533975175815721, 9.620483692897547, 9.70047844342257, 9.778670512255436, 9.859770984260802, 9.948490944303312, 10.048871891792691, 10.156737327747484, 10.262395152727136, 10.35605124622417, 10.427911487731118, 10.4681817567405, 10.469139456198805, 10.436258929922502, 10.38019323593409, 10.311607660992125, 10.241136956640629, 10.17434221117455, 10.106085042477503, 10.02987089438776, 9.9393463620412, 9.833426096823164, 9.717743963955687, 9.598370608158758, 9.481358426621949, 9.370294734432996, 9.263834356826592, 9.160079290151824, 9.057256481997964, 8.954944266964507, 8.856007672085624, 8.763812672128994, 8.68190192154022, 8.614712715148928], "y_coordinates": [4.127395153045656, 4.022678157705212, 3.9079350042811063, 3.7869702339186673, 3.6635883877632245, 3.5415940069601115, 3.4247916326546566, 3.3169858059921924, 3.2219810681180485, 3.143078609664266, 3.075741033907904, 3.0159394498961793, 2.96688700473219, 2.9321491857053528, 2.915291480105087, 2.919879375220812, 2.9493545279788456, 3.0029128618516574, 3.0745428207109415, 3.157914151553617, 3.2466966013766054, 3.3345599171768243, 3.4156297424890036, 3.489627058958486, 3.5600282212524337, 3.6303790464954973, 3.704225351812326, 3.785112954327568, 3.875936123934117, 3.975438354305044, 4.080734300734329, 4.188934772264973, 4.297142766366125, 4.401163326791199, 4.494064339406871, 4.568566751180859, 4.617548663250022, 4.639753493023727, 4.641405655149927, 4.629215863164745, 4.609868114329513, 4.586437270352035, 4.554776692169354, 4.512190833809108, 4.464066586045302, 4.4145143270791225, 4.3600880932091135, 4.296190205924815, 4.2188636126524335, 4.127395153045656]}}, {"topic_id": "bt-12", "name": " Network Graphs", "lemma_name": null, "term_id": ["Graphs", "graph", "graphs", "Networks", "Node Classification", "reservoir", "Graph Networks", "descriptors", "protein", "Molecules", "Smooth Signals", "Structure", "Message", "Convolutional Networks", "representations", "structure", "block", "interaction", "Analysis", "networks", "Graph", "attention", "labels", "factor", "k", "RNA", "transformer", "computation", "chemical", "Score", "algorithm", "PCA", "water", "relationship", "MLPs", "NP", "Tracking", "Sequences", "labeling", "properties", "Prediction", "theory", "application", "Interactions", "Transformer", "mixture", "power", "gene", "Gaussian Processes", "Sampling", "Directions", "material", "Traces", "Sparse", "Framework", "market", "Stability", "data analysis", "disease", "Insights", "efficiency", "confidence", "structures", "Trust", "RNN", "platform", "memory", "plasticity", "Network", "level", "CUR", "network", "Enhancement", "path", "Sequence", "Optimal Transport", "edge", "compression", "Correlation", "stage", "norm", "encoder", "analysis", "task", "Training", "Clustering", "Transformers", "estimation", "Embeddings", "matrices", "multivariate", "assessment", "dynamics", "Tasks", "recovery", "Trees", "complexity", "Design", "Classification", "term", "Inference", "clustering", "Events", "Gradients", "reduction", "approaches", "Modeling", "classification", "detection", "Errors", "Processing", "inverse", "Learning", "design", "embeddings", "Image", "Challenges", "modeling", "features", "Feature", "Web", "equations", "survey", "Theory", "problem", "order", "space", "Strategies", "method", "training", "Approach", "Neural Networks", "identification", "Applications", "Constraints", "label", "Depth", "time", "CNNs", "information", "selection", "Machine", "time series", "Machine Learning", "methods", "Scale", "Study", "problems", "Generation", "Performance", "series", "images", "loss", "3D"], "x_centroid": 3.2271222619727107, "y_centroid": 5.645953357809841, "size": 303, "top_doc_id": null, "top_doc_content": ["Sequence-guided protein structure determination using graph\n  convolutional and recurrent networks", "Enhancing the functional content of protein interaction networks", "Joint embedding of structure and features via graph convolutional\n  networks", "The expressive power of kth-order invariant graph networks", "From block-Toeplitz matrices to differential equations on graphs:\n  towards a general theory for scalable masked Transformers", "LPGNet: Link Private Graph Networks for Node Classification", "Oil reservoir recovery factor assessment using Bayesian networks based\n  on advanced approaches to analogues clustering", "Polyp-artifact relationship analysis using graph inductive learned\n  representations", "A Bayesian Model of node interaction in networks", "Powerful, transferable representations for molecules through intelligent\n  task selection in deep multitask networks", "Predicting thermoelectric properties from crystal graphs and material\n  descriptors - first application for functional materials", "Community detection in networks using graph embeddings", "Classification of signaling proteins based on molecular star graph\n  descriptors using Machine Learning models", "Higher-Order Relations Skew Link Prediction in Graphs", "A Preference Random Walk Algorithm for Link Prediction through Mutual\n  Influence Nodes in Complex Networks", "Lattice-based Improvements for Voice Triggering Using Graph Neural\n  Networks", "Collaborative likelihood-ratio estimation over graphs", "Understanding over-squashing and bottlenecks on graphs via curvature", "SMILES Enumeration as Data Augmentation for Neural Network Modeling of\n  Molecules", "Academic Performance Estimation with Attention-based Graph Convolutional\n  Networks", "Proving the NP-completeness of optimal moral graph triangulation", "Processing of incomplete images by (graph) convolutional neural networks", "Heterogeneous Graph Matching Networks", "Data Considerations in Graph Representation Learning for Supply Chain\n  Networks", "Efficient Proximal Mapping of the 1-path-norm of Shallow Networks", "Block Dense Weighted Networks with Augmented Degree Correction", "Stochastic complexity of Bayesian networks", "Network Vector: Distributed Representations of Networks with Global\n  Context", "Heterogeneous Data Fusion Considering Spatial Correlations using Graph\n  Convolutional Networks and its Application in Air Quality Prediction", "Graph Learning Network: A Structure Learning Algorithm", "Spatiotemporal data analysis with chronological networks", "Popularity Adjusted Block Models are Generalized Random Dot Product\n  Graphs", "Inductive Representation Learning in Large Attributed Graphs", "An Empirical Study on Budget-Aware Online Kernel Algorithms for Streams\n  of Graphs", "KCoreMotif: An Efficient Graph Clustering Algorithm for Large Networks\n  by Exploiting k-core Decomposition and Motifs", "p2pGNN: A Decentralized Graph Neural Network for Node Classification in\n  Peer-to-Peer Networks", "SELFIES and the future of molecular string representations", "Constraint-based graph network simulator", "Solve routing problems with a residual edge-graph attention neural\n  network", "Federated Learning for Cross-block Oil-water Layer Identification", "Large Scale Graph Learning from Smooth Signals", "Neighborhood-Based Label Propagation in Large Protein Graphs", "Triangular Contrastive Learning on Molecular Graphs", "Structure learning for CTBN's via penalized maximum likelihood methods", "Adaptive Neural Message Passing for Inductive Learning on Hypergraphs", "Analysis of Hydrological and Suspended Sediment Events from Mad River\n  Watershed using Multivariate Time Series Clustering", "Symmetrization for Embedding Directed Graphs", "Analysis of Gene Interaction Graphs as Prior Knowledge for Machine\n  Learning Models", "Message Passing Networks for Molecules with Tetrahedral Chirality", "An analytic theory of shallow networks dynamics for hinge loss\n  classification", "Graph Decipher: A transparent dual-attention graph neural network to\n  understand the message-passing mechanism for the node classification", "A Generalization of Transformer Networks to Graphs", "Machine Learning for Scent: Learning Generalizable Perceptual\n  Representations of Small Molecules", "Learning to Route in Similarity Graphs", "Semi-Supervised Classification for oil reservoir", "Persona2vec: A Flexible Multi-role Representations Learning Framework\n  for Graphs", "Label-Enhanced Graph Neural Network for Semi-supervised Node Classification", "motif2vec: Motif Aware Node Representation Learning for Heterogeneous\n  Networks", "Relational Fusion Networks: Graph Convolutional Networks for Road\n  Networks", "Accelerated Graph Learning from Smooth Signals", "Structure Learning for Directed Trees", "ParaVS: A Simple, Fast, Efficient and Flexible Graph Neural Network\n  Framework for Structure-Based Virtual Screening", "Graph Networks with Spectral Message Passing", "Link Prediction with Mutual Attention for Text-Attributed Networks", "Low congestion online routing and an improved mistake bound for online\n  prediction of graph labeling", "Structure Learning of $H$-colorings", "A New Space for Comparing Graphs", "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric\n  graphs", "Domain-Aware Dynamic Networks", "Spectral embedding of weighted graphs", "Open Graph Benchmark: Datasets for Machine Learning on Graphs", "Convolutional Networks with Adaptive Inference Graphs", "Dynamic Stacked Generalization for Node Classification on Networks", "Meta-Active Learning for Node Response Prediction in Graphs", "Parameterized Correlation Clustering in Hypergraphs and Bipartite Graphs", "DeepBundle: Fiber Bundle Parcellation with Graph Convolution Neural\n  Networks", "Robustness modularity in complex networks", "Message Passing in Graph Convolution Networks via Adaptive Filter Banks", "Network Clustering by Embedding of Attribute-augmented Graphs", "Multilateration of Random Networks with Community Structure"], "top_term_id": null, "convex_hull": {"x_coordinates": [2.943821907043456, 3.0601781800415417, 3.180644726769018, 3.3030372108082204, 3.4251712957414813, 3.544862645151134, 3.6599269226195155, 3.768179791728957, 3.867436916061792, 3.9555139592003563, 4.0302269200744485, 4.090571572588913, 4.1393688922616825, 4.180213738067339, 4.2167009765979, 4.252718879946204, 4.291593531796022, 4.309680589318576, 4.273725324357349, 4.193146487058245, 4.086486208447248, 3.972286619550338, 3.867437475985028, 3.7676128132729305, 3.654951503034577, 3.525863635867498, 3.3866375763762533, 3.24374933251201, 3.1036749122259404, 2.9728903234692114, 2.857871574192995, 2.7650946723484604, 2.700977730829884, 2.6603560441349368, 2.6280951170934155, 2.6035341593751005, 2.586863080761865, 2.5781509989747193, 2.5761930290636443, 2.5790202281471974, 2.5846532839309417, 2.5911128841204443, 2.596419716421268, 2.59859446853898, 2.5956578281791427, 2.594990986069614, 2.640698730444033, 2.7323090151089513, 2.833777061820315, 2.943821907043456], "y_coordinates": [4.538646697998047, 4.5124141179106205, 4.509695773226257, 4.528253176092111, 4.565847838655331, 4.620241273063069, 4.689194991462478, 4.7704705060007075, 4.861829328824908, 4.961032972082235, 5.0658430257696985, 5.174294960949257, 5.285312257255312, 5.397998048942624, 5.511455496649517, 5.6258039938193845, 5.744262383262484, 5.860726789118478, 5.964116048769138, 6.0546208510520865, 6.134857263146897, 6.207441352233138, 6.274956577179772, 6.339567721543098, 6.402857639589609, 6.462770700267302, 6.514787757720829, 6.554342870251577, 6.576870096160936, 6.577803493750294, 6.552577121321043, 6.496625037174571, 6.40545763137015, 6.289793709497637, 6.171935144194147, 6.053473476028271, 5.934802504193845, 5.81627470889052, 5.697806775874386, 5.579054031794018, 5.4596682562625904, 5.339301228893289, 5.217604729299288, 5.09423053709377, 4.968830431889912, 4.84441497738667, 4.737433321738603, 4.655413900146712, 4.588732317245574, 4.538646697998048]}}, {"topic_id": "bt-13", "name": " 3D Object Face Recognition", "lemma_name": null, "term_id": ["3D", "object", "face", "GAN", "shot learning", "GANs", "Style Transfer", "StyleGAN", "Matching", "glaucoma", "CNNs", "shot", "image", "CycleGAN", "image classification", "LiDAR", "Depth", "events", "Detectors", "multi", "images", "Teacher", "Translation", "Point", "Generation", "benchmark", "benchmarking", "Meshes", "electron", "segment", "point", "region", "Student", "loop", "pixel", "Categories", "Score", "Domains", "aggregation", "ultrasound", "fusion", "2D", "screening", "relevance", "attentive", "art", "age", "Images", "generation", "classification", "detection", "Estimation", "Image", "features", "segmentation", "Information", "resolution", "Interactions", "Classes", "quality", "tuning", "verification", "Sensors", "Auto", "Quantization", "Nets", "Distributions", "inspection", "disease", "Validation", "Lessons", "Understanding", "rate", "Convolutional Networks", "vision", "machine vision", "recognition", "Datasets", "Enhancement", "computer", "similarity", "Augmentation", "layer", "separation", "Detection", "Optimal Transport", "self", "Text", "View", "encoder", "Sparsity", "type", "decomposition", "bias", "Tuning", "Sets", "VAEs", "Graph", "assessment", "size", "Classifiers", "Domain", "attention", "Classification", "Inference", "distributions", "Search", "Processing", "algorithms", "representations", "Learning", "Self", "Labels", "generalization", "Feature", "System", "Attacks", "problem", "Transfer", "training", "box", "view", "Machine", "Flows", "Generalization", "task", "performance", "applications", "estimation", "Uncertainty", "quantum", "End", "networks", "loss", "scale", "Methods", "feature", "Regression", "level"], "x_centroid": 3.0079839663949572, "y_centroid": 2.381694006533758, "size": 247, "top_doc_id": null, "top_doc_content": ["Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone\n  fine-tuning without episodic meta-learning dominates for few-shot learning\n  image classification", "Unsupervised Enhancement of Real-World Depth Images Using Tri-Cycle GAN", "AffinityNet: semi-supervised few-shot learning for disease type\n  prediction", "NDPNet: A novel non-linear data projection network for few-shot\n  fine-grained image classification", "Voxel-FPN: multi-scale voxel feature aggregation in 3D object detection\n  from point clouds", "RGB and LiDAR fusion based 3D Semantic Segmentation for Autonomous\n  Driving", "LiDAR Snowfall Simulation for Robust 3D Object Detection", "Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video\n  Processing", "Meta-ticket: Finding optimal subnetworks for few-shot learning within\n  randomly initialized neural networks", "Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free and Anchor-based Detectors", "Training CNNs in Presence of JPEG Compression: Multimedia Forensics vs\n  Computer Vision", "RocNet: Recursive Octree Network for Efficient 3D Deep Representation", "Learning to Segment 3D Point Clouds in 2D Image Space", "How far are we from solving the 2D & 3D Face Alignment problem? (and a\n  dataset of 230,000 3D facial landmarks)", "Evaluating Post-Training Compression in GANs using Locality-Sensitive\n  Hashing", "Learning Spectral Unions of Partial Deformable 3D Shapes", "Uncertainty-Aware Voxel based 3D Object Detection and Tracking with\n  von-Mises Loss", "Realistic face animation generation from videos", "GANs for Medical Image Analysis", "Domain Adaptation via CycleGAN for Retina Segmentation in Optical\n  Coherence Tomography", "Unsupervised Domain Adaptation via CycleGAN for White Matter\n  Hyperintensity Segmentation in Multicenter MR Images", "Style-based quantum generative adversarial networks for Monte Carlo\n  events", "Machine unlearning via GAN", "Stain Style Transfer of Histopathology Images Via Structure-Preserved\n  Generative Learning", "GAN Vocoder: Multi-Resolution Discriminator Is All You Need", "Zero-Query Transfer Attacks on Context-Aware Object Detectors", "MODS -- A USV-oriented object detection and obstacle segmentation\n  benchmark", "Analyzing and Improving the Image Quality of StyleGAN", "GANs May Have No Nash Equilibria", "AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds", "FacialFilmroll: High-resolution multi-shot video editing", "MirrorGAN: Learning Text-to-image Generation by Redescription", "Towards Dense People Detection with Deep Learning and Depth images", "BioMetricNet: deep unconstrained face verification through learning of\n  metrics regularized onto Gaussian distributions", "Towards glass-box CNNs", "Composition and decomposition of GANs", "Continual egocentric object recognition", "Simulation of electron-proton scattering events by a Feature-Augmented\n  and Transformed Generative Adversarial Network (FAT-GAN)", "A self-training framework for glaucoma grading in OCT B-scans", "Robust Reference-based Super-Resolution via C2-Matching", "Dynamic region proposal networks for semantic segmentation in automated\n  glaucoma screening", "McGan: Mean and Covariance Feature Matching GAN", "Learning Body-Aware 3D Shape Generative Models", "Towards causal benchmarking of bias in face analysis algorithms", "Parallax Motion Effect Generation Through Instance Segmentation And\n  Depth Estimation", "Deformation-Aware 3D Model Embedding and Retrieval", "When do GANs replicate? On the choice of dataset size", "GAN Slimming: All-in-One GAN Compression by A Unified Optimization\n  Framework", "S-Extension Patch: A simple and efficient way to extend an object\n  detection model", "Probabilistic Semantic Inpainting with Pixel Constrained CNNs", "Unpaired Motion Style Transfer from Video to Animation", "Endo-Depth-and-Motion: Reconstruction and Tracking in Endoscopic Videos\n  using Depth Networks and Photometric Constraints", "Style Transfer by Rigid Alignment in Neural Net Feature Space", "ClipMatrix: Text-controlled Creation of 3D Textured Meshes", "Visual object categorization with new keypoint-based adaBoost features", "StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation", "Validation and generalization of pixel-wise relevance in convolutional\n  neural networks trained for face classification", "Zero-shot Knowledge Transfer via Adversarial Belief Matching", "Steerable CNNs", "Manhattan Room Layout Reconstruction from a Single 360 image: A\n  Comparative Study of State-of-the-art Methods"], "top_term_id": null, "convex_hull": {"x_coordinates": [2.231428861618042, 2.3356549590271087, 2.4423440984086207, 2.551775560328253, 2.6642286253516843, 2.7799825740445914, 2.8993166869726528, 3.022510244701547, 3.149626478395407, 3.2768926363562847, 3.3972404655745034, 3.5034945420822488, 3.588479441911707, 3.64540334202639, 3.674767395628183, 3.6836052093852576, 3.6791813078057647, 3.668760215397855, 3.6596064566696773, 3.6589828258540544, 3.670532720933411, 3.6866531638736544, 3.697563188885272, 3.6934818301787504, 3.664628121964574, 3.6037493410044212, 3.5157765924178968, 3.409306476594493, 3.2929363225042776, 3.175263459117321, 3.0643413401050403, 2.959205449300312, 2.8528074139780286, 2.7461256736546966, 2.6432790163309603, 2.548392376673885, 2.465590689350535, 2.398998889027976, 2.3487801117417257, 2.301375901403722, 2.254190976246578, 2.2093145983011335, 2.1688370517858977, 2.1348486209193798, 2.1094395899200937, 2.094700243006547, 2.0927208643972515, 2.1064704114187185, 2.147536818702183, 2.2314288616180424], "y_coordinates": [1.58337676525116, 1.5401610518221698, 1.5105170097845757, 1.492758380053104, 1.485198903542481, 1.4861523211674337, 1.4939323738426884, 1.5068528024829728, 1.5233791684054077, 1.5446726222578258, 1.574210101409376, 1.6155438534956277, 1.67222612615215, 1.747612218527127, 1.841313068060033, 1.9495857182760312, 2.068568654804359, 2.194400363274253, 2.3232193293149486, 2.451164405466713, 2.5751419501037436, 2.6944431555907937, 2.808821064334134, 2.9180287187400364, 3.0218191612147707, 3.1191235649077305, 3.2049124410635574, 3.272964738878335, 3.317059170704581, 3.3309744488948145, 3.3094204955784017, 3.26254757684182, 3.210466750838506, 3.156735351695356, 3.098463796401768, 3.0327498832682673, 2.956691410605378, 2.8673861767236257, 2.7649625040150716, 2.6601198914291064, 2.555535566844823, 2.450413524630495, 2.34395700127963, 2.235369233285739, 2.1238534571423338, 2.0086129093429204, 1.8888508263810115, 1.7654081348124364, 1.6551899986787857, 1.5833767652511601]}}, {"topic_id": "bt-14", "name": " Meta Bandit Learning", "lemma_name": null, "term_id": ["Bandits", "bandit", "bandits", "Meta Learning", "MDPs", "policy", "Arms", "Optimism", "Auctions", "regret", "Online Learning", "feedback", "games", "Process", "line", "Rewards", "reward", "Risk", "Stochastic", "Strategies", "Bounds", "Losses", "Search", "Context", "Markets", "document", "parameters", "Teachers", "Domains", "Subspaces", "Linear", "Weighted", "algorithm", "inequalities", "gradient method", "PPO", "Variance", "Separators", "set", "Shot", "control", "Programming", "intelligence", "Investigation", "Measure", "POMDPs", "Risk Bounds", "imaging", "efficiency", "Teaching", "Representation", "Sharing", "policies", "identification", "Constraints", "Evaluation", "Problems", "Benefits", "retrieval", "stage", "Effect", "Sparsity", "Device", "Confidence", "Tuning", "Markov", "convergence", "Teacher", "processes", "Model", "Processes", "evaluation", "Decision", "Convergence", "Reinforcement Learning", "Kernel", "text", "decision", "approximation", "algorithms", "process", "case", "time", "generalization", "Information", "Environments", "application", "Web", "equations", "Identification", "problem", "gradient", "stochastic", "space", "Making", "Attention", "noise", "Optimization", "recognition", "Generalization", "problems", "Generation", "learning", "reinforcement learning", "reinforcement", "systems", "Methods", "feature", "Guarantees", "inference", "CUR", "optimization", "method", "methods"], "x_centroid": 9.00400616005423, "y_centroid": 5.168910049585905, "size": 207, "top_doc_id": null, "top_doc_content": ["On learning Whittle index policy for restless bandits with scalable\n  regret", "Matrix games with bandit feedback", "Stochastic continuum armed bandit problem of few linear parameters in\n  high dimensions", "Thompson Sampling for Combinatorial Semi-bandits with Sleeping Arms and\n  Long-Term Fairness Constraints", "Statistically Robust, Risk-Averse Best Arm Identification in Multi-Armed\n  Bandits", "Best arm identification in multi-armed bandits with delayed feedback", "A Model-free Learning Algorithm for Infinite-horizon Average-reward MDPs\n  with Near-optimal Regret", "Stochastic processes and feedback-linearisation for online\n  identification and Bayesian adaptive control of fully-actuated mechanical\n  systems", "Cheap Bandits", "Instance-Wise Minimax-Optimal Algorithms for Logistic Bandits", "Linear convergence of a policy gradient method for finite horizon\n  continuous time stochastic control problems", "Decentralized Heterogeneous Multi-Player Multi-Armed Bandits with\n  Non-Zero Rewards on Collisions", "Online Learning for Combinatorial Network Optimization with Restless\n  Markovian Rewards", "Meta-learning of Sequential Strategies", "Online Learning under Delayed Feedback", "Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed\n  Bandits", "Temporal Regularization in Markov Decision Process", "On Under-exploration in Bandits with Mean Bounds from Confounded Data", "Large Scale Markov Decision Processes with Changing Rewards", "Meta-Learning via Learned Loss", "Why is Posterior Sampling Better than Optimism for Reinforcement\n  Learning?", "Discovering a set of policies for the worst case reward", "Adversarial Dueling Bandits", "Data Poisoning Attacks in Contextual Bandits", "Learning in games from a stochastic approximation viewpoint", "Path Consistency Learning in Tsallis Entropy Regularized MDPs", "Stochastic Process Bandits: Upper Confidence Bounds Algorithms via\n  Generic Chaining", "Play to Grade: Testing Coding Games as Classifying Markov Decision\n  Process", "The Sufficiency of Off-policyness: PPO is insufficient according to an Off-policy Measure", "Risk-Sensitive Markov Decision Processes with Combined Metrics of Mean\n  and Variance", "Reinforcement Learning for on-line Sequence Transformation", "Risk Bounds for the Majority Vote: From a PAC-Bayesian Analysis to a\n  Learning Algorithm", "Fast online inference for nonlinear contextual bandit based on\n  Generative Adversarial Network", "Preselection Bandits", "Meta-Learning with Latent Embedding Optimization", "Online Learning in Opportunistic Spectrum Access: A Restless Bandit\n  Approach", "Online No-regret Model-Based Meta RL for Personalized Navigation", "On-line Learning of an Unlearnable True Teacher through Mobile Ensemble\n  Teachers", "Model-Free Algorithm and Regret Analysis for MDPs with Long-Term\n  Constraints", "Dynamic Bidding Strategies with Multivariate Feedback Control for\n  Multiple Goals in Display Advertising", "Learning to Bid Optimally and Efficiently in Adversarial First-price\n  Auctions", "Restless Bandits with Many Arms: Beating the Central Limit Theorem", "Competing With Strategies", "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits", "Bandits with Partially Observable Confounded Data", "Convergence of Meta-Learning with Task-Specific Adaptation over Partial\n  Parameters", "Real-Time Optimisation for Online Learning in Auctions", "Rotting Bandits", "Reinforcement Learning for Non-Stationary Markov Decision Processes: The\n  Blessing of (More) Optimism", "PAC-Bayesian Bound for the Conditional Value at Risk", "Approachability in unknown games: Online learning meets multi-objective\n  optimization", "Simple and optimal methods for stochastic variational inequalities, II:\n  Markovian noise and policy evaluation in reinforcement learning", "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust\n  Control Design: Implicit Regularization and Sample Complexity"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.053348541259766, 8.031978865967764, 8.021427251312133, 8.02069208920119, 8.028771771543257, 8.101344888031337, 8.202517515621727, 8.30291423024744, 8.403565206703165, 8.50550061978358, 8.609750644283373, 8.71734545499723, 8.828946683655033, 8.943488520154446, 9.05939946210294, 9.175107943412279, 9.289042397994201, 9.399637770492369, 9.509921708213698, 9.622996494988454, 9.734947764595988, 9.84175294096213, 9.939389448012712, 10.023844608098788, 10.093130497827678, 10.14974101437004, 10.196770984085054, 10.237315233331904, 10.274012926711013, 10.282276115230804, 10.241222648252197, 10.158569763844433, 10.04244169386716, 9.900962670180027, 9.742256924642678, 9.574448689114762, 9.405662195455923, 9.244021675525813, 9.09761819980722, 8.969423747512398, 8.851809311914655, 8.735830599702334, 8.613323818696342, 8.487792462182865, 8.371709931589793, 8.2743031510363, 8.195446149231781, 8.133456398671008, 8.086651371848744, 8.053348541259767], "y_coordinates": [5.343271732330321, 5.216068921623708, 5.094314549804567, 4.974351904483644, 4.85252427327168, 4.755582705940757, 4.667862554150959, 4.579884655396663, 4.498133813088979, 4.42909483063902, 4.379252511457893, 4.355091658956708, 4.361151270209089, 4.39284992303263, 4.442936278600113, 4.504158661788302, 4.569265397473954, 4.631010480108632, 4.686944325960925, 4.742210452577733, 4.7999838692849535, 4.863388352510094, 4.935547678680661, 5.019577122123331, 5.1168528254893575, 5.224901340260501, 5.340733058990492, 5.461358374233065, 5.583513097540038, 5.687824885557219, 5.760149899760663, 5.8053052940064305, 5.828374293006695, 5.8344401214736346, 5.828586004119421, 5.8158951656562285, 5.801450830796233, 5.790336224251607, 5.787620001104492, 5.796121716037482, 5.8140033233016295, 5.838848898882601, 5.86755380963302, 5.8867182854447675, 5.8750357273567, 5.8189532851899415, 5.726322221371929, 5.608555979134658, 5.477068001710124, 5.343271732330323]}}, {"topic_id": "bt-15", "name": " Forecasting with MAML and FPGA", "lemma_name": null, "term_id": ["forecasting", "MAML", "FPGA", "Activation Functions", "Field", "GPUs", "Failure", "comparison", "series", "processing", "bit", "Quantization", "Workloads", "diversity", "Machine Learning", "time series", "Errors", "DNNs", "production", "Calibration", "prediction", "models", "series data", "Need", "ML", "failure", "Ensembles", "Capacity", "latency", "Distillation", "competition", "sensor", "points", "Machines", "Markets", "Mining", "chaos", "network models", "Student", "Calls", "Teachers", "regression models", "tools", "stability", "wavelet", "Values", "Phases", "uniform", "Dependencies", "simulation", "forecast", "Goals", "imbalance", "Decision Making", "term", "time", "Deep Learning", "Processing", "embeddings", "tree", "Review", "clusters", "drift", "management", "material", "Sensors", "inspection", "world", "impact", "P", "Characterization", "supervision", "RNN", "memory", "Decision", "Network", "Making", "regression", "Overview", "block", "Devices", "latent", "Forecasting", "Solutions", "E", "science", "LSTMs", "validation", "encoder", "description", "Modelling", "Device", "Layers", "bias", "CNNs", "information", "Datasets", "Study", "Rules", "step", "context", "monitoring", "Cost", "diagnosis", "Model", "training", "Application", "Data", "dynamics", "Tasks", "Dataset", "Dynamics", "techniques", "Domain", "risk", "knowledge", "batch", "machines", "Rate", "error", "Search", "Events", "Kernel", "Predictions", "text", "approaches", "Survey", "End", "Algorithms", "transfer", "review", "Challenges", "features", "Approximation", "Environments", "Feature", "Systems", "Web", "Identification", "survey", "Training", "Prediction", "class", "control", "space", "identification", "Applications", "Constraints", "box", "view", "selection", "Machine", "Networks", "Generalization", "task", "performance", "applications", "Transformers", "images", "Structure", "systems", "graph", "feature", "learning"], "x_centroid": 5.609933880553848, "y_centroid": 3.4085926424954587, "size": 261, "top_doc_id": null, "top_doc_content": ["A review and comparison of strategies for multi-step ahead time series\n  forecasting based on the NN5 forecasting competition", "Nonparametric risk bounds for time-series forecasting", "Operational Calibration: Debugging Confidence Errors for DNNs in the\n  Field", "Automatic deep learning for trend prediction in time series data", "A consistent deterministic regression tree for non-parametric prediction\n  of time series", "Machine Learning to Tackle the Challenges of Transient and Soft Errors\n  in Complex Circuits", "Probabilistic forecasting approaches for extreme NO$_2$ episodes: a\n  comparison of models", "Low-bit Quantization of Neural Networks for Efficient Inference", "The Curse of Zero Task Diversity: On the Failure of Transfer Learning to\n  Outperform MAML and their Empirical Equivalence", "Field-aware Calibration: A Simple and Empirically Strong Method for\n  Reliable Probabilistic Predictions", "On the cross-validation bias due to unsupervised pre-processing", "Robustness-aware 2-bit quantization with real-time performance for\n  neural network", "PRESISTANT: Learning based assistant for data pre-processing", "Does MAML Only Work via Feature Re-use? A Data Centric Perspective", "Taming Unbalanced Training Workloads in Deep Learning with Partial\n  Collective Operations", "Machine Learning based Framework for Robust Price-Sensitivity Estimation with Application to Airline Pricing", "An ensemble diversity approach to supervised binary hashing", "Who supervises the supervisor? Model monitoring in production using deep\n  feature embeddings with applications to workpiece inspection", "Machine Learning and Cloud Computing: Survey of Distributed and SaaS\n  Solutions", "Robust identification of thermal models for in-production\n  High-Performance-Computing clusters with machine learning-based data\n  selection", "Soft Calibration Objectives for Neural Networks", "Machine Learning for CUDA+MPI Design Rules", "Investigating the Impact of Pre-processing and Prediction Aggregation on\n  the DeepFake Detection Task", "Machine Learning based CVD Virtual Metrology in Mass Produced\n  Semiconductor Process", "Kernel machines that adapt to GPUs for effective large batch training", "Machine learning method for return direction forecasting of Exchange Traded Funds using classification and regression models", "Continuous and randomized defensive forecasting: unified view", "Scanflow: A multi-graph framework for Machine Learning workflow\n  management, supervision, and debugging", "Logical Activation Functions: Logit-space equivalents of Boolean\n  Operators", "Post-training Quantization for Neural Networks with Provable Guarantees", "Detecting False Data Injection Attacks in Smart Grids with Modeling\n  Errors: A Deep Transfer Learning Based Approach", "Evaluating race and sex diversity in the world's largest companies using\n  deep neural networks", "Data imputation and comparison of custom ensemble models with existing\n  libraries like XGBoost, Scikit learn, etc. for Predictive Equipment failure", "Data-driven Neural Architecture Learning For Financial Time-series\n  Forecasting", "SMAUG: End-to-End Full-Stack Simulation Infrastructure for Deep Learning\n  Workloads", "Market forecasting using Hidden Markov Models", "Machine Learning for Auxiliary Sources", "Towards Practical Robustness Analysis for DNNs based on PAC-Model\n  Learning", "Activation Functions for Generalized Learning Vector Quantization - A\n  Performance Comparison", "ATM Cash demand forecasting in an Indian Bank with chaos and deep\n  learning", "XSP: Across-Stack Profiling and Analysis of Machine Learning Models on\n  GPUs", "Understanding Failure Modes of Self-Supervised Learning", "DLAU: A Scalable Deep Learning Accelerator Unit on FPGA", "Demand forecasting techniques for build-to-order lean manufacturing\n  supply chains", "Model-Architecture Co-Design for High Performance Temporal GNN Inference\n  on FPGA"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.704063892364501, 4.716884080803345, 4.75643839239633, 4.8171984915277255, 4.893636042581797, 4.9802227099428125, 5.071430157995042, 5.161730051122751, 5.2455940537102075, 5.324065071729834, 5.4358461124314035, 5.549455345687658, 5.664938005753415, 5.781861098402428, 5.89288811339137, 5.9909777874103805, 6.075078482701553, 6.148702852551915, 6.215080877572542, 6.27735384757472, 6.338662139752212, 6.400950981895208, 6.462619406299819, 6.521411776536648, 6.573695892930997, 6.592841233249017, 6.546799893524008, 6.456614051243359, 6.355903784468394, 6.261409708306359, 6.1719093770141, 6.085309012100592, 5.99951483507481, 5.912433067445733, 5.821969930722333, 5.726028055697488, 5.621253276912164, 5.508693232610997, 5.402401364326258, 5.296595676723242, 5.18538682516331, 5.081756338957211, 5.003499466984789, 4.947151627875665, 4.901947673070629, 4.858134951202843, 4.808492877810261, 4.759169288354426, 4.720809920313315, 4.704063892364501], "y_coordinates": [3.2925479412078853, 3.192178362186855, 3.0959626189086342, 3.0030843292868794, 2.912727111235239, 2.8240745826673694, 2.7363103614969218, 2.64861806563755, 2.560181313002905, 2.47631825014183, 2.4458820697464994, 2.453011033116177, 2.4608940258626473, 2.4662768808251094, 2.4869162120525963, 2.539464357275112, 2.619195564973534, 2.7083762509290916, 2.8017283930820294, 2.896783583151045, 2.9910745367470786, 3.083605800899853, 3.177749077013042, 3.277682293725366, 3.386826425299161, 3.4959559647395726, 3.590031143304057, 3.672019328797981, 3.7492608052426606, 3.825357873374026, 3.899934886205628, 3.9724232387607996, 4.042254326062874, 4.108859543135187, 4.171670285001072, 4.230094813232629, 4.275443415950888, 4.281578343456293, 4.24501403818368, 4.194870121467199, 4.157223231610287, 4.113414521353537, 4.032823564594485, 3.9313968171684905, 3.827718230832908, 3.722114948023824, 3.614181021519305, 3.5052919149505817, 3.3974224605739276, 3.292547941207886]}}, {"topic_id": "bt-16", "name": " Speech Endings", "lemma_name": null, "term_id": ["speech", "speaker", "End", "speech synthesis", "synthesis", "prosody", "fine", "hearing", "dataset", "event", "Synthesis", "recognition", "channel", "Text", "Teacher", "Effects", "identification", "attention", "Baseline", "scenarios", "labels", "planning", "Cross Modal", "resource", "Phase", "rates", "discrimination", "Conditions", "Manifolds", "Weighted", "speech recognition", "robotics", "signals", "attentive", "Language", "VAE", "text", "BERT", "Self", "level", "CycleGAN", "Investigation", "Directions", "verification", "encoding", "Auto", "environments", "Memory", "samples", "Modality", "temperature", "patients", "Captioning", "Insights", "outcomes", "tasks", "supervision", "regularization", "word", "Understanding", "Representation", "body", "test", "RNNs", "Implementation", "noise", "label", "Networks", "Style Transfer", "Devices", "computer", "cancer", "style", "retrieval", "path", "LSTMs", "self", "Users", "View", "target", "vectors", "vector", "Layers", "Performance", "constraints", "shot", "systems", "Signals", "Thresholding", "Dataset", "Representations", "machines", "processing", "Units", "Design", "detection", "error", "Federated Learning", "generation", "Training", "Features", "sparse", "language", "modeling", "features", "Labels", "segmentation", "generalization", "resolution", "GANs", "System", "training", "Network", "space", "Strategies", "representation", "Attention", "Datasets", "Study", "task", "Generation", "Clustering", "images", "loss", "network", "Regression", "models", "Models", "framework", "Deep Learning"], "x_centroid": 3.921513333916664, "y_centroid": 0.5460327343729053, "size": 192, "top_doc_id": null, "top_doc_content": ["Fully-hierarchical fine-grained prosody modeling for interpretable\n  speech synthesis", "Generating diverse and natural text-to-speech samples using a quantized\n  fine-grained VAE and auto-regressive prosody prior", "Byakto Speech: Real-time long speech synthesis with convolutional neural\n  network: Transfer learning from English to Bangla", "Self-attention encoding and pooling for speaker recognition", "ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis", "Speaker-adaptive neural vocoders for parametric speech synthesis systems", "Text-to-speech for the hearing impaired", "Latent space representation for multi-target speaker detection and\n  identification with a sparse dataset using Triplet neural networks", "End-to-end Networks for Supervised Single-channel Speech Separation", "A scalable noisy speech dataset and online subjective test framework", "Domain Adaptation via Teacher-Student Learning for End-to-End Speech\n  Recognition", "A novel dataset for the identification of computer generated melodies in\n  the CSMT challenge", "Exploiting semi-supervised training through a dropout regularization in\n  end-to-end speech recognition", "Joint prediction of truecasing and punctuation for conversational speech\n  in low-resource scenarios", "Partially Fake Audio Detection by Self-attention-based Fake Span\n  Discovery", "End-to-End Optimized Speech Coding with Deep Neural Networks", "Transient-evoked otoacoustic emission signals predicting outcomes of\n  acute sensorineural hearing loss in patients with Meniere's Disease", "Infant directed speech is consistent with teaching", "Hierarchical Multi-Grained Generative Model for Expressive Speech\n  Synthesis", "End-To-End Label Uncertainty Modeling for Speech-based Arousal\n  Recognition Using Bayesian Neural Networks", "Generative x-vectors for text-independent speaker verification", "deepSELF: An Open Source Deep Self End-to-End Learning Framework", "Quantifying the Effects of Prosody Modulation on User Engagement and\n  Satisfaction in Conversational Systems", "General-purpose Tagging of Freesound Audio with AudioSet Labels: Task\n  Description, Dataset, and Baseline", "Weakly-supervised word-level pronunciation error detection in non-native\n  English speech", "Quaternion Convolutional Neural Networks for End-to-End Automatic Speech\n  Recognition", "Developing hierarchical anticipations via neural network-based event\n  segmentation", "Language Modelling for Sound Event Detection with Teacher Forcing and\n  Scheduled Sampling", "Very Deep Self-Attention Networks for End-to-End Speech Recognition", "Deep convolutional neural networks for predominant instrument\n  recognition in polyphonic music", "Self-Training for End-to-End Speech Recognition", "Speaker discrimination in humans and machines: Effects of speaking style\n  variability", "Detecting and analysing spontaneous oral cancer speech in the wild", "Kernel Machines Beat Deep Neural Networks on Mask-based Single-channel\n  Speech Enhancement", "Improving Pseudo-label Training For End-to-end Speech Recognition Using\n  Gradient Mask", "ChannelAugment: Improving generalization of multi-channel ASR by\n  training with input channel randomization", "Differentiable Wavetable Synthesis", "What shall we do with an hour of data? Speech recognition for the un-\n  and under-served languages of Common Voice", "One-shot learning for acoustic identification of bird species in\n  non-stationary environments", "Improving weakly supervised sound event detection with self-supervised\n  auxiliary tasks", "Ensemble Chinese End-to-End Spoken Language Understanding for Abnormal\n  Event Detection from audio stream", "Pretrained Semantic Speech Embeddings for End-to-End Spoken Language\n  Understanding via Cross-Modal Teacher-Student Learning"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.904904842376708, 4.912168373153311, 4.896895913117817, 4.861585432928872, 4.808734903245124, 4.740842294725224, 4.660405578027816, 4.56992272381155, 4.471891702735076, 4.36881048545704, 4.263177042636092, 4.157277448870947, 4.051815188142838, 3.9467778958803135, 3.842008610211945, 3.736732188572471, 3.630004215333801, 3.5208802705312165, 3.4084373734266276, 3.2945100353415557, 3.1863784117122753, 3.0919611005723944, 3.019176699955521, 2.975940133313209, 2.9669517166041643, 2.9878106521556855, 3.0325166994352855, 3.095069617910474, 3.1694691670487627, 3.2497151063176606, 3.3298071951846806, 3.403745193117334, 3.4663616065620158, 3.521133570300867, 3.5766598600357566, 3.6416062967130456, 3.724638701279095, 3.83011546942381, 3.9375275304627735, 4.043325538533549, 4.148452905733061, 4.2538530441582285, 4.360385991742507, 4.466803181415223, 4.569635533604723, 4.665308194313083, 4.750246309542384, 4.820875025294703, 4.873619487572118, 4.904904842376708], "y_coordinates": [0.498900443315506, 0.5983444108632247, 0.7000027342331134, 0.8020959336611498, 0.9028445293833124, 1.000469041635579, 1.0931899906539273, 1.1792278966743357, 1.2568032799327824, 1.324136660665245, 1.379448559107702, 1.4211773728842185, 1.4493887630529314, 1.4648844459482124, 1.4684064694137453, 1.460419570051966, 1.4413125498338488, 1.4114742087849876, 1.3712958015307337, 1.3214842908818427, 1.2633701172093545, 1.1983568168532328, 1.1278479261534389, 1.0532464488374544, 0.9754894471878678, 0.8941948221137628, 0.808748643198386, 0.7185369800249829, 0.6229459021768006, 0.521361479237085, 0.4131697807890825, 0.2977568764160391, 0.17528633044122707, 0.05399276986472621, -0.05310735505091348, -0.13293499720849994, -0.17241110951084263, -0.16596206034007607, -0.15047755295819348, -0.131739805859475, -0.10755643616500825, -0.07573506099588115, -0.03414096226442938, 0.017902185464791397, 0.07953491542846956, 0.14982460318522756, 0.2278386242936877, 0.3126443543124731, 0.4033091688002049, 0.498900443315506]}}, {"topic_id": "bt-17", "name": " Natural Language Processing", "lemma_name": null, "term_id": ["Answering", "BERT", "Topic", "Sentences", "keyword", "topic", "word embeddings", "health records", "knowledge graph", "Alignment", "language", "embeddings", "knowledge", "language model", "entity", "Documents", "records", "word", "Tree", "Embeddings", "Experiments", "health", "Translation", "Models", "text", "domain", "rule", "seq2seq", "semantics", "Sense", "levels", "document", "distances", "variants", "Tricks", "examples", "Annotations", "Notes", "Ontology", "summarization", "behavior", "Language", "Web", "System", "Classification", "Modeling", "level", "kernels", "tree", "Review", "Investigation", "classifier", "ell", "supervision", "structures", "Understanding", "Representation", "RNN", "Logic", "model", "study", "Augmentation", "Don", "Sequence", "t", "task", "Generation", "Tuning", "Graph", "shot", "Reasoning", "Exploration", "graph", "Dataset", "risk", "machines", "End", "detection", "Events", "properties", "Examples", "Processing", "Estimation", "Algorithms", "Learning", "Image", "Case", "generalization", "training", "Theory", "Transfer", "system", "space", "representation", "Attention", "Evaluation", "CNNs", "Machine", "function", "Study", "analysis", "Performance", "images", "Structure", "Training", "Data", "scale", "feature", "Survey", "CUR", "Features", "Prediction", "approach"], "x_centroid": 5.348253690419983, "y_centroid": 1.399054491542765, "size": 261, "top_doc_id": null, "top_doc_content": ["Multimodal data matters: language model pre-training over structured and\n  unstructured electronic health records", "Ontology-driven weak supervision for clinical entity classification in\n  electronic health records", "Invariance and identifiability issues for word embeddings", "Modeling electronic health record data using a knowledge-graph-embedded\n  topic model", "DegreEmbed: incorporating entity embedding into logic rule learning for\n  knowledge graph reasoning", "BULNER: BUg Localization with word embeddings and NEtwork Regularization", "NukeBERT: A Pre-trained language model for Low Resource Nuclear Domain", "Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in\n  Pretrained Embeddings", "Factoring out prior knowledge from low-dimensional embeddings", "Topic Modeling of Hierarchical Corpora", "Contextual Networks and Unsupervised Ranking of Sentences", "Image Question Answering using Convolutional Neural Network with Dynamic\n  Parameter Prediction", "From phonemes to images: levels of representation in a recurrent neural\n  model of visually-grounded language learning", "SenseBERT: Driving Some Sense into BERT", "Probabilities on Sentences in an Expressive Logic", "Tree-Structured Semantic Encoder with Knowledge Sharing for Domain\n  Adaptation in Natural Language Generation", "mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot\n  Filling", "MEKER: Memory Efficient Knowledge Embedding Representation for Link\n  Prediction and Question Answering", "Clinical Trial Information Extraction with BERT", "Discovering topic structures of a temporally evolving document corpus", "Teaching keyword spotters to spot new keywords with limited examples", "CG-BERT: Conditional Text Generation with BERT for Generalized Few-shot\n  Intent Detection", "Semantic Sensitive TF-IDF to Determine Word Relevance in Documents", "TACo: Token-aware Cascade Contrastive Learning for Video-Text Alignment", "Analyzing Team Performance with Embeddings from Multiparty Dialogues", "Distributed Deep Learning for Question Answering", "Selection-based Question Answering of an MOOC", "Alignment Restricted Streaming Recurrent Neural Network Transducer", "Event detection in Twitter: A keyword volume approach", "ScopeIt: Scoping Task Relevant Sentences in Documents", "Ranking Paragraphs for Improving Answer Recall in Open-Domain Question\n  Answering", "Speeding up Word Mover's Distance and its variants via properties of\n  distances between embeddings", "Word2vec to behavior: morphology facilitates the grounding of language\n  in machines", "Tree-to-tree Neural Networks for Program Translation"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.489263534545897, 4.498388646012215, 4.542122950945373, 4.604938074365394, 4.671339171055205, 4.7313603423452015, 4.786673666070686, 4.840423146715323, 4.895752788762775, 4.956831944954684, 5.041563981292998, 5.159470976821168, 5.276681349437484, 5.386784307487175, 5.492223908630036, 5.595444210525866, 5.698875662487276, 5.8040481300054, 5.911044951186244, 6.019631572498273, 6.126455349485267, 6.225591389004845, 6.311037886755681, 6.376793038436455, 6.416855039745837, 6.425222086382511, 6.396285582578526, 6.336120020866857, 6.264169830902066, 6.19872647706178, 6.13025262845343, 6.0608780573342, 5.993102460183015, 5.916732446364103, 5.822372789553427, 5.710709943971293, 5.589328938253132, 5.466389010112675, 5.350803322296889, 5.25074168670414, 5.1658144630147955, 5.090526308135658, 5.019313681755692, 4.946721579904339, 4.8686067875753265, 4.7816981574052715, 4.686568394034176, 4.595988846240776, 4.525155298314781, 4.489263534545896], "y_coordinates": [1.4233326911926263, 1.3148921165200456, 1.2029838885165303, 1.0915827743476172, 0.9846479826675505, 0.8835731752895452, 0.7843517495095433, 0.6822940978719496, 0.5727106129211675, 0.4551713608256044, 0.3863246590958618, 0.41392199304294647, 0.4623864619712459, 0.5115322519685912, 0.5606871855151586, 0.6091790850911253, 0.6563762505066262, 0.7043257219067827, 0.7593771608693745, 0.8279557154536393, 0.9112803987893953, 1.0062754570943881, 1.1097367215142222, 1.218460023194503, 1.3292411932808352, 1.4388760629188244, 1.544258906417207, 1.6452089604643636, 1.7448927413456112, 1.8460065941910337, 1.9421272489743107, 2.0414081692790806, 2.14210514150247, 2.2303581855489774, 2.2935238780358396, 2.3343074182071044, 2.3657682225045487, 2.3900240638931622, 2.3901186653238704, 2.3491735310218655, 2.2707164348961157, 2.170447465750147, 2.0642292988221835, 1.9668404376234272, 1.8799558988463183, 1.796553653746178, 1.710726207835786, 1.6206156294432466, 1.5251688225637856, 1.4233326911926258]}}, {"topic_id": "bt-18", "name": " Tree Feature Labeling", "lemma_name": null, "term_id": ["label", "Trees", "Feature", "Noisy Labels", "loss function", "output", "vector machines", "forests", "Decision Trees", "Uncertainty", "Labels", "Classifiers", "Loss Functions", "batch", "classification", "Terms", "feature selection", "loss", "Generalization", "ReLU", "SGD", "vector", "Training", "Classification", "Tree", "Sets", "support", "robustness", "feature", "noise", "machines", "classifiers", "selection", "Survey", "Ensembles", "latency", "Curriculum Learning", "learner", "sensor", "Bases", "effects", "Context", "Multivariate", "Samples", "length", "Regularization", "uncertainties", "gene expression", "values", "utility", "Queries", "Norm", "imbalance", "performance", "Performance", "scale", "functions", "tree", "predictor", "Classes", "bit", "gene", "Measure", "Traces", "Sketches", "Nets", "Alternative", "impact", "P", "efficiency", "Distance", "Characterization", "confidence", "regularization", "bounds", "diversity", "Decision", "problem", "class", "Neural Networks", "Optimization", "machine learning", "calibration", "Benefits", "accuracy", "activation", "similarity", "Augmentation", "DNNs", "Introduction", "target", "uncertainty quantification", "vectors", "description", "Modelling", "Points", "bias", "function", "task", "applications", "Embeddings", "Message", "distribution", "augmentation", "assessment", "training", "machine", "Losses", "evaluation", "techniques", "knowledge", "Rates", "data", "Convergence", "Gradients", "properties", "Kernel", "learning approach", "quantification", "domain", "Guarantees", "Regression", "datasets", "case", "modeling", "descent", "Features", "uncertainty", "Information", "Web", "Identification", "Theory", "Transfer", "image", "system", "stochastic", "space", "Problems", "Applications", "Constraints", "box", "Evaluation", "approach", "models", "information", "Datasets", "Machine", "Machine Learning", "methods", "Scale", "estimation", "analysis"], "x_centroid": 6.555023912095676, "y_centroid": 4.560591823863287, "size": 274, "top_doc_id": null, "top_doc_content": ["Random forests with random projections of the output space for high\n  dimensional multi-label classification", "Logitron: Perceptron-augmented classification model based on an extended\n  logistic loss function", "On the intrinsic robustness to noise of some leading classifiers and\n  symmetric loss function -- an empirical evaluation", "Large-scale Multi-label Learning with Missing Labels", "Tree-Structured Boosting: Connections Between Gradient Boosted Stumps\n  and Full Decision Trees", "Multi-utility Learning: Structured-output Learning with Multiple\n  Annotation-specific Loss Functions", "Decision Stream: Cultivating Deep Decision Trees", "Learning with Neighbor Consistency for Noisy Labels", "Optimal randomized classification trees", "Exploring Uncertainty in Deep Learning for Construction of Prediction\n  Intervals", "Understanding the Interaction of Adversarial Training with Noisy Labels", "Simplest Streaming Trees", "Uncertainty in Gradient Boosting via Ensembles", "Entropy methods for the confidence assessment of probabilistic\n  classification models", "Going Beyond One-Hot Encoding in Classification: Can Human Uncertainty\n  Improve Model Performance?", "Generalization of Machine Learning for Problem Reduction: A Case Study\n  on Travelling Salesman Problems", "On Uncertainty, Tempering, and Data Augmentation in Bayesian\n  Classification", "ReLU Networks as Surrogate Models in Mixed-Integer Linear Programs", "Characterizing Implicit Bias in Terms of Optimization Geometry", "Online Active Model Selection for Pre-trained Classifiers", "Pretrained Generalized Autoregressive Model with Adaptive Probabilistic\n  Label Clusters for Extreme Multi-label Text Classification", "Loss Functions for Classification using Structured Entropy", "A constrained recursion algorithm for batch normalization of\n  tree-sturctured LSTM", "IMMIGRATE: A Margin-based Feature Selection Method with Interaction\n  Terms", "RBUE: A ReLU-Based Uncertainty Estimation Method of Deep Neural Networks", "On Symmetric Losses for Learning from Corrupted Labels", "Feature Selection Using Reinforcement Learning", "A Huber loss-based super learner with applications to healthcare\n  expenditures", "CEMENT: Incomplete Multi-View Weak-Label Learning with Long-Tailed\n  Labels", "Comment on \"robustness and regularization of support vector machines\" by\n  H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510,\n  2009, arXiv:0803.3490)", "Peer Loss Functions: Learning from Noisy Labels without Knowing Noise\n  Rates", "Incremental Feature Learning For Infinite Data", "Neuro-algorithmic Policies enable Fast Combinatorial Generalization", "Regularization and feature selection for large dimensional data", "Feature Gradients: Scalable Feature Selection via Discrete Relaxation", "The perils of being unhinged: On the accuracy of classifiers minimizing\n  a noise-robust convex loss", "AI Uncertainty Based on Rademacher Complexity and Shannon Entropy", "Exploiting Local and Global Features in Transformer-based Extreme\n  Multi-label Text Classification", "Feature Partitioning for Efficient Multi-Task Architectures", "Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep\n  Classifiers", "Modulation and signal class labelling using active learning and\n  classification using machine learning", "Using Ontologies To Improve Performance In Massively Multi-label\n  Prediction Models", "A Conjugate Property between Loss Functions and Uncertainty Sets in\n  Classification Problems", "Beyond Average Performance -- exploring regions of deviating performance\n  for black box classification models", "A Hybrid Swarm and Gravitation based feature selection algorithm for\n  Handwritten Indic Script Classification problem", "Feature Interactions in XGBoost", "Distributed Maximization of Submodular plus Diversity Functions for\n  Multi-label Feature Selection on Huge Datasets", "Convergence proof for stochastic gradient descent in the training of\n  deep neural networks with ReLU activation for constant target functions", "Uncertainty Modelling in Deep Networks: Forecasting Short and Noisy\n  Series", "How You Start Matters for Generalization", "Category Trees", "Engineering fast multilevel support vector machines", "Nonconvex One-bit Single-label Multi-label Learning", "NBDT: Neural-Backed Decision Trees", "Is Batch Norm unique? An empirical investigation and prescription to\n  emulate the best properties of common normalizers without batch dependence", "Survey of resampling techniques for improving classification performance\n  in unbalanced datasets", "Learning with Different Amounts of Annotation: From Zero to Many Labels", "Data optimization for large batch distributed training of deep neural\n  networks", "Improved Multi-label Classification with Frequent Label-set Mining and\n  Association", "Collage Inference: Achieving low tail latency during distributed image\n  classification using coded redundancy models", "Machine Unlearning: Linear Filtration for Logit-based Classifiers", "Context-dependent feature analysis with random forests", "Robustness of different loss functions and their impact on networks\n  learning capability", "Meta Dropout: Learning to Perturb Features for Generalization"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.801013469696044, 6.895042861877212, 6.972381428927216, 7.036172393181697, 7.089558976976292, 7.135684402646647, 7.177691892528401, 7.218724668957193, 7.262025737057323, 7.311982486111669, 7.373503033574734, 7.435990375473448, 7.462972010347923, 7.430860585712338, 7.361459034915326, 7.2848858792134665, 7.21687098133215, 7.1405216438681185, 7.052013755511853, 6.9542147316170455, 6.850001002444918, 6.742248998256691, 6.633835149313584, 6.526989992243722, 6.421201357887117, 6.3152291976998285, 6.207833955487998, 6.1025913619108545, 6.018960773925087, 5.962514874025498, 5.924176711937876, 5.895381100950247, 5.8683041294983385, 5.840784427014915, 5.813273833466769, 5.786238216413648, 5.760191978949452, 5.785798178319433, 5.8511650713279435, 5.9118329539927394, 5.981109905101831, 6.059049425717317, 6.141255723425831, 6.225441761849029, 6.312083057879211, 6.40184161329277, 6.495316240201785, 6.5929183373336375, 6.695024720184364, 6.801013469696044], "y_coordinates": [3.6252503395080566, 3.645635059628258, 3.7023917408191167, 3.7872371000449476, 3.891887854270061, 4.008060720458772, 4.127472415575392, 4.241839656584235, 4.343746833213033, 4.435729459813837, 4.5266197468391205, 4.620955027470592, 4.715935884391251, 4.808787627825325, 4.898868487135387, 4.985923416375884, 5.067534595520195, 5.137062958430586, 5.193804709661046, 5.239494624266126, 5.2758707625727315, 5.304671184907767, 5.3276339515981395, 5.345836345023345, 5.357549737412743, 5.360300847974444, 5.351615964940428, 5.324905916994411, 5.26101758399776, 5.171010142799093, 5.070730324093851, 4.966234523260817, 4.862936072976228, 4.761362130107165, 4.659784926372739, 4.556464589158439, 4.4496743602817075, 4.351667121868655, 4.264074449756995, 4.178349929309553, 4.098651751265548, 4.024907608197477, 3.9556297268849425, 3.890015426150241, 3.828159493003739, 3.7702179574980614, 3.717187040654403, 3.6725548747096397, 3.6402694221426994, 3.625250339508057]}}, {"topic_id": "bt-19", "name": " Federated Learning Fairness", "lemma_name": null, "term_id": ["Federated Learning", "Fairness", "Federated", "G", "Devices", "Users", "risk", "Decision Making", "learner", "point", "measures", "Scenarios", "Noise", "Phases", "relationship", "Estimation", "Systems", "Making", "weight", "Traces", "entity", "POMDPs", "measure", "outcomes", "computing", "rate", "Sharing", "Networks", "calibration", "Experts", "Don", "E", "edge", "t", "topology", "reinforcement learning", "reinforcement", "Communication", "AI", "Decision", "Images", "reduction", "learning approach", "generation", "decision", "learning", "Rank", "theory", "Algorithms", "Learning", "Case", "Machine Learning", "Labels", "Environments", "resolution", "survey", "Attacks", "problem", "Network", "Constraints", "view", "Datasets", "Data", "Clustering", "Transformers", "images", "Approach", "Structure", "dynamics", "Modeling", "Survey", "Regression", "approach", "prediction", "classification", "End", "Training", "Application", "data"], "x_centroid": 9.357014541894618, "y_centroid": 1.8583293800622644, "size": 142, "top_doc_id": null, "top_doc_content": ["Fairness risk measures", "Multi-learner risk reduction under endogenous participation dynamics", "Dynamic Modeling and Equilibria in Fair Decision Making", "Don't Throw it Away! The Utility of Unlabeled Data in Fair Decision Making", "Federated learning and next generation wireless communications: A survey\n  on bidirectional relationship", "Estimation of Video Streaming KQIs for Radio Access Negotiation in\n  Network Slicing Scenarios", "Federated Learning with Sparsification-Amplified Privacy and Adaptive\n  Optimization", "FGLP: A Federated Fine-Grained Location Prediction System for Mobile\n  Users", "Fairness by Learning Orthogonal Disentangled Representations", "FedH2L: Federated Learning with Model and Statistical Heterogeneity", "Is calibration a fairness requirement? An argument from the point of\n  view of moral philosophy and decision theory", "Federated Learning with Unbiased Gradient Aggregation and Controllable\n  Meta Updating", "Graph Reinforcement Learning for Predictive Power Allocation to Mobile\n  Users", "Federated learning for LEO constellations via inter-HAP links", "Deep Echo State Q-Network (DEQN) and Its Application in Dynamic Spectrum\n  Sharing for 5G and Beyond", "Threats to Federated Learning: A Survey", "A Federated Learning Framework for Smart Grids: Securing Power Traces in\n  Collaborative Learning", "Estimation of Individual Device Contributions for Incentivizing\n  Federated Learning", "Evolution of Small Cell from 4G to 6G: Past, Present, and Future", "Federated Learning with Noisy User Feedback", "Learning-Aided Deep Path Prediction for Sphere Decoding in Large MIMO\n  Systems", "Federated Learning with Autotuned Communication-Efficient Secure\n  Aggregation", "Practical and Light-weight Secure Aggregation for Federated Submodel\n  Learning", "Federated Cycling (FedCy): Semi-supervised Federated Learning of\n  Surgical Phases", "Noise-tolerant fair classification", "Fairness in machine learning: against false positive rate equality as a\n  measure of fairness", "Quantization Robust Federated Learning for Efficient Inference on Heterogeneous Devices", "Federated Multi-Mini-Batch: An Efficient Training Approach to Federated\n  Learning in Non-IID Environments", "A Machine Learning Solution for Beam Tracking in mmWave Systems", "To Talk or to Work: Delay Efficient Federated Learning over Mobile Edge\n  Devices"], "top_term_id": null, "convex_hull": {"x_coordinates": [9.809948921203612, 9.815731943781211, 9.821091965892837, 9.822538298103723, 9.81658025097911, 9.799727135084229, 9.768488260984311, 9.719442260905184, 9.651618701373705, 9.567096650731775, 9.468146007129183, 9.357036668715732, 9.236038533641207, 9.107421500055407, 8.973455466108126, 8.836650210775964, 8.701743051239452, 8.574680282071927, 8.461420196863415, 8.367921089203932, 8.300141252683506, 8.264038980892156, 8.265457013169442, 8.298383801195499, 8.340156518822216, 8.384698822282086, 8.43221081664326, 8.482908130315023, 8.537006391706655, 8.594721229227432, 8.65626827128663, 8.721863146293533, 8.791721482657415, 8.866058908787554, 8.94509105309323, 9.029033543983722, 9.118102009868307, 9.212512079156268, 9.312479380256875, 9.415045829699439, 9.510261310193188, 9.597215527553143, 9.668983694230578, 9.721410731607813, 9.757721928827733, 9.781160421538663, 9.794914288436159, 9.802171608215781, 9.806120459573078, 9.80994892120361], "y_coordinates": [2.034223556518554, 2.152638084689072, 2.2713849065271514, 2.3875399635391714, 2.4981791972315106, 2.600378549110545, 2.691213960682652, 2.767808104629144, 2.8289358794813144, 2.8754279164460277, 2.908243489077445, 2.9283418709297298, 2.936682335557043, 2.9342241565135465, 2.9219266073534027, 2.900642352916923, 2.870234087373857, 2.8300272067420487, 2.7793417743924924, 2.717497853696181, 2.64381550802411, 2.5576148007472708, 2.4583218049639357, 2.35548992442281, 2.2552975807546622, 2.1531848570851206, 2.050119311849921, 1.9470872967984458, 1.8450751636800726, 1.7450692642441823, 1.6480559502401535, 1.5550215734173665, 1.4669524855252005, 1.3848350383130348, 1.3096555835302501, 1.2424004729262248, 1.1840560582503394, 1.1356086912519732, 1.0980447236805053, 1.0951422845276197, 1.1588878597556986, 1.2236220464185414, 1.2997542095418033, 1.3929342714429989, 1.490722993700333, 1.59228731076556, 1.6975233741093356, 1.806327335202321, 1.9185953455151745, 2.0342235565185534]}}, {"topic_id": "bt-2", "name": " COVID-19 Survival", "lemma_name": null, "term_id": ["COVID", "EEG", "survival", "challenges", "Patients", "fMRI", "MRI", "ray", "flow", "breast", "Blood", "chest", "Cardiac", "Cases", "connectivity", "Skin", "People", "PET", "work", "year", "stroke", "admission", "diagnosis", "brain", "segmentation", "learning", "patients", "consistency", "reconstruction", "imaging", "prediction", "UNet", "examination", "alpha", "machine learning", "Images", "learning approach", "approaches", "Deep Learning", "cancer", "study", "Impact", "Forecasting", "signal", "Detection", "Case", "Application", "machine", "images", "augmentation", "modelling", "Risk", "scale", "techniques", "risk", "benchmark", "Semi Supervised", "outcome", "Diffusion", "resonance", "blood", "transformer", "Denoising", "Multivariate", "measures", "component analysis", "component", "Calls", "Scenarios", "Extraction", "trajectory", "tool", "field", "analytics", "aggregation", "Smartphones", "fusion", "summarization", "Host", "screening", "labeling", "forecast", "Diagnosis", "approach", "Machine", "network", "data", "Events", "quantification", "methods", "Estimation", "transfer", "review", "Image", "Uncertainty", "Convolutions", "intelligence", "Process", "language model", "correlation", "Construction", "Acceleration", "Framework", "Auto", "classifier", "feature selection", "ell", "disease", "Validation", "LiDAR", "reliability", "value", "momentum", "rank", "studies", "body", "platform", "uncertainty", "resolution", "3D", "analysis", "Overview", "Step", "Explainability", "accuracy", "retrieval", "events", "predictions", "source", "stage", "Analysis", "Adaptation", "discovery", "Device", "Confidence", "health", "model", "selection", "Datasets", "Features", "comparison", "context", "Calibration", "support", "distribution", "Interpretability", "Cost", "AI", "performance", "Prediction", "Signals", "Classifiers", "recovery", "Dataset", "evaluation", "Loss Functions", "Representations", "processing", "Rates", "Design", "Rate", "Decision Making", "Search", "clustering", "channel", "physics", "decision", "state", "language", "design", "datasets", "modeling", "Approach", "Feature", "Systems", "application", "survey", "time", "models", "Transfer", "image", "Strategies", "Making", "representation", "framework", "Neural Networks", "identification", "Applications", "box", "Evaluation", "regression", "view", "recognition", "Depth"], "x_centroid": 2.1215725506053253, "y_centroid": 3.6334268934586467, "size": 255, "top_doc_id": null, "top_doc_content": ["Ten-year Survival Prediction for Breast Cancer Patients", "The Invisible COVID-19 Crisis: Post-Traumatic Stress Disorder Risk Among\n  Frontline Physicians Treating COVID-19 Patients", "A novel framework based on deep learning and ANOVA feature selection\n  method for diagnosis of COVID-19 cases from chest X-ray Images", "Automated segmentation on the entire cardiac cycle using a deep learning\n  work-flow", "Combining Graph Neural Networks and Spatio-temporal Disease Models to\n  Predict COVID-19 Cases in Germany", "COVIDX: Computer-aided diagnosis of Covid-19 and its severity prediction\n  with raw digital chest X-ray images", "Multi-modality fusion using canonical correlation analysis methods:\n  Application in breast cancer survival prediction from histology and genomics", "Automatic Monitoring Social Dynamics During Big Incidences: A Case Study\n  of COVID-19 in Bangladesh", "A Novel AI-enabled Framework to Diagnose Coronavirus COVID 19 using\n  Smartphone Embedded Sensors: Design Study", "Acceleration of cerebral blood flow and arterial transit time maps estimation from multiple post-labeling delay arterial spin-labeled MRI via deep learning", "Feature matching as improved transfer learning technique for wearable\n  EEG", "Improved low-count quantitative PET reconstruction with an iterative\n  neural network", "Localized adversarial artifacts for compressed sensing MRI", "Prediction of Blood Lactate Values in Critically Ill Patients: A\n  Retrospective Multi-center Cohort Study", "Adversarial Multi-Source Transfer Learning in Healthcare: Application to\n  Glucose Prediction for Diabetic People", "Extraction of hierarchical functional connectivity components in human\n  brain using resting-state fMRI", "Design of one-year mortality forecast at hospital admission based: a\n  machine learning approach", "AutoScore-Survival: Developing interpretable machine learning-based\n  time-to-event scores with right-censored survival data", "Causal inference for observational longitudinal studies using deep\n  survival models", "Decoding visual stimuli in human brain by using Anatomical Pattern\n  Analysis on fMRI images", "Calibrated Bagging Deep Learning for Image Semantic Segmentation: A Case\n  Study on COVID-19 Chest X-ray Image", "Deep learning for temporal data representation in electronic health\n  records: A systematic review of challenges and methodologies", "Localization and Control of Magnetic Suture Needles in Cluttered\n  Surgical Site with Blood and Tissue", "EsmamDS: A more diverse exceptional survival model mining approach", "Deep variational network for rapid 4D flow MRI reconstruction", "Simple 1-D Convolutional Networks for Resting-State fMRI Based\n  Classification in Autism", "Enhancing the Interpretability of Deep Models in Heathcare Through\n  Attention: Application to Glucose Forecasting for Diabetic People", "DeepHealth: Review and challenges of artificial intelligence in health\n  informatics", "Architectural configurations, atlas granularity and functional\n  connectivity with diagnostic value in Autism Spectrum Disorder", "COVID-Net US: A Tailored, Highly Efficient, Self-Attention Deep\n  Convolutional Neural Network Design for Detection of COVID-19 Patient Cases\n  from Point-of-care Ultrasound Imaging", "Deep Learning Analysis of Cardiac MRI in Legacy Datasets: Multi-Ethnic\n  Study of Atherosclerosis", "Process Mining Model to Predict Mortality in Paralytic Ileus Patients", "DDoS-UNet: Incorporating temporal information using Dynamic Dual-channel\n  UNet for enhancing super-resolution of dynamic MRI", "Large-Scale Screening of COVID-19 from Community Acquired Pneumonia\n  using Infection Size-Aware Classification", "An Evaluation of the EEG alpha-to-theta and theta-to-alpha band Ratios\n  as Indexes of Mental Workload", "Left Ventricle Segmentation and Volume Estimation on Cardiac MRI using\n  Deep Learning", "EEGsig: an open-source machine learning-based toolbox for EEG signal\n  processing", "Graph Neural Network for Interpreting Task-fMRI Biomarkers", "Large-scale benchmark study of survival prediction methods using\n  multi-omics data", "Transfer Learning with Ensembles of Deep Neural Networks for Skin Cancer\n  Detection in Imbalanced Data Sets", "Understanding Consumer Preferences for Movie Trailers from EEG using\n  Machine Learning", "Reproducible evaluation of classification methods in Alzheimer's\n  disease: framework and application to MRI and PET data", "Integration of a machine learning model into a decision support tool to\n  predict absenteeism at work of prospective employees", "Neural network based country wise risk prediction of COVID-19", "An amplitudes-perturbation data augmentation method in convolutional\n  neural networks for EEG decoding", "Detecting COVID-19 Conspiracy Theories with Transformers and TF-IDF", "DOSED: a deep learning approach to detect multiple sleep micro-events in\n  EEG signal", "Confidence Aware Neural Networks for Skin Cancer Detection", "Adaptation of a deep learning malignancy model from full-field digital\n  mammography to digital breast tomosynthesis", "EEG-based Emotional Video Classification via Learning Connectivity\n  Structure", "Deep regression for uncertainty-aware and interpretable analysis of\n  large-scale body MRI", "Assessing the Impact of COVID-19 on Trade: a Machine Learning\n  Counterfactual Analysis", "A review of machine learning approaches, challenges and prospects for computational tumor pathology"], "top_term_id": null, "convex_hull": {"x_coordinates": [1.5658398866653451, 1.499035082549214, 1.4269111442939177, 1.3547986477301783, 1.288028168688714, 1.2319302830002457, 1.1918355664954936, 1.1730745950051777, 1.1809829399357963, 1.2297846253431846, 1.3464127107685653, 1.4769613166374658, 1.6025782689411028, 1.7241000231021024, 1.84236303454309, 1.9582203864435457, 2.072939121440657, 2.18821854961352, 2.3057782725447935, 2.4273378918171367, 2.55360301884926, 2.6801876811457004, 2.801111213718487, 2.910392398080656, 3.0020500157452448, 3.0701028482252912, 3.1085707413028385, 3.1155837572942073, 3.101995013245616, 3.0769762211116176, 3.047789105701823, 3.016831454629938, 2.9812186136430596, 2.937800709369755, 2.8834445428974838, 2.815038501398795, 2.729472407198249, 2.620595457539798, 2.4875594238318337, 2.348354635344343, 2.222063674431159, 2.12772387886078, 2.0535590944870115, 1.9793636806421266, 1.9057178269292445, 1.8332017229514814, 1.7623955583119566, 1.6938795226137864, 1.6282338054600898, 1.5658398866653453], "y_coordinates": [3.809160947799683, 3.7039936565483544, 3.6002906430047417, 3.4961440125190815, 3.3896458704416017, 3.2788883221225373, 3.1619634729121193, 3.036963428160581, 2.9019962251162847, 2.783516968199971, 2.765074800634073, 2.765706674531334, 2.7572707259479126, 2.7474267556979353, 2.7438345645955313, 2.7539391716918953, 2.779838456138727, 2.81804667182481, 2.864815966033322, 2.916398486047439, 2.969867678016666, 3.0264210045210325, 3.0885475768989155, 3.1587369548047657, 3.239478697893038, 3.3332623658181864, 3.442576430024097, 3.5657066829037496, 3.6892323820782162, 3.8097332758512854, 3.928775645483363, 4.047275672193814, 4.16543020597199, 4.283319395784328, 4.3979170607090285, 4.5021756898529475, 4.588780413986551, 4.654236688738618, 4.699542570383793, 4.715415405539489, 4.691847421366487, 4.618883277633635, 4.520235339187769, 4.4215355150756395, 4.322441576782455, 4.222611295793427, 4.121702443593765, 4.0193727916686806, 3.9152801115033857, 3.809160947799684]}}, {"topic_id": "bt-3", "name": " Ranking and Predictions", "lemma_name": null, "term_id": ["Ranking", "Rank", "Predictions", "market", "style", "Prediction", "decision", "Need", "failure", "Bayes", "safety", "Comparing", "Mining", "Controllers", "loop", "Remedies", "guarantees", "uncertainties", "Tricks", "Package", "road", "experimentation", "experts", "experiments", "Shift", "loss", "Examples", "algorithms", "design", "review", "Environments", "System", "Strategies", "Making", "Class", "drift", "Demonstrations", "Needs", "solutions", "event", "verification", "programming", "user", "Max", "Time", "reliability", "Teaching", "Perception", "test", "Implementation", "results", "Problems", "Enhancement", "cancer", "retrieval", "path", "E", "stage", "Adaptation", "Device", "performance", "Calibration", "support", "feedback", "Effects", "Experiments", "software", "brain", "scale", "Methods", "Losses", "evaluation", "Dynamics", "techniques", "Domain", "classifiers", "Decision", "Decision Making", "distributions", "generation", "approaches", "framework", "Errors", "Processing", "representations", "language", "Challenges", "case", "Approach", "time", "Approximation", "uncertainty", "functions", "Systems", "Web", "training", "system", "control", "Network", "Attention", "Constraints", "information", "prediction", "analysis", "Study", "Performance", "Transformers", "Uncertainty", "systems", "graph", "network", "Guarantees", "inference", "Modeling", "machine learning", "Models", "Deep Learning", "machine", "Machine Learning"], "x_centroid": 7.770889171182293, "y_centroid": 3.730543504566907, "size": 219, "top_doc_id": null, "top_doc_content": ["Rare event failure test case generation in Learning-Enabled-Controllers", "Scaling up Ranking under Constraints for Live Recommendations by\n  Replacing Optimization with Prediction", "Comparing decision mining approaches with regard to the meaningfulness\n  of their results", "Which Tricks are Important for Learning to Rank?", "Competition analysis on the over-the-counter credit default swap market", "Multi-stage Ensemble Model for Cross-market Recommendation", "MCU-Net: A framework towards uncertainty representations for decision\n  support system patient referrals in healthcare contexts", "Learning-Based sensitivity analysis and feedback design for drug delivery of mixed therapy of cancer in the presence of high model uncertainties", "ColO-RAN: Developing Machine Learning-based xApps for Open RAN\n  Closed-loop Control on Programmable Experimental Platforms", "Towards Non-Parametric Learning to Rank", "How much data is sufficient to learn high-performing algorithms?\n  Generalization guarantees for data-driven algorithm design", "All your loss are belong to Bayes", "Reducing Overconfidence Predictions for Autonomous Driving Perception", "Hybrid Style Siamese Network: Incorporating style loss in complementary\n  apparels retrieval", "Advances in Collaborative Filtering and Ranking", "Towards Automated Neural Interaction Discovery for Click-Through Rate\n  Prediction", "A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and\n  Remedies", "Predict and Optimize: Through the Lens of Learning to Rank", "Learning to Rank under Multinomial Logit Choice", "Need is All You Need: Homeostatic Neural Networks Adapt to Concept Shift", "A Batch Learning Framework for Scalable Personalized Ranking", "Customizing ML Predictions for Online Algorithms", "Dance Hit Song Prediction", "Testing and verification of neural-network-based safety-critical control\n  software: A systematic literature review", "Multi-objective Ranking via Constrained Optimization", "Mining Fashion Outfit Composition Using An End-to-End Deep Learning\n  Approach on Set Data", "Thought Flow Nets: From Single Predictions to Trains of Model Thought", "Distilled Neural Networks for Efficient Learning to Rank", "Supporting stylists by recommending fashion style", "Breaking Type Safety in Go: An Empirical Study on the Usage of the\n  unsafe Package", "Online Adaptation of Neural Network Models by Modified Extended Kalman\n  Filter for Customizable and Transferable Driving Behavior Prediction", "Fair Wrapping for Black-box Predictions", "How to \"Improve\" Prediction Using Behavior Modification"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.301483154296873, 8.409385664627258, 8.500116766183924, 8.572825959225572, 8.626662744010904, 8.660776744265672, 8.675581048901043, 8.675862752667074, 8.667354825752211, 8.655788378367719, 8.64473248395064, 8.631424704332675, 8.611949641162145, 8.582391896087369, 8.538836070756675, 8.477366766940348, 8.396270112368075, 8.302537821738813, 8.20444540770099, 8.100399244152166, 7.9845303753654076, 7.863650595296458, 7.749625286269675, 7.651007628052569, 7.5626996359893734, 7.476344790121237, 7.389064879050759, 7.303378272914146, 7.221750325161242, 7.1450136864142655, 7.07341352383526, 7.00719422928396, 6.9466001946200935, 6.891875811703393, 6.844134983415855, 6.8227866303822475, 6.860324034135732, 6.953381021900434, 7.080178481143626, 7.218796831786991, 7.3491968076073695, 7.466772186030066, 7.574484405980466, 7.675346986403245, 7.77237344624308, 7.868577304444647, 7.96697207995263, 8.070571291711696, 8.18238845866653, 8.301483154296873], "y_coordinates": [2.601454257965088, 2.6252095618494353, 2.7054859097948256, 2.8244148504958715, 2.964127932647185, 3.1067571335662105, 3.2388206210811363, 3.3620211704997387, 3.481345216956808, 3.601777656399772, 3.7265142339620225, 3.853511177448705, 3.9797706052459088, 4.10229463573972, 4.218085387316228, 4.324144978400867, 4.418185784287609, 4.500728778966759, 4.573365305493792, 4.641965685287121, 4.711417360064549, 4.762888627817158, 4.768151897932039, 4.709465122892206, 4.612235202884748, 4.511987301111159, 4.422869193483353, 4.337970184463224, 4.250298244947649, 4.157559931975185, 4.0591524603070965, 3.9544752758667743, 3.8429278245776133, 3.7239095523630064, 3.597403130649199, 3.4756626347313673, 3.380053273317519, 3.3107255453750732, 3.256909230758616, 3.2077507979867823, 3.15337205023179, 3.091900040554997, 3.0253872318568353, 2.9559131013829405, 2.885557126378951, 2.816398784090501, 2.7505175517632297, 2.689992906642772, 2.636904325974766, 2.601454257965088]}}, {"topic_id": "bt-4", "name": " Physics Simulations and Inverses", "lemma_name": null, "term_id": ["Physics", "inverse", "simulations", "monitoring", "inverse problems", "dynamics", "Inverse", "life", "radiative transfer", "radiative", "soil", "waves", "wind", "wind turbine", "battery", "Stage", "turbine", "building", "fly", "forecasts", "physics", "transfer", "problems", "machine", "temperature", "learning framework", "world", "Inverse Problems", "plasticity", "time", "approach", "bike", "health", "quantification", "framework", "time series", "networks", "accuracy", "separation", "predictions", "fields", "uncertainty quantification", "flows", "Prediction", "Deep Learning", "state", "design", "series", "uncertainty", "step", "extraction", "network", "machine learning", "system", "series data", "search", "magnets", "Meshes", "series classification", "Distillation", "electron", "Denoising", "basis", "safety", "operators", "chemical", "Machines", "detector", "causes", "pixel", "Samples", "conditions", "trade", "Activities", "alignment", "spectrum", "ultrasound", "wavelet", "water", "2D", "road", "simulation", "Tracking", "learning algorithms", "signals", "scheduling", "Diagnosis", "experimentation", "implications", "analysis", "term", "distributions", "Events", "properties", "reduction", "domain", "Self", "review", "learning", "predictor", "types", "Convolutions", "correlation", "management", "material", "Sensors", "encoding", "data analysis", "Geometry", "consistency", "adaptation", "reconstruction", "image classification", "Monte Carlo", "reliability", "operator", "vision", "machine vision", "resolution", "application", "System", "prediction", "Problems", "systems", "detection", "Theory", "class", "Overview", "structure", "activation", "similarity", "path", "Forecasting", "Noisy Labels", "production", "Detection", "edge", "science", "Correlation", "validation", "target", "multi", "Modelling", "discovery", "flow", "Machine Learning", "data", "Machine", "Tree", "constraints", "transport", "diagnosis", "augmentation", "AI", "modelling", "Features", "Study", "Flows", "task", "Approach", "dataset", "recovery", "Dataset", "Representations", "Units", "classifiers", "Design", "Decision Making", "Images", "Inference", "GAN", "clustering", "channel", "learning approach", "algorithms", "Challenges", "case", "modeling", "Modeling", "level", "features", "generalization", "Environments", "functions", "Systems", "equations", "Identification", "survey", "models", "order", "image", "Network", "Making", "Models"], "x_centroid": 4.045854928900167, "y_centroid": 3.9690073214247077, "size": 299, "top_doc_id": null, "top_doc_content": ["Dictionary learning approach to monitoring of wind turbine drivetrain\n  bearings", "Inverse design optimization framework via a two-step deep learning\n  approach: application to a wind turbine airfoil", "Generative networks as inverse problems with Scattering transforms", "Anomalous phase separation dynamics in a correlated electron system:\n  machine-learning enabled large-scale kinetic Monte Carlo simulations", "Task adapted reconstruction for inverse problems", "Inference over radiative transfer models using variational and\n  expectation maximization methods", "Predicting atmospheric optical properties for radiative transfer\n  computations using neural networks", "Solving inverse problems using conditional invertible neural networks", "Physics guided neural networks for modelling of non-linear dynamics", "Random mesh projectors for inverse problems", "Physics-informed neural networks for improving cerebral hemodynamics\n  predictions", "Remaining useful life prediction with uncertainty quantification:\n  development of a highly accurate model for rotating machinery", "Online structural health monitoring by model order reduction and deep\n  learning algorithms", "Multifidelity deep neural operators for efficient learning of partial\n  differential equations with application to fast inverse design of nanoscale\n  heat transport", "A Two-Stage Stochastic Programming Model for Car-Sharing Problem using\n  Kernel Density Estimation", "CFDNet: a deep learning-based accelerator for fluid simulations", "On statistic alignment for domain adaptation in structural health\n  monitoring", "Reshaping Smart Energy Transition: An analysis of human-building\n  interactions in Qatar Using Machine Learning Techniques", "Detection of gravitational waves using topological data analysis and\n  convolutional neural network: An improved approach", "Physics-informed neural network for ultrasound nondestructive\n  quantification of surface breaking cracks", "On-the-fly Prediction of Protein Hydration Densities and Free Energies\n  using Deep Learning", "An artificial neural network approach to bifurcating phenomena in\n  computational fluid dynamics", "Revisiting the dynamics of Bose-Einstein condensates in a double well by\n  deep learning with a hybrid network", "Novel Deep neural networks for solving Bayesian statistical inverse", "Combining SchNet and SHARC: The SchNarc machine learning approach for\n  excited-state dynamics", "Solving Inverse Problems in Medical Imaging with Score-Based Generative\n  Models", "Physics-Driven Deep Learning for Computational Magnetic Resonance\n  Imaging", "Automated analysis of continuum fields from atomistic simulations using statistical machine learning", "Physics perception in sloshing scenes with guaranteed thermodynamic\n  consistency", "Global soil moisture from in-situ measurements using machine learning --\n  SoMo.ml", "Geometry encoding for numerical simulations", "Optimising simulations for diphoton production at hadron colliders using\n  amplitude neural networks", "Hardware-accelerated Mars Sample Localization via deep transfer learning from photorealistic simulations", "Autonomous discovery of battery electrolytes with robotic\n  experimentation and machine-learning", "Assessing out-of-domain generalization for robust building damage\n  detection", "Revisiting Classical Bagging with Modern Transfer Learning for\n  On-the-fly Disaster Damage Detector", "Attractive versus truncated repulsive supercooled liquids: The dynamics\n  is encoded in the pair correlation function", "Using solar and load predictions in battery scheduling at the\n  residential level", "System-reliability based multi-ensemble of GAN and one-class joint\n  Gaussian distributions for unsupervised real-time structural health\n  monitoring", "A Machine Learning Framework for Real-time Inverse Modeling and\n  Multi-objective Process Optimization of Composites for Active Manufacturing\n  Control", "Physics-informed neural networks for modeling rate- and\n  temperature-dependent plasticity", "Depth separation for reduced deep networks in nonlinear model reduction:\n  Distilling shock waves in nonlinear hyperbolic problems", "Improved prediction of soil properties with Multi-target Stacked\n  Generalisation on EDXRF spectra", "Inverse Problems Leveraging Pre-trained Contrastive Representations", "Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without\n  Matched Training Data", "Deep learning to discover and predict dynamics on an inertial manifold", "A weakly supervised framework for high-resolution crop yield forecasts", "Second-life Lithium-ion batteries: A chemistry-agnostic and scalable\n  health estimation algorithm", "Increasing the accuracy and resolution of precipitation forecasts using\n  deep generative models"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.01585865020752, 3.897425416376758, 3.768952616844619, 3.6357341861455104, 3.5030640588138415, 3.376236169384021, 3.2605444523904588, 3.161282842367562, 3.0837452738497406, 3.0332256813714022, 3.012839922535478, 3.016351644845013, 3.035014890138448, 3.0600836694276645, 3.082811993724541, 3.094921065618219, 3.101208272802751, 3.1209902824755007, 3.1740308165994287, 3.2615353306081243, 3.359994634392198, 3.4629622310937425, 3.569894276672206, 3.6802481812552372, 3.793481354970483, 3.909630533273472, 4.032413526648759, 4.1618188370215705, 4.292181606025084, 4.417563614545516, 4.53202664346908, 4.629632473681988, 4.704595794642691, 4.756975222375039, 4.794363265909509, 4.8248501870335705, 4.8565262475346875, 4.893751576048935, 4.900610716481923, 4.859569021930667, 4.797730238449536, 4.725852183061646, 4.64930755248673, 4.571917933100102, 4.49185106718492, 4.407437188530231, 4.31825025812032, 4.223843152084062, 4.123379536617744, 4.01585865020752], "y_coordinates": [4.951539039611816, 4.909090567514623, 4.871253430152408, 4.835325091040315, 4.79860301369349, 4.758384661627076, 4.711967498356221, 4.656648987396066, 4.5897265922617585, 4.508497776468442, 4.4112181185000034, 4.3002571435784, 4.179088328176415, 4.051185162327135, 3.9200211360636463, 3.7891099179295065, 3.6630897293619977, 3.547847450917961, 3.4492005590510786, 3.3649087247128766, 3.2834031871016514, 3.207312242221438, 3.143878390772882, 3.1003451138613722, 3.0839558925922943, 3.0979893413877666, 3.1198488026501248, 3.134940111314896, 3.148758640830325, 3.1677719543056173, 3.1984476148499787, 3.2472531855726157, 3.3204963896033606, 3.4183761159629387, 3.5332158462626495, 3.6568187460239563, 3.7809879807683204, 3.898635111338482, 4.014677083353396, 4.129602059085184, 4.233393891968009, 4.3283735161161685, 4.420580423553207, 4.51284512942262, 4.596916750743537, 4.675372322082741, 4.762113408888275, 4.864638729552269, 4.946027783693695, 4.951539039611816]}}, {"topic_id": "bt-5", "name": " Quantum Tensor Clustering", "lemma_name": null, "term_id": ["quantum", "Tensor", "Clustering", "matrix", "completion", "Quantum", "tensor", "clustering", "Boltzmann", "factorization", "states", "Approximation", "clusters", "Sensing", "degree", "sparse", "computer", "sparsity", "Correlation", "norm", "Sparsity", "decomposition", "matrices", "software", "method", "view", "Thresholding", "recovery", "complexity", "shrinkage", "Semi Supervised", "Diffusion", "series classification", "architecture", "k", "RNA", "grid", "rates", "Consistency", "length", "parameterization", "Sketching", "tools", "spectrum", "Noise", "gene expression", "Values", "Package", "Padding", "Video", "Product", "experiments", "Algorithms", "model", "Information", "application", "Interactions", "dimensionality reduction", "kernels", "Kernels", "power", "gene", "solutions", "Construction", "Directions", "quality", "Distributions", "dimension", "Insights", "Max", "Distance", "Characterization", "Priors", "value", "computing", "rank", "body", "Guarantees", "noise", "Constraints", "block", "Impact", "similarity", "separation", "source", "sample", "fields", "Federated", "validation", "t", "spaces", "vectors", "description", "discovery", "differentiation", "Confidence", "Scale", "approach", "Application", "distance", "ODEs", "Markov", "context", "constraints", "Embeddings", "Communication", "size", "Error", "dimensionality", "data", "knowledge", "classifiers", "Design", "feature", "Rate", "distributions", "Wasserstein", "reduction", "Errors", "Processing", "theory", "algorithms", "representations", "embeddings", "Challenges", "datasets", "equations", "problem", "order", "class", "Transfer", "image", "system", "representation", "Problems", "Applications", "regression", "information", "Datasets", "Machine", "time series", "performance", "applications", "Performance", "series", "classification", "analysis", "dynamics", "loss", "systems", "Methods", "inference"], "x_centroid": 4.5809706328278885, "y_centroid": 7.036658329478765, "size": 236, "top_doc_id": null, "top_doc_content": ["Neural tensor contractions and the expressive power of deep neural\n  quantum states", "Exact nuclear norm, completion and decomposition for random overcomplete\n  tensors via degree-4 SOS", "Consistency of regularized spectral clustering in degree-corrected mixed\n  membership model", "Construction of the similarity matrix for the spectral clustering\n  method: numerical experiments", "Improving application performance with biased distributions of quantum\n  states", "Clustering using Max-norm Constrained Optimization", "Sum-of-squares meets square loss: Fast rates for agnostic tensor\n  completion", "Training a quantum annealing based restricted Boltzmann machine on\n  cybersecurity data", "Nonlinear regression based on a hybrid quantum computer", "A Riemannian gossip approach to decentralized matrix completion", "Quantum noise protects quantum classifiers against adversaries", "Bayesian machine learning for Boltzmann machine in quantum-enhanced\n  feature spaces", "Deterministic tensor completion with hypergraph expanders", "Simulating a perceptron on a quantum computer", "Non-negative matrix factorization with sparseness constraints", "A Classification-Based Approach to Semi-Supervised Clustering with\n  Pairwise Constraints", "An efficient high-quality hierarchical clustering algorithm for\n  automatic inference of software architecture from the source code of a\n  software system", "Quantum classification", "Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field\n  Approximation", "Tensor network to learn the wavefunction of data", "Optimal Sketching for Kronecker Product Regression and Low Rank\n  Approximation", "Application of quantum computing to a linear non-Gaussian acyclic model\n  for novel medical knowledge discovery", "Relaxed Oracles for Semi-Supervised Clustering", "Off-the-grid: Fast and Effective Hyperparameter Search for Kernel\n  Clustering", "An Analytic Solution to the Inverse Ising Problem in the Tree-reweighted\n  Approximation", "A description length approach to determining the number of k-means\n  clusters", "Robust Correlation Clustering with Asymmetric Noise", "Using the left Gram matrix to cluster high dimensional data", "Local Correlation Clustering with Asymmetric Classification Errors", "Learning quantum dynamics with latent neural ODEs", "Finding sparse solutions of systems of polynomial equations via\n  group-sparsity optimization", "PennyLane: Automatic differentiation of hybrid quantum-classical\n  computations", "Tensor-networks for High-order Polynomial Approximation: A Many-body\n  Physics Perspective", "Towards a theory of quantum gravity from neural networks", "Group-sparse Matrix Recovery", "A Data-Driven Compressive Sensing Framework Tailored For\n  Energy-Efficient Wearable Sensing", "On the optimality of kernels for high-dimensional clustering", "A theoretical contribution to the fast implementation of null linear\n  discriminant analysis method using random matrix multiplication with scatter\n  matrices", "Sparse Inverse Covariance Matrix Estimation Using Quadratic\n  Approximation", "Transfer learning in hybrid classical-quantum neural networks", "Scalable Hierarchical Clustering with Tree Grafting", "Personalised novel and explainable matrix factorisation", "Optimal Clustering from Noisy Binary Feedback", "Quantum Finite Automata and Quiver Algebras", "Impact of the Sensing Spectrum on Signal Recovery in Generalized Linear\n  Models", "Tensor Laplacian Regularized Low-Rank Representation for Non-uniformly\n  Distributed Data Subspace Clustering", "Contrastive Multi-view Hyperbolic Hierarchical Clustering", "Densifying Assumed-sparse Tensors: Improving Memory Efficiency and MPI\n  Collective Performance during Tensor Accumulation for Parallelized Training\n  of Neural Machine Translation Models", "Low-Rank Tucker Approximation of a Tensor From Streaming Data", "Markov random fields factorization with context-specific independences", "Recover the spectrum of covariance matrix: a non-asymptotic iterative\n  method", "Semisupervised Clustering by Queries and Locally Encodable Source Coding", "Tensor-on-Tensor Regression: Riemannian Optimization, Over-parameterization, Statistical-computational Gap, and Their Interplay", "Semi-supervised model-based clustering with controlled clusters leakage", "Confidence-constrained joint sparsity recovery under the Poisson noise\n  model", "A Quantum-inspired Algorithm for General Minimum Conical Hull Problems", "Semi-supervised time series classification method for quantum computing", "Noise fingerprints in quantum computers: Machine learning software tools", "Bayesian sparse convex clustering via global-local shrinkage priors", "Unsupervised Fuzzy eIX: Evolving Internal-eXternal Fuzzy Clustering", "Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix"], "top_term_id": null, "convex_hull": {"x_coordinates": [3.502874374389648, 3.3900995859352814, 3.315113457614954, 3.2742886517377237, 3.263997830612649, 3.2806136565487916, 3.3205087918552074, 3.3800558988409586, 3.4556276398151025, 3.5435966770866996, 3.640335672964807, 3.7422172897584858, 3.8456238844417343, 3.9485197420920906, 4.0521904470506005, 4.158340386507252, 4.268787978020735, 4.387963670148606, 4.521262960233828, 4.660961437573726, 4.791983367609297, 4.8991469634321865, 4.977259647963118, 5.036966685728665, 5.090318036521469, 5.14936366013418, 5.226153516359439, 5.328598508857459, 5.4454534010498, 5.559935004383747, 5.65525958022331, 5.714643389932497, 5.721302694875319, 5.658494180813404, 5.528291682455265, 5.378909042387917, 5.233301051607286, 5.091444676584794, 4.952851600477121, 4.817033506440954, 4.6835020776329745, 4.551768997209865, 4.42134594832831, 4.291744614144991, 4.162476677816595, 4.0330538224998, 3.902987731351293, 3.7717900875277537, 3.6389318018307324, 3.502874374389648], "y_coordinates": [8.023301124572756, 7.978980772952077, 7.899791561908951, 7.791274572704183, 7.658970886598584, 7.508421584852967, 7.345167748728142, 7.1747504594849225, 7.002710798384119, 6.834589846686542, 6.675928685653, 6.532268396544309, 6.409125217702973, 6.307961641325042, 6.221729213969692, 6.142306285233976, 6.062353586447361, 5.992453437383405, 5.960055799003133, 5.9779032523590026, 6.035176252181252, 6.117945875989066, 6.216682864553006, 6.328833602451962, 6.452463160451946, 6.585636609318975, 6.726419019819059, 6.872373504011965, 7.018740037700474, 7.160086988688026, 7.290982658067422, 7.405995346931456, 7.4996933563729264, 7.566658134146548, 7.60759076639348, 7.638225868086481, 7.666445492783938, 7.692910803214337, 7.718136744607766, 7.742638262194314, 7.766930301204059, 7.791527806867095, 7.816945724413506, 7.843698999073373, 7.872302576076788, 7.903271400653834, 7.9371204180346, 7.974364573449165, 8.014683426530368, 8.023301124572754]}}, {"topic_id": "bt-6", "name": " Optimization with Gradient Descent and Stochastic Methods", "lemma_name": null, "term_id": ["optimization", "gradient", "stochastic", "Optimization", "Bounds", "Step", "Dimensions", "convex", "Newton", "Concentration", "descent", "size", "Results", "Stochastic", "difference", "filtering", "Stability", "Risk Bounds", "stochastic gradient", "Monte Carlo", "momentum", "box", "Convergence", "error", "Methods", "function", "SGD", "sample", "parameter", "Points", "methods", "step", "Communication", "convergence", "Applications", "batch", "Regression", "rule", "benchmarking", "shrinkage", "planning", "factor", "Langevin", "Bayes", "Critics", "operators", "optics", "Comments", "optimisation", "placement", "Conditions", "infty", "trade", "alignment", "inequalities", "estimators", "gradient method", "variance", "uniform", "function approximation", "Output", "MLPs", "State", "law", "Trajectory", "Functionals", "set", "activation function", "Forests", "applications", "Risk", "Rate", "approximation", "theory", "Learning", "Programming", "weight", "solutions", "entropy", "Acceleration", "environments", "Sketches", "Distributions", "Alternative", "Max", "causal", "bounds", "operator", "testing", "Application", "inference", "order", "regression", "activation", "Fairness", "edge", "Distribution", "Effect", "validation", "topology", "Adaptation", "type", "bias", "Scale", "Problems", "method", "Tuning", "constraints", "processes", "multivariate", "estimation", "Processes", "Losses", "Thresholding", "Dynamics", "complexity", "Loss Functions", "Rates", "Design", "Point", "systems", "Guarantees", "Search", "Gradients", "Predictions", "CUR", "sparse", "Algorithms", "process", "Self", "ReLU", "case", "modeling", "Features", "Approximation", "Environments", "functions", "Systems", "System", "survey", "problem", "class", "control", "matrix", "Network", "approach", "noise", "selection", "Study", "problems", "performance", "Clustering", "loss", "scale"], "x_centroid": 7.2386618891069965, "y_centroid": 5.93428055787172, "size": 279, "top_doc_id": null, "top_doc_content": ["Momentum-based variance-reduced proximal stochastic gradient method for\n  composite nonconvex stochastic optimization", "An adaptive stochastic gradient-free approach for high-dimensional\n  blackbox optimization", "TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic\n  Meta-descent", "Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast\n  Convergence", "Random gradient extrapolation for distributed and stochastic\n  optimization", "Stability and Deviation Optimal Risk Bounds with Convergence Rate\n  $O(1/n)$", "A Riemannian smoothing steepest descent method for non-Lipschitz\n  optimization on submanifolds", "Risk Bounds for Infinitely Divisible Distribution", "Optimizing Optimizers: Regret-optimal gradient descent algorithms", "Inexact Proximal Gradient Methods for Non-convex and Non-smooth\n  Optimization", "Concentration bounds for temporal difference learning with linear\n  function approximation: The case of batch data and uniform sampling", "Optimized conformal classification using gradient descent approximation", "On the One-sided Convergence of Adam-type Algorithms in Non-convex\n  Non-concave Min-max Optimization", "Exponential convergence of testing error for stochastic gradient methods", "Olympus: a benchmarking framework for noisy optimization and experiment\n  planning", "Backpropagation through the Void: Optimizing control variates for\n  black-box gradient estimation", "A General Descent Aggregation Framework for Gradient-based Bi-level\n  Optimization", "Cross-Entropy Method Variants for Optimization", "Langevin-gradient parallel tempering for Bayesian neural learning", "Thinking inside the box: A tutorial on grey-box Bayesian optimization", "Modified swarm-based metaheuristics enhance Gradient Descent\n  initialization performance: Application for EEG spatial filtering", "Distributed Averaging Methods for Randomized Second Order Optimization", "Rate-Distortion Theoretic Bounds on Generalization Error for Distributed\n  Learning", "Stability and Convergence Trade-off of Iterative Optimization Algorithms", "Efficient Batch Black-box Optimization with Deterministic Regret Bounds", "Trajectory of Mini-Batch Momentum: Batch Size Saturation and Convergence in High Dimensions", "Asynchronous Iterations in Optimization: New Sequence Results and\n  Sharper Algorithmic Guarantees", "Concentration of the matrix-valued minimum mean-square error in optimal\n  Bayesian inference", "Estimating Normalizing Constants for Log-Concave Distributions:\n  Algorithms and Lower Bounds", "Constant Step Size Stochastic Gradient Descent for Probabilistic\n  Modeling", "Use of low-fidelity models with machine-learning error correction for\n  well placement optimization", "Decentralized gradient methods: does topology matter?", "Stochastic Gradient Descent with Nonlinear Conjugate Gradient-Style\n  Adaptive Momentum", "Learning theory estimates with observations from general stationary\n  stochastic processes", "Optimal Convergence Rate of Hamiltonian Monte Carlo for Strongly\n  Logconcave Distributions", "Communication trade-offs for synchronized distributed SGD with large\n  step size", "Online linear optimization with the log-determinant regularizer", "A sparse semismooth Newton based proximal majorization-minimization\n  algorithm for nonconvex square-root-loss regression problems", "Why resampling outperforms reweighting for correcting sampling bias with\n  stochastic gradients", "Shannon Entropy Estimation in $\\infty$-Alphabets from Convergence\n  Results", "Robust Optimisation Monte Carlo", "State estimation under non-Gaussian Levy noise: A modified Kalman\n  filtering method", "A survey on multi-objective hyperparameter optimization algorithms for\n  Machine Learning", "Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient\n  Methods", "Pathfinder: Parallel quasi-Newton variational inference", "SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs", "Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions", "A globally convergent fast iterative shrinkage-thresholding algorithm with a new momentum factor for single and multi-objective convex optimization", "Beyond Application End-Point Results: Quantifying Statistical Robustness\n  of MCMC Accelerators", "Stochastic Zeroth Order Gradient and Hessian Estimators: Variance\n  Reduction and Refined Bias Bounds", "Lower Bounds for Parallel and Randomized Convex Optimization", "GIANT: Globally Improved Approximate Newton Method for Distributed\n  Optimization", "Optimization on the Surface of the (Hyper)-Sphere", "On the Generalization of Models Trained with SGD: Information-Theoretic\n  Bounds and Implications", "Stochastic Online Shortest Path Routing: The Value of Feedback", "Surrogate modeling for Bayesian optimization beyond a single Gaussian\n  process", "Effect of barren plateaus on gradient-free optimization"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.152063369750977, 8.162447103585283, 8.161063165303158, 8.148223184235357, 8.12423878971264, 8.089421611065761, 8.044083277625482, 7.988535418722557, 7.923089663687743, 7.848057641851796, 7.763750982545475, 7.67048131509954, 7.554892265870279, 7.42921005200384, 7.307273112390167, 7.189270768092247, 7.075392340173067, 6.965827149695616, 6.860764517722876, 6.761956468772602, 6.69554360815505, 6.659469868079838, 6.637499110598228, 6.613416579856491, 6.5780214419060625, 6.5392028447123876, 6.506368968090548, 6.4694060104242626, 6.418191522792915, 6.392598718851757, 6.436923770721251, 6.546401675004141, 6.687144821579035, 6.826520897468984, 6.952998503011858, 7.0697014682858255, 7.180049252848159, 7.287461316256133, 7.395357118067019, 7.507156117838094, 7.6262777751266295, 7.7544478181227605, 7.868830540918936, 7.951448983734898, 8.008741621867374, 8.048247718344438, 8.077506536194159, 8.104017807371505, 8.130759264339664, 8.152063369750977], "y_coordinates": [5.818847179412841, 5.939876784585858, 6.06325994984308, 6.188041282049779, 6.313265388071224, 6.437976874772685, 6.5612203490194325, 6.682040417676736, 6.799481687609863, 6.912588765684086, 7.020406258764672, 7.121978773716895, 7.149257745417617, 7.117172726125058, 7.077438580370718, 7.030070574438614, 6.975083974612767, 6.912494047177197, 6.842316058415918, 6.7636853959662355, 6.66228913508532, 6.540533170208617, 6.408961573093222, 6.27810666365562, 6.154645831211423, 6.0358636182297385, 5.917540742309155, 5.793568955688367, 5.662823979584429, 5.543510830910497, 5.455225245208593, 5.395604951571082, 5.349253454379422, 5.301401311785825, 5.2475630034136564, 5.190395506916704, 5.132699880458555, 5.0772771822027964, 5.026928470313016, 4.984454802952803, 4.9526572382857434, 4.935762834257348, 4.958378721307833, 5.0340405656951965, 5.148687626932541, 5.287021570981931, 5.433744063805422, 5.573626114926474, 5.699371014092276, 5.818847179412841]}}, {"topic_id": "bt-7", "name": " Unsupervised Learning", "lemma_name": null, "term_id": ["Transformers", "VAEs", "modal", "Attention", "Taxonomy", "Generation", "Transformer", "sequence", "Modality", "adaptation", "Captioning", "LSTMs", "Tasks", "Domain", "Classification", "term", "domain", "search", "States", "autoencoder", "Cross Modal", "architecture", "seq2seq", "Bases", "recipe", "variation", "Annotations", "Variance", "Dependencies", "Padding", "Trajectories", "Sequences", "art", "VAE", "Video", "experts", "Networks", "features", "segmentation", "Identification", "image", "representation", "power", "types", "weight", "tuning", "encoding", "Memory", "Nets", "feature extraction", "line", "representation learning", "Priors", "Lessons", "vision", "machine vision", "recognition", "framework", "style", "Node Classification", "Sequence", "interaction", "self", "Text", "Effect", "target", "Adaptation", "type", "Confidence", "Generalization", "extraction", "Graph", "Interpretability", "robot", "Model", "Exploration", "feature", "dataset", "Translation", "Dataset", "Representations", "attention", "properties", "text", "generation", "Data", "Rank", "state", "Estimation", "theory", "simulations", "Learning", "language", "Prediction", "generalization", "Information", "survey", "order", "class", "Transfer", "Network", "Neural Networks", "Applications", "view", "Depth", "CNNs", "Scale", "applications", "End", "estimation", "Application", "network", "models", "Modeling", "Survey", "CUR", "model", "Deep Learning", "Problems", "machine"], "x_centroid": 4.30629681280531, "y_centroid": 2.3229571066238806, "size": 227, "top_doc_id": null, "top_doc_content": ["On the Latent Holes of VAEs for Text Generation", "Semi-supervised representation learning via dual autoencoders for domain\n  adaptation", "Dispersed Exponential Family Mixture VAEs for Interpretable Text\n  Generation", "Learning transferable and discriminative features for unsupervised\n  domain adaptation", "Recurrent autoencoder with sequence-aware encoding", "Attention Interpretability Across NLP Tasks", "Transformer-based Automatic Post-Editing with a Context-Aware Encoding\n  Approach for Multi-Source Inputs", "OptiGAN: Generative Adversarial Networks for Goal Optimized Sequence\n  Generation", "Addressing Some Limitations of Transformers with Feedback Memory", "Implicit Deep Latent Variable Models for Text Generation", "MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal\n  Retrieval", "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks", "Improving Deep Learning for HAR with shallow LSTMs", "Adding Quaternion Representations to Attention Networks for\n  Classification", "RealFormer: Transformer Likes Residual Attention", "Mixture-of-experts VAEs can disregard variation in surjective multimodal\n  data", "Taxonomy of Saliency Metrics for Channel Pruning", "Attention mechanisms and deep learning for machine vision: A survey of\n  the state of the art", "Saturated Transformers are Constant-Depth Threshold Circuits", "Multi-view Deep One-class Classification: A Systematic Exploration", "ENCONTER: Entity Constrained Progressive Sequence Generation via\n  Insertion-based Transformer", "MART: Memory-Augmented Recurrent Transformer for Coherent Video\n  Paragraph Captioning", "Domain Adaptation with Adversarial Training and Graph Embeddings", "The Use of Video Captioning for Fostering Physical Activity", "Increasing the Generalisation Capacity of Conditional VAEs", "Attending to Mathematical Language with Transformers", "Extreme Compression for Pre-trained Transformers Made Simple and Efficient", "The Neural Data Router: Adaptive Control Flow in Transformers Improves\n  Systematic Generalization", "Maximum Likelihood Estimation for Multimodal Learning with Missing\n  Modality", "Simplified Long Short-term Memory Recurrent Neural Networks: part III", "Sequentially Generated Instance-Dependent Image Representations for\n  Classification", "Attention-based Image Upsampling", "Efficient Urdu Caption Generation using Attention based LSTM", "The Monte Carlo Transformer: a stochastic self-attention model for\n  sequence prediction", "SqueezeNAS: Fast neural architecture search for faster semantic\n  segmentation", "Latent-Variable Generative Models for Data-Efficient Text Classification", "Transfer Reward Learning for Policy Gradient-Based Text Generation", "A Taxonomy for Neural Memory Networks", "Adversarially trained LSTMs on reduced order models of urban air\n  pollution simulations", "Unsupervised Generative Modeling Using Matrix Product States", "Modality-dependent Cross-media Retrieval", "Simple to Complex Cross-modal Learning to Rank", "Adaptive Attention Span in Transformers", "Domain Adaptation on Graphs by Learning Aligned Graph Bases", "Towards Non-saturating Recurrent Units for Modelling Long-term\n  Dependencies", "Quantifying Attention Flow in Transformers", "Online Multi-modal Person Search in Videos", "Owl and Lizard: Patterns of Head Pose and Eye Pose in Driver Gaze\n  Classification"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.694233417510986, 4.587907047625707, 4.482894483620373, 4.378189296832831, 4.272276932502357, 4.163642835868216, 4.05077245216968, 3.932259357944253, 3.8147850251428084, 3.718585600155572, 3.660357532009405, 3.6357635986664754, 3.634746449796958, 3.6472486185233746, 3.6632126379682495, 3.6726024511225788, 3.670682346334223, 3.6649401937466357, 3.664581257939497, 3.676917453655926, 3.696249898899042, 3.7237349675581086, 3.7667584674308827, 3.830405888796865, 3.9144102534254417, 4.01723819891586, 4.127947804519783, 4.239571269658402, 4.348625007778521, 4.451625432326946, 4.536204822184372, 4.6028930291508505, 4.666136728374821, 4.731127239785558, 4.803055883312331, 4.887113978884412, 4.987188910758409, 5.094664675408693, 5.193962948763073, 5.2694302273322915, 5.3054130076270996, 5.28625778615824, 5.218676595893512, 5.143738377133947, 5.072297370065466, 5.006038772566799, 4.940128023248208, 4.8695401774235005, 4.789250290406491, 4.694233417510987], "y_coordinates": [3.1067745685577397, 3.1232225349737575, 3.1249062907096463, 3.116701509973192, 3.103141321713009, 3.088758854877706, 3.0780872384158937, 3.075527417481903, 3.0755933875590498, 3.056229396731701, 2.9989601885446118, 2.907774027111978, 2.7927681538706786, 2.664039934728046, 2.5316867355914137, 2.4057881633665703, 2.2920273083963374, 2.1859480764600985, 2.081669833505272, 1.9744592522680733, 1.8677930222759376, 1.7634294735760478, 1.6604726650975863, 1.5638370895305274, 1.4918082719956658, 1.4620101372991994, 1.4463476159709463, 1.43682340997049, 1.442581525437521, 1.47276596851173, 1.539427527206234, 1.621196119304559, 1.7024077058826483, 1.7835894111692419, 1.865268359393079, 1.9479716747828986, 2.0321790156873805, 2.117914892001749, 2.2049503711555247, 2.293053783896293, 2.3819934609716467, 2.471537733129171, 2.5563055227407108, 2.634259747524559, 2.719335344130429, 2.813350916785657, 2.9078545008116707, 2.9940942209528005, 3.0633182019533796, 3.1067745685577397]}}, {"topic_id": "bt-8", "name": " Data Privacy and Truth", "lemma_name": null, "term_id": ["Privacy", "privacy", "truth", "Data", "Identifiability", "changes", "Vulnerability", "Smartphones", "utility", "behavior", "age", "Guarantees", "Attacks", "Needs", "Documents", "Sharing", "RNNs", "estimation", "Don", "predictions", "Effect", "t", "differentiation", "Error", "Survey", "Rate", "distributions", "channel", "Algorithms", "Image", "system", "Evaluation", "Bandits", "Explanations", "loss", "inference", "level", "Risk", "Models", "Deep Learning", "Machine Learning", "data", "detection", "Approach", "model", "machine"], "x_centroid": 8.313764169812202, "y_centroid": 0.7337494720704854, "size": 96, "top_doc_id": null, "top_doc_content": ["Generating synthetic mobility data for a realistic population with RNNs\n  to improve utility and privacy", "An automatic differentiation system for the age of differential privacy", "Privacy with Estimation Guarantees", "Vulnerability and Transaction behavior based detection of Malicious\n  Smart Contracts", "Graphical-model based estimation and inference for differential privacy", "Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with\n  Assisted AutoEncoders", "Don't Generate Me: Training Differentially Private Generative Models\n  with Sinkhorn Divergence", "Differentially Private (Gradient) Expectation Maximization Algorithm\n  with Statistical Guarantees", "Privacy Attacks on Network Embeddings", "ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function\n  Secret Sharing", "A Data Quarantine Model to Secure Data in Edge Computing", "Subpopulation Data Poisoning Attacks", "Privacy in Deep Learning: A Survey", "Continuous Authentication of Smartphones Based on Application Usage", "Data Poisoning Attacks and Defenses to Crowdsourcing Systems", "Securing Your Transactions: Detecting Anomalous Patterns In XML\n  Documents", "Data Stealing Attack on Medical Images: Is it Safe to Export Networks from Data Lakes?", "A compressive multi-kernel method for privacy-preserving machine\n  learning", "Data Smashing", "Data Poisoning Attacks on Stochastic Bandits", "Crowdsourcing via Pairwise Co-occurrences: Identifiability and\n  Algorithms", "Privacy-Enhancing Context Authentication from Location-Sensitive Data", "Needmining: Designing Digital Support to Elicit Needs from Social Media", "\"Is not the truth the truth?\": Analyzing the Impact of User Validations\n  for Bus In/Out Detection in Smartphone-based Surveys", "Cryptotree: fast and accurate predictions on encrypted structured data", "Asymptotically optimal private estimation under mean square loss", "A New Analysis of Differential Privacy's Generalization Guarantees", "An Equivalence Between Data Poisoning and Byzantine Gradient Attacks", "Privately detecting changes in unknown distributions"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.187292098999023, 8.124652055669724, 8.073140304069845, 8.017182109265228, 7.952124549923389, 7.882662674991643, 7.813674190142666, 7.7500368010491325, 7.696628213383719, 7.658326132819099, 7.640008265027951, 7.643777085369661, 7.655231954621354, 7.666866523816149, 7.678166630653669, 7.690567610862594, 7.706886994210232, 7.729973293560672, 7.762675021778, 7.807840691726303, 7.868226491954692, 7.9436294419470626, 8.030331749596149, 8.124411137431595, 8.221945327983034, 8.319012043780107, 8.412123331641418, 8.500332506741383, 8.583614406953096, 8.66194515859423, 8.73530088798246, 8.803653953391805, 8.865834200355541, 8.917928422489222, 8.955620211502607, 8.974609232034059, 8.972753087181045, 8.952220232041368, 8.915691552825807, 8.865847935745146, 8.80537026701016, 8.736939432831628, 8.663236319420335, 8.586941812987058, 8.510736799742576, 8.43730216589767, 8.36931879766312, 8.308102069828331, 8.249344630018596, 8.187292098999022], "y_coordinates": [1.7643078565597534, 1.7002552262140616, 1.6293828502988366, 1.5606965973897509, 1.4942870692782446, 1.428797926094732, 1.3628445551341692, 1.295042343691513, 1.2240066790617194, 1.1483529485397441, 1.066696539420544, 0.9789169059182603, 0.8918378572299803, 0.8045507356560327, 0.7112926741624925, 0.6127860647015824, 0.5144817320656376, 0.42193649303380226, 0.3407071643852208, 0.2763505628990379, 0.2342804652604911, 0.2153259423698495, 0.21487049014335047, 0.22798079082201408, 0.24972352664686034, 0.27516537985890943, 0.3002440390845047, 0.3259935253932109, 0.35529590790338494, 0.3910358396171016, 0.436097973536436, 0.4933594222065205, 0.5634109477711818, 0.6413540275467813, 0.7214832674632878, 0.7981106859156375, 0.8678860848334031, 0.9321293895150976, 0.9927156629711088, 1.0515199682118255, 1.1104173682476355, 1.171282926088926, 1.235991704746086, 1.306418767229503, 1.3844391765495652, 1.4719279957166607, 1.5707602877411775, 1.6759183387300192, 1.7540022452860218, 1.7643078565597532]}}, {"topic_id": "bt-9", "name": " Explanations and Reasoning for Interventions", "lemma_name": null, "term_id": ["Explanations", "explanations", "Reasoning", "interventions", "Explainability", "reviews", "Hypothesis", "Lists", "Causal Inference", "APIs", "Interpretability", "user", "causal", "studies", "Logic", "Inference", "apples", "science", "Markov", "Effects", "assessment", "Model", "AI", "Results", "Features", "scenarios", "outcome", "shift", "blood", "Identifiability", "effects", "levels", "Comparing", "causes", "Extraction", "Activities", "tool", "stability", "analytics", "values", "variance", "Ontology", "Trajectories", "Separators", "Queries", "Product", "Occlusion", "Gradient", "Shift", "decision", "Case", "systems", "Methods", "dimensionality reduction", "mixture", "Class", "sequence", "drift", "Needs", "correlation", "Construction", "filtering", "quality", "Framework", "data analysis", "inspection", "learning framework", "Validation", "representation learning", "outcomes", "tasks", "Time", "confidence", "Agents", "structures", "Trust", "degree", "testing", "test", "results", "Theory", "health", "Enhancement", "structure", "study", "interaction", "Solutions", "source", "production", "E", "Distribution", "Introduction", "Users", "decomposition", "Training", "machine", "Rules", "context", "support", "Message", "software", "dimensionality", "Machine Learning", "Approach", "Translation", "evaluation", "complexity", "machines", "Rates", "Decision", "agent", "policy", "Predictions", "reduction", "graphs", "generation", "BERT", "Modeling", "Survey", "Errors", "Processing", "Learning", "review", "Challenges", "datasets", "case", "modeling", "machine learning", "Models", "framework", "features", "Information", "GANs", "Web", "order", "Transfer", "control", "representation", "models", "identification", "Applications", "Constraints", "Evaluation", "methods", "CNNs", "selection", "time series", "Scale", "Study", "Flows", "data", "Classification", "prediction", "series", "analysis", "Application", "Data", "inference"], "x_centroid": 6.967673680721185, "y_centroid": 2.4260212235398346, "size": 273, "top_doc_id": null, "top_doc_content": ["Integrating Markov processes with structural causal modeling enables\n  counterfactual inference in complex systems", "FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph\n  Reasoning", "Generating personalized counterfactual interventions for algorithmic\n  recourse by eliciting user preferences", "The Dangers of Post-hoc Interpretability: Unjustified Counterfactual\n  Explanations", "Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach", "Conformal testing: binary case with Markov alternatives", "A Practical Approach to Proper Inference with Linked Data", "Reducing the Effects of Detrimental Instances", "Modeling user context for valence prediction from narratives", "Behavior Cloning in OpenAI using Case Based Reasoning", "Learning latent causal graphs via mixture oracles", "Distinguishing correlation from causation using genome-wide association\n  studies", "Survey of explainable machine learning with visual and granular methods\n  beyond quasi-explanations", "Causal Discovery in Heterogeneous Environments Under the Sparse\n  Mechanism Shift Hypothesis", "SLISEMAP: Supervised dimensionality reduction through local explanations", "Invariant Structure Learning for Better Generalization and Causal\n  Explainability", "Model updating after interventions paradoxically introduces bias", "Predicting computational reproducibility of data analysis pipelines in\n  large population studies using collaborative filtering", "SEEN: Sharpening Explanations for Graph Neural Networks using\n  Explanations from Neighborhoods", "Exact and Consistent Interpretation of Piecewise Linear Models Hidden\n  behind APIs: A Closed Form Solution", "Extraction of Product Specifications from the Web -- Going Beyond Tables\n  and Lists", "Differentiable Adaptive Computation Time for Visual Reasoning", "A Few Good Counterfactuals: Generating Interpretable, Plausible and\n  Diverse Counterfactual Explanations", "Causal Discovery in Heterogeneous Environments Under the Sparse Mechanism Shift Hypothesis", "Predicting health inspection results from online restaurant reviews", "User Driven Model Adjustment via Boolean Rule Explanations", "Clinical outcome prediction under hypothetical interventions -- a\n  representation learning framework for counterfactual reasoning", "Training Machine Learning Models by Regularizing their Explanations", "Inference and learning in probabilistic logic programs using weighted\n  Boolean formulas", "Improving the Learnability of Machine Learning APIs by Semi-Automated\n  API Wrapping", "Leveraging Latent Features for Local Explanations", "Causal Inference with Corrupted Data: Measurement Error, Missing Values,\n  Discretization, and Differential Privacy", "Tell me why! Explanations support learning relational and causal\n  structure", "ELUDE: Generating interpretable explanations via a decomposition into labelled and unlabelled features", "Causal Inference under Networked Interference and Intervention Policy\n  Enhancement", "Generating User-friendly Explanations for Loan Denials using GANs", "Comparing apples to apples in the evaluation of binary coding methods", "The Barrier of meaning in archaeological data science", "Open science in machine learning", "Towards Realistic Individual Recourse and Actionable Explanations in\n  Black-Box Decision Making Systems", "Explainability via Interactivity? Supporting Nonexperts' Sensemaking of\n  Pretrained CNN by Interacting with Their Daily Surroundings", "ConceptDistil: Model-Agnostic Distillation of Concept Explanations", "SAT-Based Rigorous Explanations for Decision Lists", "Diffusion Models for Counterfactual Explanations", "Interpretability via Model Extraction", "Explanatory causal effects for model agnostic explanations", "Predicting Driver Fatigue in Automated Driving with Explainability", "Inference for Interpretable Machine Learning: Fast, Model-Agnostic\n  Confidence Intervals for Feature Importance", "One Explanation to Rule them All -- Ensemble Consistent Explanations", "Automatic generation of reviews of scientific papers", "Deep Learning for Ontology Reasoning", "On the Accuracy of Influence Functions for Measuring Group Effects", "Proper Network Interpretability Helps Adversarial Robustness in\n  Classification"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.5409159660339355, 6.434523464798212, 6.323913478116981, 6.214644946935883, 6.11227681220055, 6.0223680148566245, 5.95047749584974, 5.902164196125536, 5.8829870566296485, 5.898384258845033, 5.947264046695721, 6.018804611421575, 6.101391276339199, 6.183455056884101, 6.265492907125005, 6.372257307767039, 6.490167418199983, 6.610361493194257, 6.732396610093948, 6.8558296376242644, 6.980126388152578, 7.104519470113283, 7.228204685580098, 7.350377836626738, 7.470234725326919, 7.586971153754356, 7.70021813594562, 7.8131101906861105, 7.924539377187519, 8.027627111875905, 8.115076248076537, 8.175171143661416, 8.195007096894248, 8.1784727726454, 8.135139037314246, 8.07305434510205, 7.995381657663943, 7.904308595905263, 7.802022780731351, 7.690711833047549, 7.572563373759193, 7.4497650237716275, 7.324504403990193, 7.198969135320225, 7.075346838667071, 6.955825134936067, 6.8425916450325515, 6.737792391692458, 6.639904496291783, 6.540915966033936], "y_coordinates": [3.203359842300415, 3.1131634200661438, 3.0198125117049575, 2.923691093903931, 2.825183143350137, 2.7246726367306517, 2.622543550732548, 2.5191798620429013, 2.4149655473487845, 2.3102830924094198, 2.2054343626701463, 2.1006010938056265, 1.995955232536149, 1.891701800786405, 1.7967800047601912, 1.7361952047054448, 1.6924489590485348, 1.6572830389080264, 1.632511219057565, 1.619945405720201, 1.620581934572385, 1.6333283880875102, 1.6567626827561577, 1.689462735068907, 1.7300064615163395, 1.7769717785890349, 1.8287392703666583, 1.8822710763139299, 1.939907306977407, 2.0098221710638406, 2.1000067931172124, 2.2093930397315273, 2.328851156907874, 2.4534359955412586, 2.5797290582413863, 2.7046111733716174, 2.8259176595505306, 2.941674390030124, 3.0499072380623975, 3.148642076899347, 3.235904779792971, 3.3097212199952692, 3.3681172707582396, 3.4091188053338795, 3.4307516969741876, 3.4310418189311616, 3.4080150444568, 3.359743638949897, 3.2883915913844444, 3.2033598423004155]}}]