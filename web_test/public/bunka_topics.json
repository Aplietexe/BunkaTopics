[{"topic_id": "bt-0", "name": " Medical Imaging Diagnosis", "lemma_name": null, "term_id": ["Patients", "Images", "diagnosis", "brain", "disease", "segmentation", "ray", "camera", "ECG", "ICU", "disease diagnosis", "images", "object", "object detection", "CPS", "brain tumor", "patients", "tumor segmentation", "Detection", "tumor", "Sensors", "localization", "rays", "U", "Depth", "Classification", "Self", "Sparse", "Cases", "imaging data", "Localization", "augmentation", "CheXseen", "detection", "term", "Predictions", "risk", "imaging", "Factors", "identification", "Survey", "features", "cell", "Ensembles", "beam", "batch", "Enhancement", "CRFs", "weight", "brain atrophy", "atrophy", "boundaries", "Events", "vector machine", "Latent", "vector", "Skin", "Disease", "Diseases", "DNNs", "depth", "Detecting", "frame", "emergence", "traversal", "consistency", "Neural Network", "transfer", "classifier", "data augmentation", "inverse problems", "learning model", "cough", "subspaces", "Annotations", "Words", "stratification", "Point", "stream", "results", "Prospects", "VAE", "Protocols", "learning", "Datasets", "analysis", "Analysis", "Identification", "stage", "loss", "study", "recognition", "inverse", "challenge", "latent", "review", "monitoring", "dataset", "decision", "Results", "Mapping", "software", "Labels", "E", "measure", "mapping", "case study", "Buildings", "activity", "fusion", "Devices", "Validation", "Overview", "alignment", "head", "image", "view", "approach", "Attention", "Detectors", "architecture", "t", "support", "Feature", "model", "Performance", "3D", "classification", "case", "Sensing", "learning models", "Interpretability", "Techniques", "source", "Values", "Estimation", "Evaluation", "way", "machine", "Image", "Time", "output", "AI", "body", "level", "machine learning", "space", "label", "domain", "data", "scale", "network", "representation", "regression", "Inference", "function", "Transformers", "Prediction", "feature", "Study", "Machine", "distribution", "Risk", "estimation", "problems", "speech", "Theory", "GAN"], "x_centroid": 4.639791123955338, "y_centroid": 2.1537884491461297, "size": 270, "top_doc_id": null, "top_doc_content": ["What is the best data augmentation for 3D brain tumor segmentation?", "Cascaded V-Net using ROI masks for brain tumor segmentation", "An explainable two-dimensional single model deep learning approach for\n  Alzheimer's disease diagnosis and brain atrophy localization", "Sickle-cell disease diagnosis support selecting the most appropriate\n  machinelearning method: Towards a general and interpretable approach for\n  cellmorphology analysis from microscopy images", "High-level camera-LiDAR fusion for 3D object detection with machine\n  learning", "Machine learning based disease diagnosis: A comprehensive review", "New Bag of Deep Visual Words based features to classify chest x-ray\n  images for COVID-19 diagnosis", "Towards segmentation and spatial alignment of the human embryonic brain\n  using deep learning for atlas-based registration", "COVID-Net CXR-2: An Enhanced Deep Convolutional Neural Network Design\n  for Detection of COVID-19 Cases from Chest X-ray Images", "Building Deep Learning Models to Predict Mortality in ICU Patients", "Automatically identifying, counting, and describing wild animals in\n  camera-trap images with deep learning", "Underwater object detection using Invert Multi-Class Adaboost with deep\n  learning", "Benchmarking Deep Learning Architectures for Predicting Readmission to\n  the ICU and Describing Patients-at-Risk", "Performance of multilabel machine learning models and risk\n  stratification schemas for predicting stroke and bleeding risk in patients\n  with non-valvular atrial fibrillation", "Inference of a Multi-Domain Machine Learning Model to Predict Mortality\n  in Hospital Stays for Patients with Cancer upon Febrile Neutropenia Onset", "Interpretable ECG classification via a query-based latent space\n  traversal (qLST)", "Learning Shape Priors for Robust Cardiac MR Segmentation from Multi-view\n  Images", "Single-shot autofocusing of microscopy images using deep learning", "WiP Abstract : Robust Out-of-distribution Motion Detection and\n  Localization in Autonomous CPS", "Generative-based Airway and Vessel Morphology Quantification on Chest CT\n  Images", "Residual Attention U-Net for Automated Multi-Class Segmentation of\n  COVID-19 Chest CT Images", "North Atlantic Right Whale Contact Call Detection", "Latent Space Analysis of VAE and Intro-VAE applied to 3-dimensional MR\n  Brain Volumes of Multiple Sclerosis, Leukoencephalopathy, and Healthy\n  Patients", "A Relational-learning Perspective to Multi-label Chest X-ray\n  Classification", "EDITH :ECG biometrics aided by Deep learning for reliable Individual\n  auTHentication", "S-Extension Patch: A simple and efficient way to extend an object\n  detection model", "iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images", "Predict the model of a camera", "2D histology meets 3D topology: Cytoarchitectonic brain mapping with\n  Graph Neural Networks", "Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19\n  Patients with a Large Feature Set in 2021 BARDA Data Challenge", "Re-identification of Individuals in Genomic Datasets Using Public Face\n  Images", "CheXternal: Generalization of Deep Learning Models for Chest X-ray\n  Interpretation to Photos of Chest X-rays and External Clinical Settings", "Support vector machine classification of dimensionally reduced\n  structural MRI images for dementia", "AI outperformed every dermatologist: Improved dermoscopic melanoma\n  diagnosis through customizing batch logic and loss function in an optimized\n  Deep CNN architecture", "Predicting brain age with deep learning from raw imaging data results in\n  a reliable and heritable biomarker", "Detection of Parasitic Eggs from Microscopy Images and the emergence of\n  a new dataset", "Self-supervised representation learning from 12-lead ECG data", "On Classifying Sepsis Heterogeneity in the ICU: Insight Using Machine\n  Learning", "Automatic detection of estuarine dolphin whistles in spectrogram images", "Multi-class versus One-class classifier in spontaneous speech analysis\n  oriented to Alzheimer Disease diagnosis", "How well do U-Net-based segmentation trained on adult cardiac magnetic\n  resonance imaging data generalise to rare congenital heart diseases for\n  surgical planning?", "Predicting Alzheimer's disease: a neuroimaging study with 3D\n  convolutional neural networks", "n-CPS: Generalising Cross Pseudo Supervision to n Networks for\n  Semi-Supervised Semantic Segmentation", "Multi-Labeled Classification of Demographic Attributes of Patients: a\n  case study of diabetics patients", "Method to Classify Skin Lesions using Dermoscopic images"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.1403260231018075, 4.072618462009709, 4.02021557048259, 3.980724903795194, 3.9517540172222607, 3.9309104660385286, 3.915801805518738, 3.9040355909376303, 3.8932195642597724, 3.8838098868224433, 3.886309729895581, 3.913399341419155, 3.9709832056978196, 4.050339912703677, 4.1408431057504185, 4.2335210355802735, 4.328603810189516, 4.429498041054206, 4.537559112948013, 4.648695444633257, 4.757927712078591, 4.864559879741313, 4.97816545260621, 5.096952163621444, 5.213180084352327, 5.319083360543121, 5.406896137938079, 5.468880536282372, 5.503032114835149, 5.5200430528828095, 5.532308770718994, 5.549714561228405, 5.561288469044634, 5.548101293821807, 5.506366945988848, 5.441408192237002, 5.36360056478281, 5.279809350373003, 5.191728238582861, 5.100705878047923, 5.008090917403726, 4.915232005285808, 4.823232156862522, 4.730338806921092, 4.632964017346638, 4.529641353480929, 4.424088040369141, 4.320786084381441, 4.2244258424215815, 4.140326023101809], "y_coordinates": [2.9351501464843746, 2.8534258800762364, 2.7597372284719364, 2.6561192539910934, 2.5446070189533256, 2.42723558567825, 2.306040016485483, 2.183055373694644, 2.060316744437525, 1.9402377875267898, 1.8265674684628574, 1.7233347139847506, 1.6319482557846803, 1.5481609765689754, 1.4669891141331537, 1.3863727302540867, 1.3205123062185966, 1.2892096337492247, 1.3022106469259358, 1.3425835378188022, 1.389032253555922, 1.4269080891505903, 1.4601372242814352, 1.4941216567038673, 1.5334550649128615, 1.5827276039444818, 1.6465294288347914, 1.7294322844426362, 1.8322346392242363, 1.9473790948607048, 2.066187320461198, 2.18102321161478, 2.2929107726954423, 2.405512075350164, 2.51203254899045, 2.605951751140156, 2.6880010207246983, 2.760622848961519, 2.827612116072196, 2.892853931574484, 2.960233404986137, 3.033635645824911, 3.115263787116064, 3.18776735981043, 3.2212267385666005, 3.1998082681054516, 3.142111182948037, 3.0718090071254576, 3.005030431963206, 2.9351501464843754]}}, {"topic_id": "bt-1", "name": " Optimizing Communication Objectives", "lemma_name": null, "term_id": ["optimization", "Communication", "Objectives", "updates", "inputs", "SDPs", "programming", "Optimizers", "gradient", "lambda", "stochastic", "Distribution", "Stochastic", "Efficient Algorithms", "estimation", "problems", "Guarantees", "algorithms", "Generalization", "point", "sample", "order", "Optimization", "Scale", "change", "PCA", "parameter estimation", "optimization method", "Linear Regression", "Estimates", "Metropolis Hastings", "Rates", "particle", "guarantees", "vector machine", "differentiation", "implementation", "vector", "descent", "Derivatives", "constraints", "Improvements", "message", "decisions", "stability", "similarity", "Volume", "Newton", "speed", "latency", "step", "Adversaries", "stochastic gradient", "stratification", "results", "presence", "Protocols", "Convergence", "Features", "Approximation", "method", "Methods", "Solution", "complexity", "Risk Bounds", "Constraints", "type", "uncertainty", "Errors", "Error", "Risk", "Bounds", "parameter", "Number", "generalization", "probability", "layers", "support", "Understanding", "risk", "tasks", "Optimality", "way", "Processing", "sparse", "Model", "design", "equations", "Information", "control", "Experiments", "process", "rank", "CUR", "performance", "applications", "study", "methods", "Algorithms", "classification", "image", "Regression", "modeling", "distribution", "view", "Signals", "model", "Networks", "Approach", "class", "systems", "Survey", "detection", "Problems", "framework", "approach", "Training", "Data", "Applications"], "x_centroid": 8.497579732787944, "y_centroid": 0.54824653613516, "size": 214, "top_doc_id": null, "top_doc_content": ["Proximal algorithms for constrained composite optimization, with\n  applications to solving low-rank SDPs", "A theoretical and empirical study of new adaptive algorithms with\n  additional momentum steps and shifted updates for stochastic non-convex\n  optimization", "A sparse code increases the speed and efficiency of neuro-dynamic\n  programming for optimal control tasks with correlated inputs", "AdaDGS: An adaptive black-box optimization method with a nonlocal\n  directional Gaussian smoothing gradient", "Nearly second-order asymptotic optimality of sequential change-point\n  detection with one-sample updates", "On the convex hull of convex quadratic optimization problems with\n  indicators", "Linear Regression over Networks with Communication Guarantees", "Hyper-parameter estimation method with particle swarm optimization", "Hyperparameter optimization with approximate gradient", "Simple and optimal high-probability bounds for strongly-convex\n  stochastic gradient descent", "$\\lambda$-Regularized A-Optimal Design and its Approximation by\n  $\\lambda$-Regularized Proportional Volume Sampling", "Optimality guarantees for distributed statistical estimation", "Learning with Differentiable Perturbed Optimizers", "Convergence Guarantees for Adaptive Bayesian Quadrature Methods", "An Algebraically Converging Stochastic Gradient Descent Algorithm for\n  Global Optimization", "Convergent message passing algorithms - a unifying view", "Model-free two-step design for improving transient learning performance\n  in nonlinear optimal regulator problems", "A hybrid estimation of distribution algorithm for joint stratification\n  and sample allocation", "Efficient differentiable quadratic programming layers: an ADMM approach", "Online discrete optimization in social networks in the presence of\n  Knightian uncertainty", "Communication-efficient SGD: From Local SGD to One-Shot Averaging", "Communication-Efficient Algorithms for Decentralized and Stochastic\n  Optimization", "Efficient and passive learning of networked dynamical systems driven by\n  non-white exogenous inputs", "Efficient Algorithms for High-Dimensional Convex Subspace Optimization\n  via Strict Complementarity", "Convergence Rate of Block-Coordinate Maximization Burer-Monteiro Method\n  for Solving Large SDPs", "Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical\n  Viewpoints", "A Generalizable Approach to Learning Optimizers", "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic\n  Objectives with Skewed Hessian Spectrums", "Distribution Regression for Sequential Data", "GO Hessian for Expectation-Based Objectives", "Efficient implementation of incremental proximal-point methods", "All unconstrained strongly convex problems are weakly simplicial", "Communication-efficient Distributed Cooperative Learning with Compressed\n  Beliefs", "Surrogate modeling for Bayesian optimization beyond a single Gaussian process", "Scalable Stochastic Alternating Direction Method of Multipliers", "Communication-efficient Algorithm for Distributed Sparse Learning via\n  Two-way Truncation", "Result Diversification by Multi-objective Evolutionary Algorithms with\n  Theoretical Guarantees", "Risk Bounds for Infinitely Divisible Distribution", "Neyman-Pearson classification, convexity and stochastic constraints", "Generalization Bounds for Noisy Iterative Algorithms Using Properties of\n  Additive Noise Channels", "Infinite-dimensional optimization and Bayesian nonparametric learning of\n  stochastic differential equations"], "top_term_id": null, "convex_hull": {"x_coordinates": [9.281865119934082, 9.321619921109821, 9.346434971194224, 9.35686385542531, 9.353460159041092, 9.33677746727959, 9.30736936537882, 9.265789438576801, 9.212591272111545, 9.14832845122107, 9.073554623737278, 8.98890199399628, 8.895234782896567, 8.793977078450519, 8.68866183536833, 8.583327161217762, 8.480176986587287, 8.378628190809215, 8.277864325955445, 8.177072921064784, 8.076003223885527, 7.975541651918216, 7.876704234717445, 7.780150351118727, 7.686264992271155, 7.648128250537894, 7.631215994870935, 7.623588861531094, 7.629965973344502, 7.6550664531372865, 7.703599915997677, 7.7690713043432, 7.840519354633555, 7.918516843239716, 8.003294492128358, 8.091572892257277, 8.18214670426677, 8.274759313411405, 8.369154104945753, 8.465072294664731, 8.561941851183697, 8.658552966484779, 8.753618278430196, 8.845850354207244, 8.933357507143723, 9.014692887019642, 9.091180532375727, 9.1629259686413, 9.227598392150473, 9.281865119934082], "y_coordinates": [0.17207893729209894, 0.269178072673167, 0.37325275223521687, 0.48206541263495795, 0.5933784905290995, 0.7049544225743513, 0.8145556454274225, 0.9199445957450229, 1.0188837101838613, 1.1091354254006471, 1.1884609721674733, 1.2531081733066334, 1.2948550026630874, 1.3080165370645849, 1.3006002590123686, 1.284026612283593, 1.2653820706895684, 1.2451675941346791, 1.223332814335575, 1.1998271357253005, 1.1745678605201504, 1.1474073017002544, 1.118108143598885, 1.0826614434079587, 1.031689527517834, 0.9370023415738378, 0.8284272711597644, 0.7186944246679551, 0.611671798215952, 0.511227387921299, 0.4212245823871283, 0.34009633261528976, 0.2641073185863784, 0.19511006605878267, 0.1351885026543492, 0.08603270823170658, 0.0429641273101806, -1.229313092887225e-05, -0.04889160611232149, -0.10961451307996066, -0.18027391914698318, -0.2429844814166827, -0.2779178899761411, -0.26524825521091583, -0.20751802747303497, -0.14300015021599624, -0.07350912869498326, 0.0018529294868337802, 0.08343203489804728, 0.17207893729209894]}}, {"topic_id": "bt-10", "name": " Speech EEG Captioning", "lemma_name": null, "term_id": ["speech", "EEG", "Captioning", "Keyword Spotting", "speaker", "End", "Text", "end", "importance", "Dataset", "Actions", "times", "recognition", "Translation", "channel", "evaluation", "Generation", "processing", "text", "Processing", "motor", "approaches", "CTC", "Rate", "Events", "Latent", "dependency", "imagery", "enhancement", "emergence", "Machine learning", "child", "Effects", "Domain", "labeling", "representation learning", "rule", "Technique", "Policy Gradients", "state", "Gradient", "VAE", "domain", "representation", "methods", "training", "Study", "Machine", "attention", "modal", "review", "Gradients", "Encoders", "factorization", "genre", "encoders", "Pooling", "effect", "generation", "activity", "StyleGAN", "Multi", "purpose", "alignment", "Bit", "Signals", "Deep Learning", "task", "synthesis", "Mechanism", "maps", "representations", "Measure", "time", "Image", "correlation", "shot", "Priors", "source", "Quantum", "level", "sparse", "Model", "classifiers", "Time", "application", "space", "system", "label", "Tuning", "Analysis", "performance", "agent", "image", "feature", "Embeddings", "Policy", "GAN", "network", "Structure", "model", "Networks", "systems", "detection", "scale", "Transformers", "approach", "data", "CUR", "Training"], "x_centroid": 3.6574927502614587, "y_centroid": 3.8544979270981865, "size": 163, "top_doc_id": null, "top_doc_content": ["Large scale evaluation of importance maps in automatic speech\n  recognition", "RawNet: Advanced end-to-end deep neural network using raw waveforms for\n  text-independent speaker verification", "Latent Code and Text-based Generative Adversarial Networks for Soft-text\n  Generation", "Revisiting joint decoding based multi-talker speech recognition with DNN\n  acoustic model", "Post-hoc labeling of arbitrary EEG recordings for data-efficient\n  evaluation of neural decoding methods", "Single-channel speech separation using Soft-minimum Permutation\n  Invariant Training", "A channel attention based MLP-Mixer network for motor imagery decoding\n  with EEG", "Enabling Factorized Piano Music Modeling and Generation with the MAESTRO\n  Dataset", "Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine\n  Translation", "JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to\n  Speech", "Text-to-Image-to-Text Translation using Cycle Consistent Adversarial\n  Networks", "FSD50K: An Open Dataset of Human-Labeled Sound Events", "WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks\n  for Keyword Spotting", "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period", "textless-lib: a Library for Textless Spoken Language Processing", "An End-to-End Audio Classification System based on Raw Waveforms and\n  Mix-Training Strategy", "Dependent Multi-Task Learning with Causal Intervention for Image\n  Captioning", "End-to-End Supermask Pruning: Learning to Prune Image Captioning Models", "Speech enhancement aided end-to-end multi-task learning for voice\n  activity detection", "WaveCycleGAN2: Time-domain Neural Post-filter for Speech Waveform\n  Generation", "DONUT: CTC-based Query-by-Example Keyword Spotting", "Audio-Visual Speech Recognition is Worth 32$\\times$32$\\times$8 Voxels", "Does human speech follow Benford's Law?", "Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video\n  Captioning", "Audio Captioning with Composition of Acoustic and Semantic Information", "Deep learning with convolutional neural networks for EEG decoding and\n  visualization", "Learning Filterbanks for End-to-End Acoustic Beamforming", "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language\n  Processing", "Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation", "An Empirical Evaluation of End-to-End Polyphonic Optical Music\n  Recognition", "Adversarial representation learning for private speech generation", "Actions Speak Louder than Listening: Evaluating Music Style Transfer\n  based on Editing Experience", "Boosting Objective Scores of a Speech Enhancement Model by MetricGAN\n  Post-processing", "Local and non-local dependency learning and emergence of rule-like\n  representations in speech data by Deep Convolutional Generative Adversarial\n  Networks", "The effect of fatigue on the performance of online writer recognition", "Latent Translation: Crossing Modalities by Bridging Generative Models", "Speaker-independent classification of phonetic segments from raw\n  ultrasound in child speech", "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition", "Weight-importance sparse training in keyword spotting", "Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner\n  Party Transcription", "Deep learning methods in speaker recognition: a review", "Evidence of Task-Independent Person-Specific Signatures in EEG using\n  Subspace Techniques", "Discovering Sound Concepts and Acoustic Relations In Text", "End-to-End Probabilistic Inference for Nonstationary Audio Analysis", "End-to-End Environmental Sound Classification using a 1D Convolutional\n  Neural Network", "Intra-agent speech permits zero-shot task acquisition"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.623061180114746, 4.661751389607973, 4.678408400913849, 4.674831558221937, 4.652820205721806, 4.6143939929502675, 4.5637801234727275, 4.5064783676570075, 4.448003825987616, 4.393871598949054, 4.346812272455619, 4.26504760217757, 4.165319455674261, 4.063820103627193, 3.9608611655837636, 3.8567542610913663, 3.7518110096973967, 3.6463430309492493, 3.540947810285729, 3.4375693133533356, 3.3385475802218934, 3.2462227053413484, 3.162934783161653, 3.091442400567396, 3.0315413403327076, 2.9717481616007775, 2.918034828069736, 2.8779641470700366, 2.8590989259321358, 2.8681381134222086, 2.9068354419366136, 2.9720457092597523, 3.056492767255928, 3.152627226558605, 3.2528996978012463, 3.3502961219541687, 3.443525378894917, 3.5347641121010964, 3.626093725373293, 3.7185934186113463, 3.812915693387305, 3.909711476151429, 4.009429919545383, 4.110928453666312, 4.2123011912881605, 4.308163459388444, 4.397384771565419, 4.484409523422827, 4.562041644946459, 4.623061180114747], "y_coordinates": [3.3717021942138676, 3.4687386718560838, 3.5750165612879057, 3.6842087235322816, 3.7899880196121583, 3.8866865616037236, 3.975242439770172, 4.060401827180109, 4.146956771392683, 4.239699319967047, 4.340187166275828, 4.398375182275803, 4.433175502739547, 4.462212776573635, 4.484393224610289, 4.498623067681726, 4.503808526620165, 4.49885582225782, 4.482788665568148, 4.4551841674038, 4.415782224179941, 4.3643227546618215, 4.300545677614698, 4.224258336051608, 4.137745343200152, 4.0480152736986295, 3.9550188497452083, 3.858073368699246, 3.756496127920099, 3.6516426710578465, 3.5561154361090357, 3.4779409769315257, 3.4140701353440996, 3.360720555249818, 3.3141098805517397, 3.2704309483070397, 3.2256113984530512, 3.1754181771063443, 3.1170744604357488, 3.0579724532257813, 3.009833925833699, 2.984396630852076, 2.991087902449236, 3.0211089971931093, 3.0570589986651293, 3.097595892061655, 3.155033652732786, 3.2175423356693966, 3.2885943055211753, 3.371702194213868]}}, {"topic_id": "bt-11", "name": " Movie Genre Attention", "lemma_name": null, "term_id": ["attention", "label", "movie genre", "movie", "genre classification", "Unlabeled Data", "self", "genre", "Learning", "Representations", "Characters", "labels", "Teacher", "representation", "Text", "Examples", "text", "knowledge", "classification", "CTC", "Ontology", "net", "health", "Shot", "dependency", "humans", "videos", "machines", "mechanism", "Convolutions", "labeling", "signal", "representation learning", "supervision", "rule", "Annotations", "Forecasting", "Activities", "Neighborhood", "Biases", "Way", "set", "language", "Datasets", "class", "Classification", "scale", "Embeddings", "view", "review", "Incremental Learning", "Confidence", "Message", "Transfer", "P", "reconstruction", "path", "embeddings", "fusion", "Localization", "tuning", "head", "diffusion", "task", "Rules", "Meta Learning", "Attention", "Consistency", "layers", "synthesis", "cost", "media", "representations", "shot", "Compression", "CNNs", "Estimation", "tasks", "Tracking", "Self", "Units", "structure", "Processing", "problem", "Reasoning", "Information", "clustering", "Images", "Language", "Identification", "recognition", "Uncertainty", "methods", "image", "Study", "Methods", "Training", "data", "Guarantees", "speech", "Application", "Theory", "End", "model", "Attacks", "images", "Survey", "Features", "level", "graph", "training", "detection", "approach", "Prediction", "Models", "Applications"], "x_centroid": 5.783076870384399, "y_centroid": 3.4908500367944892, "size": 209, "top_doc_id": null, "top_doc_content": ["A multimodal approach for multi-label movie genre classification", "Rethinking movie genre classification with fine-grained semantic\n  clustering", "Transformed CNNs: recasting pre-trained convolutional layers with\n  self-attention", "A cost-reducing partial labeling estimator in text classification\n  problem", "Adaptive label thresholding methods for online multi-label\n  classification", "From phonemes to images: levels of representation in a recurrent neural\n  model of visually-grounded language learning", "An External Knowledge Enhanced Multi-label Charge Prediction Approach\n  with Label Number Learning", "Few-shot learning for medical text: A systematic review", "Self Paced Adversarial Training for Multimodal Few-shot Learning", "Probabilistic Label Trees for Extreme Multi-label Classification", "Improving learnability of neural networks: adding supplementary axes to\n  disentangle data representation", "DegreEmbed: incorporating entity embedding into logic rule learning for\n  knowledge graph reasoning", "Convolution, attention and structure embedding", "Representations of language in a model of visually grounded speech\n  signal", "Challenging Common Assumptions in the Unsupervised Learning of\n  Disentangled Representations", "Are pathologist-defined labels reproducible? Comparison of the TUPAC16\n  mitotic figure dataset with an alternative set of labels", "A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text", "CTC-synchronous Training for Monotonic Attention Model", "Learning Classifiers on Positive and Unlabeled Data with Policy Gradient", "Common-Description Learning: A Framework for Learning Algorithms and\n  Generating Subproblems from Few Examples", "Separable Self-attention for Mobile Vision Transformers", "Pay attention to the activations: a modular attention mechanism for\n  fine-grained image recognition", "A Variational Approach for Learning from Positive and Unlabeled Data", "Labelling unlabelled videos from scratch with multi-modal\n  self-supervision", "Text Detection on Roughly Placed Books by Leveraging a Learning-based\n  Model Trained with Another Domain Data", "It's All In the Teacher: Zero-Shot Quantization Brought Closer to the\n  Teacher", "Theory reconstruction: a representation learning view on predicate\n  invention", "A Cheap Linear Attention Mechanism with Fast Lookups and Fixed-Size\n  Representations", "High-throughput relation extraction algorithm development associating\n  knowledge articles and electronic health records", "On the duality between contrastive and non-contrastive self-supervised learning", "Towards a Unified Foundation Model: Jointly Pre-Training Transformers on\n  Unpaired Images and Text", "Iranis: A Large-scale Dataset of Farsi License Plate Characters", "Teaching an Active Learner with Contrastive Examples", "A Simple Yet Effective Pretraining Strategy for Graph Few-shot Learning", "Infinite attention: NNGP and NTK for deep attention networks"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.7353291511535645, 4.725795414346091, 4.753652890458394, 4.80847349891596, 4.879829159144281, 4.957825975398444, 5.038859160648028, 5.123419348830683, 5.212067155481015, 5.305363196133629, 5.403868086323133, 5.5081424415841305, 5.618529990906494, 5.7335310797313905, 5.8503645431645825, 5.965954541938941, 6.0772178147774465, 6.181071100403078, 6.2744311375388175, 6.354295350757982, 6.421674960715186, 6.482764678886522, 6.538248053772407, 6.58541140964408, 6.6215015856783195, 6.643765421051901, 6.649690076667608, 6.6388310309111995, 6.611798899420817, 6.56921272895774, 6.511800965117941, 6.440782243990712, 6.357512440976739, 6.263347905056005, 6.16030179078707, 6.052350927511111, 5.943797120186965, 5.837065598462608, 5.731950822161844, 5.628050578094132, 5.52496265306893, 5.422287001396774, 5.320455306286043, 5.221983507628347, 5.129415075626478, 5.041691745795149, 4.955339248140727, 4.867524238324627, 4.787587388017668, 4.735329151153565], "y_coordinates": [3.5560116767883296, 3.4509001198935114, 3.340395543749869, 3.228700213592735, 3.120016394657441, 3.0183553237217606, 2.925479205635539, 2.8416856923312537, 2.767247409803197, 2.7024369840456623, 2.647527041052943, 2.602790206819333, 2.5694414990747902, 2.556022169663378, 2.5664025416618945, 2.5978445099590464, 2.647438906382854, 2.712276562761335, 2.789448310922509, 2.8760538064642596, 2.969631651996311, 3.0684369369607913, 3.171599437259069, 3.2787193142686455, 3.3894021965407233, 3.503253712626505, 3.6196864468486423, 3.7364515575757666, 3.850452638704136, 3.958586511626798, 4.058247570093288, 4.149059712761084, 4.23127103586492, 4.305127914478958, 4.368413299578573, 4.411545156305595, 4.423743924085717, 4.402258823076948, 4.355594616421968, 4.29309751737686, 4.224113739197708, 4.157977701072659, 4.09949811872294, 4.04214259934065, 3.978107014766621, 3.905426221611182, 3.8260518056687713, 3.7418831299740543, 3.652607506459477, 3.55601167678833]}}, {"topic_id": "bt-12", "name": " Phase Flow Physics", "lemma_name": null, "term_id": ["physics", "phase", "flow", "equations", "networks", "equation", "PDEs", "moisture", "soil", "hyperelasticity", "fish", "initialization", "materials", "land", "soil moisture", "temperature forecasting", "surface", "data", "machine", "systems", "Flows", "dynamics", "temperature", "Machine Learning", "prediction", "Chemometric", "machine learning", "method", "regularization", "satellite", "media", "Process", "forecasting", "learning", "modeling", "simulation", "fields", "Theory", "problem", "body", "motor", "change", "motion", "battery", "package", "brain atrophy", "Recurrent", "atrophy", "imagery", "DeepONets", "failure", "events", "evolution", "Machine learning", "decisions", "data augmentation", "SVM", "integration", "conversion", "Complexity", "acceleration", "signals", "solution", "world", "Newton", "accuracy", "Order", "situ", "Forecasting", "Activities", "sensor", "science", "network", "Identification", "applications", "resolution", "inverse", "challenge", "occupancy", "latent", "Sparse", "Solution", "modelling", "Mapping", "Cases", "mapping", "learning framework", "Transfer", "field", "plasticity", "parameters", "environment", "effect", "activity", "uncertainty", "ODEs", "Multi", "purpose", "sources", "tool", "fidelity", "diffusion", "augmentation", "feature", "Machine", "level", "estimation", "noise", "System", "Systems", "autoencoders", "Detectors", "dimension", "cost", "properties", "simulations", "order", "Data", "inference", "parameter", "datasets", "correlation", "disease", "selection", "Strategies", "imaging", "ray", "Units", "identification", "Modeling", "AI", "knowledge", "energy", "application", "control", "gradient", "time", "Dataset", "system", "brain", "models", "scale", "function", "Uncertainty", "methods", "approach", "image", "Regression", "Methods", "distribution", "Deep Learning", "problems", "algorithms", "Neural Networks", "Feature"], "x_centroid": 5.3425455478706745, "y_centroid": 0.7609155933288011, "size": 198, "top_doc_id": null, "top_doc_content": ["Developing a machine learning framework for estimating soil moisture\n  with VNIR hyperspectral data", "Inferring incompressible two-phase flow fields from the interface motion\n  using physics-informed neural networks", "Global soil moisture from in-situ measurements using machine learning --\n  SoMo.ml", "Prediction of fish location by combining fisheries data and sea bottom temperature forecasting", "A novel meta-learning initialization method for physics-informed neural\n  networks", "NN-EUCLID: deep-learning hyperelasticity without stress data", "Learning differential equations from data", "Lagrangian PINNs: A causality-conforming solution to failure modes of\n  physics-informed neural networks", "Long-time integration of parametric evolution equations with\n  physics-informed DeepONets", "Understanding and mitigating gradient pathologies in physics-informed\n  neural networks", "Solving the Dirichlet problem for the Monge-Amp\\`ere equation using\n  neural networks", "Partial differential equation regularization for supervised machine\n  learning", "Application of multilayer perceptron with data augmentation in nuclear physics", "Model-free prediction of spatiotemporal dynamical systems with recurrent\n  neural networks: Role of network spectral radius", "Predicting extreme events from data using deep machine learning: when\n  and where", "Zero-phase angle asteroid taxonomy classification using unsupervised\n  machine learning algorithms", "Newton vs the machine: solving the chaotic three-body problem using deep\n  neural networks", "Hierarchical autoregressive neural networks for statistical systems", "Using Long Short-Term Memory (LSTM) and Internet of Things (IoT) for\n  localized surface temperature forecasting in an urban environment", "Machine learning accelerates parameter optimization and uncertainty\n  assessment of a land surface model", "Towards advancing the earthquake forecasting by machine learning of\n  satellite data", "Deep learning-enhanced ensemble-based data assimilation for\n  high-dimensional nonlinear dynamical systems", "Physics-informed neural networks for solving Reynolds-averaged\n  Navier$\\unicode{x2013}$Stokes equations", "Insect cyborgs: Bio-mimetic feature generators improve machine learning\n  accuracy on limited data", "Improving significance of binary black hole mergers in Advanced LIGO\n  data using deep learning : Confirmation of GW151216", "Deep learning and differential equations for modeling changes in\n  individual-level latent dynamics between observation periods", "Physics-constrained deep neural network method for estimating parameters\n  in a redox flow battery", "Optimising simulations for diphoton production at hadron colliders using\n  amplitude neural networks", "SOMOSPIE: A modular SOil MOisture SPatial Inference Engine based on data\n  driven decisions", "Ionospheric activity prediction using convolutional recurrent neural\n  networks", "Stress field prediction in fiber-reinforced composite materials using a\n  deep learning approach", "Machine Learning for semi linear PDEs", "A Bayesian neural network predicts the dissolution of compact planetary\n  systems", "How to trap a gradient flow", "Deep convolutional recurrent autoencoders for learning low-dimensional\n  feature dynamics of fluid systems", "PPINN: Parareal Physics-Informed Neural Network for time-dependent PDEs", "Hidden Markov models as recurrent neural networks: an application to\n  Alzheimer's disease", "Neural network based order parameter for phase transitions and its\n  applications in high-entropy alloys", "Multiscale modeling of inelastic materials with Thermodynamics-based\n  Artificial Neural Networks (TANN)", "Continental-scale land cover mapping at 10 m resolution over Europe\n  (ELC10)", "Identification of release sources in advection-diffusion system by\n  machine learning combined with Green function inverse method", "Sobolev training of thermodynamic-informed neural networks for smoothed\n  elasto-plasticity models with level set hardening", "Interval and fuzzy physics-informed neural networks for uncertain fields", "Deep learning for Chemometric and non-translational data", "Deep Learning strategies for ProtoDUNE raw data denoising", "Appraisal of data-driven and mechanistic emulators of nonlinear\n  hydrodynamic urban drainage simulators", "ODE$^2$VAE: Deep generative second order ODEs with Bayesian neural\n  networks", "Application of deep learning to large scale riverine flow velocity\n  estimation", "Same-different problems strain convolutional neural networks", "A deep learning energy method for hyperelasticity and viscoelasticity", "Deep learning for smart fish farming: applications, opportunities and\n  challenges", "Machine learning initialization to accelerate Stokes profile inversions", "Estimating of the inertial manifold dimension for a chaotic attractor of\n  complex Ginzburg-Landau equation using a neural network"], "top_term_id": null, "convex_hull": {"x_coordinates": [5.442946434020995, 5.3414242997203205, 5.239892546683769, 5.139188598846281, 5.040149880142794, 4.943613814508246, 4.850417825877576, 4.761399338185721, 4.677500680908578, 4.602234696580483, 4.542142756311347, 4.523937005383757, 4.5308940080803115, 4.532045055820533, 4.528646520332038, 4.523151147057169, 4.52182269520051, 4.532335651990035, 4.562366790467388, 4.619578075506112, 4.706132849560871, 4.810494082119126, 4.919204682546618, 5.025350075690365, 5.130299866592328, 5.235956217791562, 5.343800335077246, 5.452136750637916, 5.558083967826435, 5.660960927888674, 5.7611869785214935, 5.859189529538428, 5.946942934036093, 6.005263146920235, 6.040157089901299, 6.059364660812959, 6.070625757488896, 6.081680277762789, 6.100095253666169, 6.123454697854348, 6.134090929068719, 6.118016430632643, 6.076661861790062, 6.014440675348395, 5.935766324115059, 5.845052260897471, 5.746711938503046, 5.645158809739203, 5.543939858674672, 5.442946434020994], "y_coordinates": [1.6749930381774898, 1.6784652721206264, 1.657987316767085, 1.617787312985251, 1.5620934016435077, 1.495133723610239, 1.4211364197538303, 1.3443296309426644, 1.268655559502641, 1.191050021341405, 1.1012901978046803, 0.9959315986425722, 0.8876683685537824, 0.7809432372582242, 0.6711663324513387, 0.5549010731437793, 0.43650643859327437, 0.3232271009426075, 0.22231240804536587, 0.14100090127365578, 0.08251842029936607, 0.04009275333509758, 0.005547739873345216, -0.024619514980818213, -0.04799458356584906, -0.06178263673013188, -0.06344500696983384, -0.05237610409662547, -0.02900226978397987, 0.004993138804923614, 0.04730251046943431, 0.0956136604180468, 0.15388591555876338, 0.23522279852589437, 0.3350316799818599, 0.4474757630250369, 0.5667182507538033, 0.6869223462665363, 0.802307344627324, 0.9103318581833143, 1.0134037788887096, 1.1134990540781393, 1.209956672034506, 1.3016054760970313, 1.387274309604939, 1.465792015897453, 1.535987438313795, 1.5966894201931894, 1.6455179726214606, 1.6749930381774896]}}, {"topic_id": "bt-13", "name": " Demand Mechanism Patterns", "lemma_name": null, "term_id": ["Demand", "Mechanism", "patterns", "forecasting", "Recommendation", "Recommendations", "commerce", "Vehicles", "Web", "e", "price", "B", "B testing", "Choice", "System", "series", "time series", "Risk", "Recommender Systems", "Kernel", "Settings", "extension", "LSTMs", "likelihood ratio", "Stage", "child", "Matching", "trajectories", "MAML", "SVM", "conversion", "Domains", "world", "Volume", "Flexibility", "Healthcare", "step", "Activations", "stock", "Type", "ratio", "Price", "sequence models", "Biases", "stage", "Algorithms", "Embeddings", "testing", "challenge", "Results", "Risk Bounds", "Proceedings", "learning framework", "Buildings", "embeddings", "likelihood", "power", "Bounds", "term", "Power", "Challenges", "architecture", "Predictions", "sequence", "predictions", "time", "Network", "Interpretability", "Classifiers", "Priors", "processing", "framework", "View", "problem", "AI", "distributions", "energy", "application", "Prediction", "Dataset", "Topic", "box", "models", "classification", "loss", "Approximation", "graphs", "Inference", "study", "Modeling", "feature", "Methods", "Policy", "distribution", "Neural Networks", "Application", "Feature", "Approach", "inference", "Attacks", "class", "systems", "Survey", "Classification", "data", "detection", "Problems", "scale", "Data", "Applications"], "x_centroid": 9.050400682524138, "y_centroid": 3.604636442427542, "size": 204, "top_doc_id": null, "top_doc_content": ["Discovering patterns of online popularity from time series", "Predicting e-commerce customer conversion from minimal temporal patterns\n  on symbolized clickstream trajectories", "Offline A/B testing for Recommender Systems", "Web Mining to Inform Locations of Charging Stations for Electric\n  Vehicles", "A two-stage architecture for stock price forecasting by combining SOM\n  and fuzzy-SVM", "Deep-Gap: A deep learning framework for forecasting crowdsourcing\n  supply-demand gap based on imaging time series and residual learning", "Risk Bounds for the Majority Vote: From a PAC-Bayesian Analysis to a\n  Learning Algorithm", "Interacting Attention-gated Recurrent Networks for Recommendation", "An Empirical Characterization of Fair Machine Learning For Clinical Risk\n  Prediction", "Demand Response Method Considering Multiple Types of Flexible Loads in\n  Industrial Parks", "Personalized Academic Research Paper Recommendation System", "Learning to Embed Categorical Features without Embedding Tables for\n  Recommendation", "Field-aware Factorization Machines in a Real-world Online Advertising\n  System", "Defensive forecasting", "Stock price forecast with deep learning", "Multistep Speed Prediction on Traffic Networks: A Graph Convolutional\n  Sequence-to-Sequence Learning Approach with Attention Mechanism", "SAIN: Self-Attentive Integration Network for Recommendation", "The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and\n  the xAUC Metric", "Choice Set Confounding in Discrete Choice", "Kernel-based Approach to Handle Mixed Data for Inferring Causal Graphs", "Risk-Averse Classification", "A Deep Framework for Cross-Domain and Cross-System Recommendations", "Second Hand Price Prediction for Tesla Vehicles", "Music Recommendations in Hyperbolic Space: An Application of Empirical\n  Bayes and Hierarchical Poincar\\'e Embeddings", "Two-stage short-term wind power forecasting algorithm using different\n  feature-learning models", "Combining Outcome-Based and Preference-Based Matching: A Constrained\n  Priority Mechanism", "Demand Response For Residential Uses: A Data Analytics Approach", "ZoomCount: A Zooming Mechanism for Crowd Counting in Static Images", "Estimating Demand Flexibility Using Siamese LSTM Neural Networks", "XGBoostLSS -- An extension of XGBoost to probabilistic forecasting", "Who wrote this book? A challenge for e-commerce", "Evaluating Deep Vs. Wide & Deep Learners As Contextual Bandits For\n  Personalized Email Promo Recommendations", "Observing and Recommending from a Social Web with Biases"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.61884307861328, 8.5004471666275, 8.404905519855346, 8.321838355899652, 8.242294059400347, 8.178147426653153, 8.143395478413348, 8.139087502960445, 8.157481339086607, 8.190667300254832, 8.230735699928115, 8.269776851569462, 8.300069119205013, 8.326111972687793, 8.36856715083225, 8.430794137594637, 8.509411649477455, 8.60103065303559, 8.702501437876373, 8.811444101671027, 8.925633219741135, 9.042843367408294, 9.160682889695138, 9.275926622177838, 9.385808139202894, 9.491110117038565, 9.589822163088487, 9.671068782035807, 9.723477334206347, 9.760329629830588, 9.800061440132527, 9.841370738394804, 9.882387210701763, 9.921240543137753, 9.956060421787118, 9.984976532734215, 10.005633265544894, 9.988660087436868, 9.937732452751824, 9.8666444597485, 9.777995645955999, 9.674385548903429, 9.558413706119902, 9.432679655134516, 9.299782933476386, 9.162323078674616, 9.022899628258312, 8.884112119756583, 8.748560090698538, 8.61884307861328], "y_coordinates": [4.44613790512085, 4.437055403045384, 4.3747630482365905, 4.280919028513825, 4.186108890292603, 4.089726343947814, 3.9867612027482577, 3.8763112461815843, 3.7602635434876346, 3.6405583151738026, 3.5191357817474795, 3.3979361637160608, 3.2788998437089605, 3.1639777404070135, 3.0550768486358244, 2.953759347415696, 2.8614648532234135, 2.779632965423435, 2.7100996661926247, 2.6559759452019582, 2.6206286483171426, 2.607424621403885, 2.618338741417135, 2.6483662958890166, 2.691540887099498, 2.7479480583317843, 2.819349759456529, 2.9070631223357917, 3.012039581124932, 3.125090698751891, 3.236889371340579, 3.347886407104335, 3.4588097732965877, 3.5703874371707682, 3.683347365980305, 3.7984175269786316, 3.916248081329759, 4.031742344127228, 4.1308781760912705, 4.212503493275852, 4.278347657284925, 4.3301400297224415, 4.369609972192354, 4.398486846298615, 4.418500013645179, 4.431378835835995, 4.438852674475018, 4.4426508911662, 4.444502847513494, 4.44613790512085]}}, {"topic_id": "bt-14", "name": " Anomaly Detection with Quantum Annealing", "lemma_name": null, "term_id": ["Anomaly Detection", "quantum", "Quantum", "annealer", "Objects", "artifacts", "contrast", "lattice", "quantum annealer", "removal", "Accurate Vision", "Manipulation", "tissue", "platform", "motion", "beam", "Enhancement", "Modelling", "auto", "enhancement", "era", "LSTMs", "compression", "circuit", "transfer", "classifier", "learning model", "situ", "Taxonomy", "Active Learning", "Neurons", "shape", "machine learning", "Machine", "Distance", "theory", "Accurate", "Testing", "case study", "field", "generation", "tuning", "diffusion", "device", "3D", "noise", "Detectors", "Assessment", "synthesis", "environments", "properties", "Measure", "analysis", "case", "simulation", "series", "Sensing", "self", "Techniques", "source", "imaging", "Values", "Estimation", "processes", "Self", "time series", "detection", "method", "machine", "flow", "Optimization", "Reasoning", "classifiers", "functions", "Flows", "Dataset", "applications", "study", "resolution", "image", "distance", "Application", "Machine Learning", "Deep Learning", "learning", "GAN", "Performance", "reinforcement", "class", "Generation", "images", "Survey", "data", "level", "Problems", "Transformers", "Prediction", "Applications", "classification", "prediction", "Modeling", "time"], "x_centroid": 3.6618044662475584, "y_centroid": 0.7429434286803007, "size": 150, "top_doc_id": null, "top_doc_content": ["Prediction and compression of lattice QCD data using machine learning\n  algorithms on quantum annealer", "Assessment of image generation by quantum annealer", "Deep learning based electrical noise removal enables high spectral\n  optoacoustic contrast in deep tissue", "Simultaneous super-resolution and motion artifact removal in\n  diffusion-weighted MRI using unsupervised deep learning", "On exploring practical potentials of quantum auto-encoder with\n  advantages", "Equivariant flow-based sampling for lattice gauge theory", "S2MS: Self-Supervised Learning Driven Multi-Spectral CT Image\n  Enhancement", "Efficient GAN-Based Anomaly Detection", "Quantum circuit synthesis of Bell and GHZ states using projective\n  simulation in the NISQ era", "Localized adversarial artifacts for compressed sensing MRI", "Anomaly Detection with Score functions based on Nearest Neighbor Graphs", "AITom: Open-source AI platform for cryo-electron tomography data\n  analysis", "ManipulaTHOR: A Framework for Visual Object Manipulation", "V-MAO: Generative Modeling for Multi-Arm Manipulation of Articulated\n  Objects", "Anomaly Detection in Intra-Vehicle Networks", "Effective 3D Humerus and Scapula Extraction using Low-contrast and\n  High-shape-variability MR Data", "Deep learning method to remove chemical, kinetic and electric artifacts\n  on ISEs", "Variational quantum algorithm for Gaussian discrete solitons and their\n  boson sampling", "Quantum neural network autoencoder and classifier applied to an industrial case study", "Anomaly Detection in Time Series with Triadic Motif Fields and\n  Application in Atrial Fibrillation ECG Classification", "Quantum device fine-tuning using unsupervised embedding learning", "Accurate and confident prediction of electron beam longitudinal\n  properties using spectral virtual diagnostics", "Optimization by a quantum reinforcement algorithm", "Resolution enhancement in scanning electron microscopy using deep\n  learning", "PS-Net: Deep Partially Separable Modelling for Dynamic Magnetic\n  Resonance Imaging", "Anomaly Detection in Medical Imaging -- A Mini Review", "Quantum-enhanced machine learning", "Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras", "Animating Arbitrary Objects via Deep Motion Transfer", "Accurate Vision-based Manipulation through Contact Reasoning", "A Probabilistic Framework to Node-level Anomaly Detection in\n  Communication Networks"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.3994202613830575, 4.466960918739764, 4.51554687876165, 4.547035168492415, 4.563282814975765, 4.5661468452554, 4.557484286375024, 4.539152165378339, 4.513007509309047, 4.480907345210851, 4.443016390034529, 4.388164402396115, 4.31409377475214, 4.2292825701314785, 4.140629961428623, 4.047332293051378, 3.9465691955561013, 3.83684369656101, 3.721052021916559, 3.6030008196937695, 3.486496737963657, 3.3752511314761806, 3.262227269583306, 3.1447948165203283, 3.0282170243510116, 2.917757145139119, 2.8186784309484136, 2.7362441338426606, 2.6836419299883745, 2.6888178439079446, 2.7355973286197566, 2.801981373544677, 2.8695521788674543, 2.934458668161122, 2.9980085556446503, 3.0616090602971617, 3.126667401097776, 3.1945907970256164, 3.2667864670598026, 3.3446616301794556, 3.4296235053636974, 3.5230793115916494, 3.62642414484416, 3.739377872656225, 3.85828826491308, 3.9790985837672848, 4.097752091371398, 4.210192049877983, 4.312344209293933, 4.3994202613830575], "y_coordinates": [-0.07256437093019484, 0.017145962525199777, 0.11868602448954337, 0.22968172183120455, 0.3477589614185518, 0.47054365011995386, 0.5956616948037794, 0.7207390023383967, 0.8434014795921748, 0.9612750334334821, 1.0716999405931689, 1.170358426158438, 1.2580969421491035, 1.3403132706468874, 1.419966453937601, 1.4893374732410094, 1.5379119409910087, 1.5585130261950133, 1.5550433483732058, 1.5337015713864046, 1.5006863590954258, 1.4622464882643411, 1.4280243555819012, 1.3976804506388667, 1.3651085455344707, 1.3242024123679454, 1.2688558232385228, 1.1929625502454357, 1.0929122492573742, 0.9791648953641177, 0.8642143448232658, 0.7601232533215905, 0.6672837651783161, 0.5701768915445385, 0.46991513735038865, 0.36856644498505947, 0.2681987568377437, 0.17088001529763522, 0.07867816275392739, -0.006338858404185957, -0.0821031057875127, -0.14654663700685888, -0.1976037376602149, -0.23351656994699818, -0.25314702644826936, -0.255431340929001, -0.23930574715416517, -0.2037064788887343, -0.14763079759681896, -0.07256437093019488]}}, {"topic_id": "bt-15", "name": " Occupancy Policies and Monitoring", "lemma_name": null, "term_id": ["Bandits", "bandits", "policies occupancy", "Monitoring", "occupancy measures", "occupancy", "Losses", "feedback", "Accuracy\n ", "MDPs", "measures", "Processes", "Policy", "Problems", "policies", "Evaluation", "Optimality", "Time", "Convergence", "Task", "batch", "Line", "Skin", "Disease", "Settings", "log", "loop", "Connections", "State", "controllers", "intervals", "Domains", "intelligence", "Policy Gradients", "Active Learning", "symmetry", "Algorithms", "Regression", "Applications", "Gradients", "Confidence", "Message", "policy", "Gap", "price", "Search", "parameter", "Rules", "GNNs", "Systems", "Environments", "Test", "probability", "behavior", "Experts", "Stochastic", "Sets", "Efficient Algorithms", "evaluation", "Approach", "case", "Sensing", "identification", "Transformers", "Planning", "Reinforcement Learning", "Tuning", "loss", "Approximation", "Uncertainty", "Methods", "order", "Performance", "Bounds", "Decision", "Structure", "class", "Prediction", "CUR", "Risk"], "x_centroid": 9.943442643956935, "y_centroid": 0.8925334255587547, "size": 188, "top_doc_id": null, "top_doc_content": ["Non-Markovian policies occupancy measures", "Non-Markovian policies occupancy measures", "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth\n  Settings", "Best arm identification in multi-armed bandits with delayed feedback", "Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits\n  with Super Heavy-Tailed Payoffs", "Policy Optimization for Constrained MDPs with Provable Fast Global\n  Convergence", "Energy-Based Learning for Cooperative Games, with Applications to\n  Valuation Problems in Machine Learning", "No-regret learning for repeated non-cooperative games with lossy bandits", "Safe and Near-Optimal Policy Learning for Model Predictive Control using\n  Primal-Dual Neural Networks", "Bias-Robust Bayesian Optimization via Dueling Bandits", "Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic\n  and Adversarial Linear Bandits Simultaneously", "Time-varying Gaussian Process Bandit Optimization with Non-constant\n  Evaluation Time", "A Decentralized Policy with Logarithmic Regret for a Class of\n  Multi-Agent Multi-Armed Bandit Problems with Option Unavailability\n  Constraints and Stochastic Communication Protocols", "Learning Games and Rademacher Observations Losses", "On First-Order Bounds, Variance and Gap-Dependent Bounds for Adversarial\n  Bandits", "Value Iteration in Continuous Actions, States and Time", "Rotting Bandits", "DiffLoop: Tuning PID controllers by differentiating through the feedback\n  loop", "Active Exploration in Markov Decision Processes", "Efficient Algorithms for Finite Horizon and Streaming Restless\n  Multi-Armed Bandit Problems", "A Sharp Characterization of Linear Estimators for Offline Policy\n  Evaluation", "Bandits with adversarial scaling", "Monitoring and Anomaly Detection Actor-Critic Based Controlled Sensing", "Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER", "Mostly Exploration-Free Algorithms for Contextual Bandits", "PACMAN: PAC-style bounds accounting for the Mismatch between Accuracy\n  and Negative log-loss", "Concurrent bandits and cognitive radio networks", "Empirical Likelihood for Contextual Bandits", "Re-evaluating Evaluation", "Path Consistency Learning in Tsallis Entropy Regularized MDPs", "Lower Bound On the Computational Complexity of Discounted Markov\n  Decision Problems", "Bandits with Side Observations: Bounded vs. Logarithmic Regret", "Policy Gradients Incorporating the Future", "Policy Gradient and Actor-Critic Learning in Continuous Time and Space:\n  Theory and Algorithms", "Variational Policy for Guiding Point Processes", "Task-based End-to-end Model Learning in Stochastic Optimization", "Bandits with Knapsacks", "Gains and Losses are Fundamentally Different in Regret Minimization: The\n  Sparse Case", "Regret Lower Bound and Optimal Algorithm in Finite Stochastic Partial\n  Monitoring"], "top_term_id": null, "convex_hull": {"x_coordinates": [10.078279495239254, 10.163913192261838, 10.24912005185027, 10.332605522099072, 10.413075051102767, 10.489234086955875, 10.559788077752923, 10.623442471588435, 10.678902716556934, 10.724874260752934, 10.760062552270968, 10.783173039205554, 10.792911169651218, 10.787910566278013, 10.752516974659162, 10.677147353285832, 10.573844525479487, 10.454907945213936, 10.332637066462988, 10.217579022507147, 10.110741440871402, 10.009901480746139, 9.91283372313375, 9.817312749036631, 9.721113139457167, 9.622009475397748, 9.51777633786077, 9.406192824360543, 9.293036664801614, 9.208557731441617, 9.165333559914133, 9.12726470465287, 9.117316832655604, 9.130276822530728, 9.152694594339438, 9.171582257379812, 9.183928205609154, 9.196346733104162, 9.215844218187788, 9.249427039182974, 9.303702468388785, 9.369579470160648, 9.43430423791466, 9.502147769951135, 9.578206680085982, 9.667215691796356, 9.768692813879158, 9.877929717810556, 9.985360913471105, 10.078279495239254], "y_coordinates": [0.09107498824596405, 0.15847457486328848, 0.23055243471820053, 0.30704292830743596, 0.3876804161277303, 0.47219925867581936, 0.5603338164484387, 0.6518184499423244, 0.7463875196542119, 0.8437753860808366, 0.9437164097189346, 1.0459449510652414, 1.1501953706164925, 1.256117984470539, 1.3462011124070927, 1.4060672419011142, 1.4445520114396144, 1.4707725877055984, 1.49384613738207, 1.5214882250534691, 1.5537841959401004, 1.5882354896938249, 1.622341483790487, 1.653601555705931, 1.6795150829160002, 1.697581442896539, 1.7053000131233915, 1.700168292705589, 1.6763572389701253, 1.6178601188512032, 1.5219912846059493, 1.424828138843037, 1.3242703495595707, 1.2198725841226472, 1.112548945232161, 1.0032478581119544, 0.8936585944655899, 0.7861852526541734, 0.6832610475128779, 0.5873191938768776, 0.5005516495824079, 0.4158234376949668, 0.3276139135348134, 0.24457230513642583, 0.1760195177390894, 0.13021669575629688, 0.10014833964178115, 0.06941683826912368, 0.053466353589790475, 0.09107498824596404]}}, {"topic_id": "bt-16", "name": " Clustering Information Weighting", "lemma_name": null, "term_id": ["Clustering", "clustering", "information", "weighting", "DAGs", "Similarity", "Spectral Clustering", "matrix factorization", "manifold", "CUR", "Subspaces", "factorization", "Feature", "Cluster Forests", "Co", "Number", "Directions", "Challenges", "dimension", "view", "distance", "selection", "reduction", "problem", "matrix", "Bounds", "cell", "approximations", "Research", "CUR O", "Elimination", "bi", "trade", "Decompositions", "directions", "graph structure", "Sampling", "extension", "dimension reduction", "group", "Efficient Learning", "transform", "Matching", "intervals", "Counting", "SNE", "subspace", "algorithm", "omics", "recovery", "RL", "length", "O CUR", "O", "set", "space", "Distance", "Graph", "Tree", "complexity", "Risk Bounds", "Autoencoders", "Message", "measure", "Constraints", "samples", "Architectures", "hardware", "Dimensions", "purpose", "pattern", "sources", "spaces", "Estimators", "parameter", "noise", "regularization", "Consistency", "Trees", "Power", "Insights", "discovery", "media", "Processes", "datasets", "Techniques", "Values", "sample", "Forests", "way", "graph", "method", "structure", "View", "functions", "body", "Information", "diagnosis", "Datasets", "performance", "layer", "applications", "stage", "graphs", "function", "Uncertainty", "methods", "Regression", "feature", "Machine", "Graphs", "algorithms", "Performance", "model", "analysis", "images", "optimization", "level", "Problems", "framework", "Data", "Risk"], "x_centroid": 6.918368153455781, "y_centroid": -1.2059205092671441, "size": 164, "top_doc_id": null, "top_doc_content": ["Determining Optimal Number of k-Clusters based on Predefined\n  Level-of-Similarity", "scICML: Information-theoretic Co-clustering-based Multi-view Learning\n  for the Integrative Analysis of Single-cell Multi-omics data", "Multi-view graph structure learning using subspace merging on Grassmann\n  manifold", "A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions", "On the Vapnik-Chervonenkis dimension of products of intervals in\n  $\\mathbb{R}^d$", "Minimum description length as an objective function for non-negative\n  matrix factorization", "Binary matrix factorization on special purpose hardware", "Spectral Clustering via the Power Method -- Provably", "Unified Spectral Clustering with Optimal Graph", "Structures of Spurious Local Minima in $k$-means", "Resampling methods for parameter-free and robust feature selection with\n  mutual information", "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs", "A multi-stage semi-supervised improved deep embedded clustering method\n  for bearing fault diagnosis under the situation of insufficient labeled\n  samples", "Learning Gaussian DAGs from Network Data", "Adversarial Deep Embedded Clustering: on a better trade-off between\n  Feature Randomness and Feature Drift", "Multimodal-Aware Weakly Supervised Metric Learning with Self-weighting\n  Triplet Loss", "Feature Selection Approach with Missing Values Conducted for Statistical\n  Learning: A Case Study of Entrepreneurship Survival Dataset", "Deep clustering: On the link between discriminative models and K-means", "Exploring Bayesian Models for Multi-level Clustering of Hierarchically\n  Grouped Sequential Data", "Hierarchical Qualitative Clustering: clustering mixed datasets with\n  critical qualitative information", "On the Consistency of $k$-means++ algorithm", "Restructuring Graph for Higher Homophily via Learnable Spectral\n  Clustering", "Determinantal Clustering Processes - A Nonparametric Bayesian Approach\n  to Kernel Based Semi-Supervised Clustering", "Unsupervised deep clustering for predictive texture pattern discovery in\n  medical images", "Learning non-parametric Markov networks with mutual information", "A unified framework for spectral clustering in sparse graphs", "Leveraging Union of Subspace Structure to Improve Constrained Clustering", "A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and\n  Future Directions", "Dynamic Feature Scaling for K-Nearest Neighbor Algorithm", "Cluster Forests", "Greedy bi-criteria approximations for $k$-medians and $k$-means", "From Principal Subspaces to Principal Components with Linear\n  Autoencoders", "Feature Selection Based on Unique Relevant Information for Health Data", "Dissecting graph measure performance for node clustering in LFR\n  parameter space", "Distributed Graph Clustering by Load Balancing", "Practical applications of metric space magnitude and weighting vectors", "Similarity-Based Clustering for Enhancing Image Classification\n  Architectures", "Counting and Sampling from Markov Equivalent DAGs Using Clique Trees", "Auto-weighted Multi-view Feature Selection with Graph Optimization", "Minimum Message Length Clustering Using Gibbs Sampling", "Challenges of Feature Selection for Big Data Analytics", "Consistency of regularized spectral clustering in degree-corrected mixed\n  membership model", "Continuum directions for supervised dimension reduction", "Multi-rank Sparse Hierarchical Clustering", "Multiview Representation Learning for a Union of Subspaces", "A Quasi-Newton algorithm on the orthogonal manifold for NMF with\n  transform learning", "Efficient Locally Optimal Number Set Partitioning for Scheduling,\n  Allocation and Fair Selection", "Provably noise-robust, regularised $k$-means clustering", "Exploring dual information in distance metric learning for clustering", "Fair Hierarchical Clustering", "Improved Approximation for Fair Correlation Clustering"], "top_term_id": null, "convex_hull": {"x_coordinates": [7.601577281951903, 7.55674336549187, 7.5118733879583734, 7.465809634836042, 7.417394391609494, 7.365469943763364, 7.308878576782277, 7.246462576150857, 7.177064227353733, 7.09952581587553, 7.012853808463409, 6.917787361347917, 6.816105262459397, 6.70960042845829, 6.600098752972243, 6.491186362990067, 6.389059077562659, 6.300123886507131, 6.22908988832838, 6.165008707879835, 6.104590118389395, 6.050626445479411, 6.005911740598735, 5.973240055196218, 5.955405440720707, 5.955201948621055, 5.97542363034611, 6.018864537344721, 6.087526551761842, 6.172115947229889, 6.260854476436542, 6.3521670459550075, 6.4455115019688005, 6.540345690661436, 6.6361274582164285, 6.732314650817291, 6.828365114647538, 6.923736695890689, 7.017890452183123, 7.112126691367683, 7.211148533191417, 7.313007273449783, 7.412172177075714, 7.502943659886578, 7.579622137699749, 7.636508026332592, 7.667901741602479, 7.668299569948168, 7.6435257803973755, 7.601577281951905], "y_coordinates": [-1.1704062223434448, -1.0737305148382315, -0.971771279473784, -0.8680705671201694, -0.7661704286474527, -0.6696129149257011, -0.5819400768249808, -0.5066939652153583, -0.4474166309668998, -0.4076501249496717, -0.3902813292300582, -0.3912827918118024, -0.40247838839270905, -0.4156356136740455, -0.4226853158612949, -0.4242777710560208, -0.43399053095195056, -0.4664471950626209, -0.5335843924645632, -0.6209596839880357, -0.7183601894277691, -0.8227720611758926, -0.9311835177603573, -1.0405827777091148, -1.147958059550117, -1.2502975818113158, -1.3445895630206617, -1.4278222217061078, -1.4972278735814895, -1.5535370755530613, -1.5996906433697597, -1.637980637006392, -1.6706284521788815, -1.6998554846031513, -1.727883129995124, -1.7569327840707238, -1.7892258425458727, -1.8269837011364947, -1.872389061558887, -1.905463955690599, -1.8799860148333625, -1.8352854325349062, -1.7784963716814448, -1.7109260056805067, -1.6338815079396216, -1.54867005186632, -1.456598810868131, -1.3590389593573575, -1.2618178452131867, -1.170406222343445]}}, {"topic_id": "bt-17", "name": " Explanation and Logic", "lemma_name": null, "term_id": ["explanation", "background", "Logic", "survival", "Proceedings", "Adaptive", "Activation Functions", "Class", "predictions", "machine", "Interpretability", "Theory", "Reasoning", "knowledge", "system", "box", "C", "Change", "heterogeneity", "Detecting", "D", "Learnability", "constraints", "MAML", "itemsets", "SHAP", "algorithm", "latency", "project", "Geometry", "search", "Taxonomy", "product", "science", "machine learning", "Approach", "Prediction", "Machine Learning", "theory", "decision", "Incremental Learning", "software", "Confidence", "research", "P", "activation", "type", "Validation", "Overview", "tool", "Search", "terms", "Errors", "Risk", "Decision", "Trees", "Rank", "probability", "Assessment", "discovery", "measures", "synthesis", "Understanding", "Making", "Features", "learning models", "Strategies", "policies", "Factors", "classifiers", "design", "Tasks", "Experiments", "learning", "space", "Tuning", "Models", "models", "Approximation", "study", "function", "distribution", "problems", "algorithms", "Neural Networks", "network", "Feature", "Performance", "level", "Problems", "framework", "approach", "Applications", "classification", "prediction", "time", "Application"], "x_centroid": 7.481959767394013, "y_centroid": 3.2526585256660376, "size": 182, "top_doc_id": null, "top_doc_content": ["Avoiding C-hacking when evaluating survival distribution predictions\n  with discrimination measures", "Refining neural network predictions using background knowledge", "Theory In, Theory Out: The uses of social theory in machine learning for\n  social science", "FedorAS: Federated Architecture Search under system heterogeneity", "False perfection in machine prediction: Detecting and assessing\n  circularity problems in machine learning", "Balanced background and explanation data are needed in explaining deep learning models with SHAP: An empirical study on clinical decision making", "A robust algorithm for explaining unreliable machine learning survival\n  models using the Kolmogorov-Smirnov bounds", "Post-hoc explanation of black-box classifiers using confident itemsets", "Neural Algorithmic Reasoning", "AOWS: Adaptive and optimal network width search with latency constraints", "Efficient Probabilistic Logic Reasoning with Graph Neural Networks", "XAI-P-T: A Brief Review of Explainable Artificial Intelligence from\n  Practice to Theory", "The ALAMO approach to machine learning", "API design for machine learning software: experiences from the\n  scikit-learn project", "NeuPSL: Neural Probabilistic Soft Logic", "Logical Activation Functions: Logit-space equivalents of Boolean\n  Operators", "Explaining how your AI system is fair", "Explaining a black-box using Deep Variational Information Bottleneck\n  Approach", "Explaining Explanations: An Overview of Interpretability of Machine\n  Learning", "Why KDAC? A general activation function for knowledge discovery", "Proceedings of the 2017 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2017)", "Organization of machine learning based product development as per ISO\n  26262 and ISO/PAS 21448", "Local Explanations via Necessity and Sufficiency: Unifying Theory and\n  Practice", "Margin-distancing for safe model explanation", "Proceedings of the Sixteenth Workshop on Logical Frameworks and\n  Meta-Languages: Theory and Practice", "Assessing the Local Interpretability of Machine Learning Models", "Class-Incremental Learning with Generative Classifiers", "Learning to Rank based on Analogical Reasoning", "Look Before You Leap! Designing a Human-Centered AI System for Change\n  Risk Assessment"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.6950225830078125, 6.642732116238423, 6.608008019359802, 6.590852495012389, 6.591267745836626, 6.609263758473985, 6.6455922513968, 6.702348732261371, 6.780849820163352, 6.86799821241889, 6.951862018405708, 7.038237390663519, 7.132879722239378, 7.234468226668807, 7.339416789990535, 7.444147415862992, 7.5463637263715375, 7.646359139865732, 7.744739179168571, 7.842032828411698, 7.938379904555959, 8.033796842179276, 8.128300026185652, 8.217507143718842, 8.2771291267852, 8.284187828691252, 8.269013176066741, 8.25534267459686, 8.242343970034446, 8.228634547654876, 8.212998050910889, 8.194268717305754, 8.171280796372168, 8.142607423144613, 8.102941686015928, 8.044003554900598, 7.958487947728518, 7.8513287987100835, 7.735368240832664, 7.623580616980937, 7.524994039388603, 7.434365928583219, 7.343229652996673, 7.2456060686873505, 7.14354514665602, 7.040713804398067, 6.94077895940888, 6.847407529183848, 6.7642664312183625, 6.695022583007811], "y_coordinates": [3.5967853069305407, 3.504962092254233, 3.4013279449318046, 3.2903932349413427, 3.176668332260934, 3.0646706642876325, 2.959590154769767, 2.867835083316244, 2.7949546683974624, 2.7309727457460684, 2.6642741706823774, 2.598238212514269, 2.5377616725638314, 2.4896980774357775, 2.461527368536651, 2.460686708302814, 2.488574045557285, 2.534383749238509, 2.5858394965836173, 2.6330150455804238, 2.6779333299966277, 2.726405675561819, 2.784244933217416, 2.8565802926151416, 2.9454469645446317, 3.050513449725482, 3.1602115504222583, 3.267555935363996, 3.3731907148847116, 3.477965968523257, 3.5828534583470053, 3.6888619979371096, 3.7970004096842174, 3.907746725926579, 4.013691672191049, 4.101382258608457, 4.158112386867596, 4.181668933222258, 4.176618773782427, 4.147642279387868, 4.100269021842926, 4.043099525015814, 3.98542747873937, 3.9339326056507034, 3.88685726256993, 3.840744644058367, 3.792137944677331, 3.7375803589881356, 3.6736150815521005, 3.59678530693054]}}, {"topic_id": "bt-18", "name": " Generative Adversarial Networks (GANs) and Image Generation", "lemma_name": null, "term_id": ["GANs", "GAN", "Image", "StyleGAN", "3D", "resolution", "AdaGAN", "maps", "Imbalance", "C", "failure", "frame", "Integration", "videos", "Effects", "inverse problems", "examples", "omics", "Type", "Geometry", "RNN", "Video", "Way", "Networks", "Models", "inverse", "modal", "Testing", "commerce", "reconstruction", "head", "networks", "Distributions", "stochastic", "Directions", "Test", "satellite", "priors", "Generation", "series", "Generalization", "Priors", "segmentation", "Evaluation", "Forests", "time series", "Manipulation", "structure", "Model", "View", "application", "Data", "Depth", "Inference", "time", "image", "modeling", "distribution", "problems", "Feature", "Performance", "Structure", "images", "Training", "level", "training", "Problems", "framework", "scale", "Applications", "classification", "Application", "End", "network", "Approach"], "x_centroid": 3.1235059367285833, "y_centroid": 2.261325801175738, "size": 126, "top_doc_id": null, "top_doc_content": ["GAN based ball screw drive picture database enlargement for failure\n  classification", "Image to Image Translation : Generating maps from satellite images", "Exploiting Spatial Dimensions of Latent in GAN for Real-time Image\n  Editing", "Integration of AI and mechanistic modeling in generative adversarial\n  networks for stochastic inverse problems", "GAN based Data Augmentation to Resolve Class Imbalance", "FREGAN : an application of generative adversarial networks in enhancing\n  the frame rate of videos", "OmiTrans: generative adversarial networks based omics-to-omics\n  translation framework", "StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation", "Bayesian GAN", "Simple yet Effective Way for Improving the Performance of GAN", "Invertible Image Rescaling", "Rethinking Sampling in 3D Point Cloud Generative Adversarial Networks", "Forging new worlds: high-resolution synthetic galaxies with chained\n  generative adversarial networks", "On Predicting Generalization using GANs", "Wasserstein Proximal of GANs", "3D Object Reconstruction from a Single Depth View with Adversarial\n  Learning", "AdaGAN: Boosting Generative Models", "2-Wasserstein Approximation via Restricted Convex Potentials with\n  Application to Improved Training for GANs", "InterFaceGAN: Interpreting the Disentangled Face Representation Learned\n  by GANs", "Super-resolution of Omnidirectional Images Using Adversarial Learning", "Building 3D Generative Models from Minimal Data", "Image Super-Resolution Using VDSR-ResNeXt and SRCGAN", "GANs May Have No Nash Equilibria", "GIRAFFE HD: A High-Resolution 3D-aware Generative Model", "Robust Conditional GAN from Uncertainty-Aware Pairwise Comparisons", "Semi-supervised Conditional GANs", "On the Effects of Batch and Weight Normalization in Generative\n  Adversarial Networks", "The Variational Homoencoder: Learning to learn high capacity generative\n  models from few examples", "StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN", "Deformable Generator Network: Unsupervised Disentanglement of Appearance\n  and Geometry", "Shape-consistent Generative Adversarial Networks for multi-modal Medical\n  segmentation maps", "Image Difficulty Curriculum for Generative Adversarial Networks (CuGAN)", "GAN You Do the GAN GAN?", "Diffusion Models Beat GANs on Image Synthesis", "Any-resolution Training for High-resolution Image Synthesis", "Type I Attack for Generative Models", "C-RNN-GAN: Continuous recurrent neural networks with adversarial\n  training"], "top_term_id": null, "convex_hull": {"x_coordinates": [2.689330339431763, 2.7187561292697757, 2.7664490371573685, 2.820726764193955, 2.8750917244651673, 2.929433205340023, 2.9840340281962514, 3.0391770144115804, 3.0951449853637376, 3.152220762430452, 3.210687166989452, 3.2708270204184653, 3.332923144095219, 3.3976695230475533, 3.467569530295653, 3.5393107156753216, 3.608035327408401, 3.669347264833026, 3.7200320125067274, 3.757154488645529, 3.781706677558745, 3.7999681845081867, 3.8181347642624344, 3.8366324559790392, 3.8519332663938326, 3.860432067395222, 3.8585243279931922, 3.8436766956632344, 3.8166371671300303, 3.778779924276701, 3.7314791489863737, 3.6761090231421676, 3.6140437286272085, 3.5466574473246184, 3.475324361117521, 3.401418651889039, 3.32661645587581, 3.2551805901365825, 3.1916281842277767, 3.1337045652215156, 3.0766724762386604, 3.0188267307267673, 2.9609139072879302, 2.903750521388493, 2.8481530884947994, 2.794940088991148, 2.7462890927691093, 2.7081085079198486, 2.6869412762163907, 2.6893303394317623], "y_coordinates": [2.212078809738159, 2.1434008034229715, 2.0793993050637916, 2.01863885293525, 1.9602047084506484, 1.9038235943175272, 1.8492617575651673, 1.7962854452228496, 1.744660904319853, 1.6941543818854594, 1.6445321249489486, 1.5955603805396006, 1.5470053956866958, 1.5044846342561176, 1.5103814871563326, 1.555601209030057, 1.614528781905419, 1.6698108390094846, 1.7252395163092646, 1.7878321336227017, 1.859969211689725, 1.9377880261978417, 2.0171465533197233, 2.095934948274941, 2.1734360348962034, 2.248959805048628, 2.3218163519576516, 2.391497599475767, 2.4580524746167356, 2.5216361982040603, 2.582403991061246, 2.6405110740117945, 2.6961126678792113, 2.749363993486998, 2.800420271658658, 2.8494367232176963, 2.8944374020710315, 2.9151897994110283, 2.8882496699549813, 2.828903966668423, 2.766589266287147, 2.7125171351494446, 2.663163703293893, 2.6145847708566596, 2.562836137973912, 2.5039763451955532, 2.4359594155472215, 2.361942663220675, 2.2859683680172176, 2.2120788097381587]}}, {"topic_id": "bt-19", "name": " Neural Networks and Generalization", "lemma_name": null, "term_id": ["ReLU", "Neural Networks", "generalization", "perspective", "parallelism", "landscape", "PyTorch", "robustness", "networks", "Units", "Model", "Deep Learning", "error", "AdaPT", "performance", "layer", "loss", "Training", "GNNs", "Regularization", "Understanding", "distribution", "CNNs", "Experiments", "Impact", "platform", "Task", "weight", "Elimination", "path distance", "boundaries", "guarantees", "Perturbations", "directions", "gradients", "improvement", "DNNs", "humans", "descent", "Learn", "D", "log", "era", "Integration", "limit", "Context", "Convolutions", "Counting", "SNE", "k", "MLIR", "Activations", "Point", "Hardware", "RNN", "techniques", "Nets", "Neurons", "shape", "Depth", "Analysis", "training", "Distance", "theory", "Case", "Accurate", "Results", "Incremental Learning", "backpropagation", "Workloads", "Labels", "convergence", "hardware", "field", "activation", "type", "parameters", "path", "Tensor", "Gap", "Benefits", "Devices", "importance", "tuning", "Search", "terms", "Bit", "Errors", "device", "Networks", "Signals", "Monte Carlo", "Number", "noise", "Power", "approximation", "Challenges", "layers", "object", "priors", "maps", "Sets", "Efficient Algorithms", "Measure", "Performance", "parameter", "Scale", "Generalization", "learning models", "source", "Compression", "Image", "sparse", "View", "classifiers", "functions", "Flows", "AI", "energy", "dynamics", "Information", "framework", "Approach", "Dataset", "Representations", "Convergence", "rank", "Tuning", "approach", "CUR", "Approximation", "function", "recognition", "Algorithms", "Applications", "modeling", "Methods", "distance", "Guarantees", "algorithms", "models", "Theory", "Feature", "inference", "Bounds", "3D", "Structure", "model", "class", "Generation", "Survey", "Classification", "Features", "learning"], "x_centroid": 6.474433942274614, "y_centroid": 1.9350091235003488, "size": 297, "top_doc_id": null, "top_doc_content": ["How many degrees of freedom do we need to train deep networks: a loss\n  landscape perspective", "FuNNscope: Visual microscope for interactively exploring the loss\n  landscape of fully connected neural networks", "High-dimensional dynamics of generalization error in neural networks", "When does gradient descent with logistic loss find interpolating\n  two-layer networks?", "Layer rotation: a surprisingly powerful indicator of generalization in\n  deep networks?", "Deep Learning modeling of Limit Order Book: a comparative perspective", "Deep Rewiring: Training very sparse deep networks", "On the training of sparse and dense deep neural networks: less\n  parameters, same performance", "AdaPT: Fast Emulation of Approximate DNN Accelerators in PyTorch", "Understanding Global Loss Landscape of One-hidden-layer ReLU Networks,\n  Part 2: Experiments and Analysis", "Detecting Dead Weights and Units in Neural Networks", "Leapfrogging for parallelism in deep neural networks", "The developmental trajectory of object recognition robustness: children are like small adults but unlike big deep neural networks", "Accelerating GMRES with Deep Learning in Real-Time", "Dendritic error backpropagation in deep cortical microcircuits", "Low-rank Gradient Approximation For Memory-Efficient On-device Training\n  of Deep Neural Network", "Deeper-GXX: Deepening Arbitrary GNNs", "Model of the Weak Reset Process in HfOx Resistive Memory for Deep\n  Learning Frameworks", "Quantifying Point-Prediction Uncertainty in Neural Networks via Residual\n  Estimation with an I/O Kernel", "Model-based Deep Learning Receiver Design for Rate-Splitting Multiple\n  Access", "Do ideas have shape? Plato's theory of forms as the continuous limit of\n  artificial neural networks", "Model-Driven Deep Learning Based Channel Estimation and Feedback for\n  Millimeter-Wave Massive Hybrid MIMO Systems", "Learning strides in convolutional neural networks", "Non-iterative recomputation of dense layers for performance improvement\n  of DCNN", "Gradient Descent Optimizes Infinite-Depth ReLU Implicit Networks with\n  Linear Widths", "PyTorch: An Imperative Style, High-Performance Deep Learning Library", "On sparse connectivity, adversarial robustness, and a novel model of the\n  artificial neuron", "Regularization for Unsupervised Deep Neural Nets", "Understanding the Generalization of Adam in Learning Neural Networks\n  with Proper Regularization", "RePr: Improved Training of Convolutional Filters", "DeepWiFi: Cognitive WiFi with Deep Learning", "Tensor Normalization and Full Distribution Training", "Gradient Descent Provably Optimizes Over-parameterized Neural Networks", "Towards Certifying L-infinity Robustness using Neural Networks with\n  L-inf-dist Neurons", "SERF: Towards better training of deep neural networks using log-Softplus\n  ERror activation Function", "On the importance of single directions for generalization", "Generalizing Aggregation Functions in GNNs:High-Capacity GNNs via\n  Nonlinear Neighborhood Aggregators", "Improving Deep Neural Networks with Probabilistic Maxout Units", "Interlocking Backpropagation: Improving depthwise model-parallelism", "Training and Inference with Integers in Deep Neural Networks", "A Robust Initialization of Residual Blocks for Effective ResNet Training\n  without Batch Normalization", "Efficient Algorithms for Learning Depth-2 Neural Networks with General\n  ReLU Activations", "Improving performance of deep learning models with axiomatic attribution\n  priors and expected gradients", "On the Benefits of Invariance in Neural Networks", "Gradient Descent on Two-layer Nets: Margin Maximization and Simplicity\n  Bias", "Deep orthogonal linear networks are shallow", "Why bigger is not always better: on finite and infinite neural networks", "Convergence of Edge Computing and Deep Learning: A Comprehensive Survey", "Enabling On-Device CNN Training by Self-Supervised Instance Filtering\n  and Error Map Pruning", "Is Joint Training Better for Deep Auto-Encoders?", "Label-Based Diversity Measure Among Hidden Units of Deep Neural\n  Networks: A Regularization Method"], "top_term_id": null, "convex_hull": {"x_coordinates": [5.573710441589356, 5.563630409682914, 5.554365245537051, 5.560117773146297, 5.594895980500352, 5.661644865372116, 5.746513008879594, 5.83491054260138, 5.921819404952011, 6.009392838498883, 6.0999575230966805, 6.195840138600083, 6.299329865779126, 6.412127281311166, 6.534797825748929, 6.663300736687945, 6.791662486142231, 6.913902825292038, 7.024041505317611, 7.116098277399203, 7.1840928927170555, 7.230814987796436, 7.2717772088126065, 7.290986204669373, 7.292059146791918, 7.286081158604981, 7.282736463792191, 7.280099061090306, 7.270510814789544, 7.244206805180462, 7.19187403377937, 7.118408179391658, 7.031443164727994, 6.937526690115167, 6.839055200286526, 6.737433595694625, 6.634066776792016, 6.53035964403125, 6.42770582982535, 6.32655580543555, 6.225719523280662, 6.1238426551469445, 6.019570872820661, 5.911549848088066, 5.799578067701565, 5.695867954011939, 5.6201951593177935, 5.58495082171058, 5.576083393387438, 5.573710441589355], "y_coordinates": [2.110185146331787, 1.9893993699303032, 1.8743696451437701, 1.767930970279612, 1.6728577192798786, 1.5884819518098912, 1.508909424002572, 1.4282875390951704, 1.347642193544678, 1.273152727440789, 1.2111231164017946, 1.1678573360459852, 1.1488216379563643, 1.1463329448623976, 1.1444685735517142, 1.142201095087467, 1.1448919122310768, 1.1579246437210347, 1.1866829082958321, 1.2365503246939613, 1.3129105116539126, 1.4131921518089072, 1.516192776209208, 1.6239344758851215, 1.7355163548406172, 1.8483423055034047, 1.9600976307626425, 2.0708010222349893, 2.1815979300800854, 2.289146300280825, 2.3843338926477426, 2.4688556633577226, 2.54664587517957, 2.620301608523807, 2.687309585345197, 2.743935897698568, 2.786446637638746, 2.811107897220557, 2.8142241688130816, 2.795314140523623, 2.7594872191417705, 2.712412662875955, 2.6597597299346067, 2.607197678526155, 2.5592947877960293, 2.5087635893632423, 2.441093314715452, 2.3465336052132435, 2.232498069098714, 2.1101851463317867]}}, {"topic_id": "bt-2", "name": " Graph Theory", "lemma_name": null, "term_id": ["graph", "Graphs", "geometry", "drug", "Community", "graphs", "Networks", "Pooling", "likelihood", "Structure", "ChemoVerse", "Chemi net", "CheXpert", "Chemi", "Features", "Network", "structure", "body", "network", "3D", "approaches", "PCA", "Recommender Systems", "net", "Recurrent", "path distance", "bi", "health", "graph structure", "depth", "feature learning", "group", "traversal", "limit", "likelihood ratio", "message", "mechanism", "Node Classification", "Covariates", "k", "Approximations", "Penalties", "signals", "intelligence", "sampling", "ratio", "reliability", "Neighborhood", "prediction", "Representations", "layer", "testing", "Graph", "monitoring", "dataset", "Tree", "Solution", "learning framework", "Encoders", "path", "generation", "Dimensions", "pattern", "tool", "spaces", "power", "Exploration", "Distributions", "Rules", "GNNs", "Distribution", "Trees", "approximation", "Regularization", "discovery", "properties", "Measure", "task", "systems", "Generation", "fields", "Recommendation", "Priors", "CNNs", "Manipulation", "level", "View", "Reasoning", "design", "dynamics", "application", "space", "process", "information", "Prediction", "representation", "Identification", "forecasting", "function", "recognition", "Uncertainty", "Algorithms", "feature", "Embeddings", "modeling", "Machine", "attention", "distance", "estimation", "inference", "Scale", "Approach", "networks", "Image", "Survey", "detection", "method", "Problems", "framework", "approach"], "x_centroid": 5.2989310876034095, "y_centroid": -0.9013632963362493, "size": 209, "top_doc_id": null, "top_doc_content": ["Chemi-net: a graph convolutional network for accurate drug property\n  prediction", "Molecular geometry prediction using a deep generative graph neural\n  network", "Spatial-temporal associations representation and application for process monitoring using graph convolution neural network", "GOPHER: Categorical probabilistic forecasting with graph structure via\n  local continuous-time dynamics", "Learning the Structure of Dynamic Probabilistic Networks", "Community detection, pattern recognition, and hypergraph-based learning:\n  approaches using metric geometry and persistent homology", "Graph Decipher: A transparent dual-attention graph neural network to\n  understand the message-passing mechanism for the node classification", "Collaborative likelihood-ratio estimation over graphs", "N-body Networks: a Covariant Hierarchical Neural Network Architecture\n  for Learning Atomic Potentials", "Learning from Heterogeneous Data Based on Social Interactions over\n  Graphs", "Predicting Attributes of Nodes Using Network Structure", "Molecular graph generation with Graph Neural Networks", "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features\n  Learning from a Language Model", "Learning Robust Node Representations on Graphs", "Restricted maximum-likelihood method for learning latent variance\n  components in gene expression data with known and unknown confounders", "Network Embedding: on Compression and Learning", "Detecting Weak but Hierarchically-Structured Patterns in Networks", "Scalable Fragment-Based 3D Molecular Design with Reinforcement Learning", "Structured dataset documentation: a datasheet for CheXpert", "Generating 3D Molecular Structures Conditional on a Receptor Binding\n  Site with Deep Generative Models", "EvenNet: Ignoring Odd-Hop Neighbors Improves Robustness of Graph Neural\n  Networks", "Purine: A bi-graph based deep learning framework", "Protein secondary structure prediction using deep convolutional neural\n  fields", "NAGphormer: Neighborhood Aggregation Graph Transformer for Node Classification in Large Graphs", "Rethinking the Setting of Semi-supervised Learning on Graphs", "Convolutional Poisson Gamma Belief Network", "Operator Autoencoders: Learning Physical Operations on Encoded Molecular\n  Graphs", "Learning Compact Geometric Features", "Surface Networks", "Tree Structure-Aware Graph Representation Learning via Integrated\n  Hierarchical Aggregation and Relational Metric Learning", "Towards Interpretable Sparse Graph Representation Learning with\n  Laplacian Pooling", "Graph Classification Based on Skeleton and Component Features", "Properly-weighted graph Laplacian for semi-supervised learning", "Learning Local Neighboring Structure for Robust 3D Shape Representation", "ChemoVerse: Manifold traversal of latent spaces for novel molecule\n  discovery", "Augmentation-Free Self-Supervised Learning on Graphs", "Three-body renormalization group limit cycles based on unsupervised\n  feature learning", "Random sampling of bandlimited signals on graphs", "What graph neural networks cannot learn: depth vs width", "Invariance Principle Meets Out-of-Distribution Generalization on Graphs", "Markov Random Geometric Graph (MRGG): A Growth Model for Temporal\n  Dynamic Networks", "Heterogeneous-Temporal Graph Convolutional Networks: Make the Community\n  Detection Much Better", "Pharmacoprint -- a combination of pharmacophore fingerprint and\n  artificial intelligence as a tool for computer-aided drug design", "On the equivalence between graph isomorphism testing and function\n  approximation with GNNs", "GraphZoom: A multi-level spectral approach for accurate and scalable\n  graph embedding", "Learning from graphs with structural variation", "Algorithms for Bayesian network modeling and reliability inference of\n  complex multistate systems: Part II-Dependent systems", "Edge Contraction Pooling for Graph Neural Networks", "Multi-task graph neural networks for simultaneous prediction of global\n  and atomic properties in ferromagnetic systems", "Evaluating Link Prediction Accuracy on Dynamic Networks with Added and\n  Removed Edges", "Equipping SBMs with RBMs: An Explainable Approach for Analysis of\n  Networks with Covariates", "Shortest path distance in random k-nearest neighbor graphs", "Structure Learning for Directed Trees", "Graph Neural Networks with Precomputed Node Features", "Community Detection on Mixture Multi-layer Networks via Regularized\n  Tensor Decomposition", "A Graph VAE and Graph Transformer Approach to Generating Molecular\n  Graphs", "Deep Learning Approach on Information Diffusion in Heterogeneous\n  Networks"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.064290523529053, 6.100401897756911, 6.143147599825881, 6.183749476154659, 6.213429373161954, 6.223409137266472, 6.204917817709133, 6.1540419851349855, 6.080155429912922, 5.993586164353652, 5.900134530182792, 5.8017597879738005, 5.6992432640276505, 5.593363801127443, 5.48490024205627, 5.374631429597229, 5.263336206533415, 5.15179144050924, 5.040718392978882, 4.930776397752014, 4.82262154461223, 4.71690992334312, 4.614297623728282, 4.515440735551304, 4.423572037541315, 4.359574949161289, 4.349300278498622, 4.381621968841609, 4.425480063997336, 4.472103956248109, 4.5214388119741376, 4.573990765085013, 4.63026594949033, 4.690770499099686, 4.7560105478226715, 4.826492229568882, 4.902721678247914, 4.985205027769361, 5.074438824115661, 5.170627306404837, 5.273425526209551, 5.380277288058394, 5.48732369700426, 5.591422520066704, 5.695554823335832, 5.805533379372331, 5.914415021736495, 5.995521955310318, 6.037146453522155, 6.064290523529052], "y_coordinates": [-1.109994173049927, -0.9983594296520254, -0.8906491928318668, -0.7863943103017103, -0.6851256297738164, -0.5863739989604457, -0.48967361912289115, -0.39682029617115, -0.3157954904752217, -0.2534939313445705, -0.20985761682764428, -0.18161972169954624, -0.16477391116823534, -0.15531229128402133, -0.1492269680972138, -0.14251004765812242, -0.13115363601705687, -0.11132080851797826, -0.08398794861758838, -0.055491937092969165, -0.03245045973545302, -0.021481202336372494, -0.029201850687060077, -0.06223009057884822, -0.1256467229735662, -0.2140046960155971, -0.3171728767397683, -0.42091197828265836, -0.5175774439946793, -0.6144693971436858, -0.7114221684072616, -0.8073450337039924, -0.9011472689524626, -0.991738150071258, -1.0780269529789634, -1.1589229535941639, -1.233335427835445, -1.3001736516213915, -1.3582780162200583, -1.4043888285038066, -1.4333411070972117, -1.4453452995566487, -1.443886936691491, -1.4325529886425226, -1.415415940244886, -1.3966235393846211, -1.3703414630248267, -1.315316593579789, -1.222072925919544, -1.1099941730499268]}}, {"topic_id": "bt-3", "name": " Continual Learning with Lens", "lemma_name": null, "term_id": ["lens", "Continual Learning", "training data", "sparsity", "tilting", "rating", "Decision", "tasks", "Forests", "Tasks", "modelling", "Workloads", "Architectures", "ticket", "Meta Learning", "class", "datasets", "Classifiers", "classifiers", "output", "task", "Imbalance", "output layer", "attribute", "Ensembles", "Campaigns", "Intersection", "Rates", "differentiation", "Diseases", "Lie", "events", "game", "variables", "loop", "compression", "mining", "Matrices", "itemsets", "acceleration", "Adaptation", "MLIR", "sampling", "Probability", "search", "Price", "symmetry", "reliability", "presence", "Nets", "domain", "stage", "training", "framework", "monitoring", "Losses", "Testing", "Tree", "interaction", "Labels", "research", "environment", "fusion", "pattern", "terms", "power", "Training", "algorithms", "Theory", "Rules", "Power", "channel", "approximation", "Rank", "Insights", "t", "Predictions", "Experts", "cost", "sequence", "environments", "Stochastic", "Sets", "analysis", "simulation", "fields", "Strategies", "Compression", "Values", "processes", "End", "View", "functions", "design", "dynamics", "application", "features", "control", "scale", "data", "approach", "system", "process", "label", "Datasets", "Analysis", "regression", "layer", "applications", "loss", "Inference", "methods", "Modeling", "feature", "Study", "modeling", "Machine Learning", "problems", "Guarantees", "Neural Networks", "Application", "inference", "Performance", "Structure", "model", "Classification", "machine learning", "Problems", "learning", "models"], "x_centroid": 8.127595201686576, "y_centroid": 1.944818678829405, "size": 216, "top_doc_id": null, "top_doc_content": ["Understanding new tasks through the lens of training data via\n  exponential tilting", "Understanding new tasks through the lens of training data via exponential tilting", "Whole MILC: generalizing learned dynamics across tasks, datasets, and\n  populations", "Binary output layer of feedforward neural networks for solving\n  multi-class classification problems", "One ticket to win them all: generalizing lottery ticket initializations\n  across datasets and optimizers", "Prototype-based classifiers in the presence of concept drift: A\n  modelling framework", "A novel approach to rating transition modelling via Machine Learning and SDEs on Lie groups", "Exploiting random projections and sparsity with random forests and\n  gradient boosting methods -- Application to multi-label and multi-output\n  learning, random forest model compression and leveraging input sparsity", "Constraint-based Sequential Pattern Mining with Decision Diagrams", "Meta-Learning via Learned Loss", "Predict then Interpolate: A Simple Algorithm to Learn Stable Classifiers", "Probability-driven scoring functions in combining linear classifiers", "Discovering Generalizable Skills via Automated Generation of Diverse\n  Tasks", "Tsunami: A Learned Multi-dimensional Index for Correlated Data and\n  Skewed Workloads", "Continual Learning via Inter-Task Synaptic Mapping", "Fault Detection of Broken Rotor Bar in LS-PMSM Using Random Forests", "Understanding Square Loss in Training Overparametrized Neural Network\n  Classifiers", "Learning where to learn: Gradient sparsity in meta and continual\n  learning", "Adaptive Learning of Aggregate Analytics under Dynamic Workloads", "Continual Learning in Neural Networks", "Decision Making Problems with Funnel Structure: A Multi-Task Learning\n  Approach with Application to Email Marketing Campaigns", "Non-uniform Feature Sampling for Decision Tree Ensembles", "On the Importance of Adaptive Data Collection for Extremely Imbalanced\n  Pairwise Tasks", "MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and\n  Architectures", "Random Similarity Forests", "Feature Selection Methods for Cost-Constrained Classification in Random\n  Forests", "Controllable Dynamic Multi-Task Architectures", "A scalable stage-wise approach to large-margin multi-class loss based\n  boosting", "Decision Tree-Based Predictive Models for Academic Achievement Using\n  College Students' Support Networks", "Meta Learning as Bayes Risk Minimization", "Insights into Pre-training via Simpler Synthetic Tasks", "An Elo-based rating system for TopCoder SRM", "RandomBoost: Simplified Multi-class Boosting through Randomization", "Decision Machines: Interpreting Decision Tree as a Model Combination\n  Method", "Fast Training of Effective Multi-class Boosting Using Coordinate Descent\n  Optimization"], "top_term_id": null, "convex_hull": {"x_coordinates": [7.7327704429626465, 7.847791765809184, 7.963463505246596, 8.078791039255742, 8.192779745817496, 8.304435002912706, 8.41276218852224, 8.516766680626958, 8.615512813654812, 8.711671818369988, 8.807616387182069, 8.899888136176692, 8.984764168986391, 9.058669272551187, 9.119573205357321, 9.166366381801657, 9.197194799305516, 9.207674832344896, 9.192942497034304, 9.151891315131868, 9.089780435526134, 9.011373578588916, 8.920261504926852, 8.819979770919195, 8.714063932945205, 8.606029926006443, 8.49682302447213, 8.383654369698892, 8.269483646890613, 8.158903477018423, 8.051057141132041, 7.944201591534427, 7.840230905660138, 7.741121597793553, 7.648850182219054, 7.5653931732210244, 7.492710734898597, 7.432601743924604, 7.386773235066455, 7.356931178167185, 7.344089635458407, 7.336749325497483, 7.316595447342208, 7.295107079653386, 7.297345123204831, 7.345798715617905, 7.425977109148715, 7.517077181040656, 7.620455985276982, 7.732770442962645], "y_coordinates": [1.143224954605103, 1.1337886780131208, 1.135205041509806, 1.1469957651216347, 1.168682568875084, 1.1997871727966287, 1.2398312969127454, 1.28833666124991, 1.3447736136921442, 1.4054997894596828, 1.467793758161373, 1.5346577921062283, 1.6093512211323282, 1.6948411185687722, 1.7910371506601486, 1.8960267078674953, 2.007431616256162, 2.1213984683398843, 2.2337627651931204, 2.34010927171636, 2.435702518902754, 2.518449942045942, 2.589066580721623, 2.6483996117107087, 2.6972962117941126, 2.7366011123859666, 2.7668386694295832, 2.786717048085294, 2.7893894174326834, 2.767062889198016, 2.7286751285126747, 2.6849869890024523, 2.634908271973008, 2.5770814202086147, 2.5101488764935467, 2.432753083612077, 2.343797579357093, 2.2447614895852834, 2.138590557364393, 2.0282475314679513, 1.9165283382994762, 1.8032118748007524, 1.686246753854111, 1.5693750492246852, 1.4589874414067423, 1.3611316208396738, 1.27696332372844, 1.209255510035429, 1.1655951181732207, 1.1432249546051028]}}, {"topic_id": "bt-4", "name": " Kernel Ranking Samples", "lemma_name": null, "term_id": ["kernel", "rank", "Samples", "trace", "Lasso", "Lasso Screening", "kernels", "ridge", "ridge regression", "regression", "sparse", "matrix", "multivariate", "convergence", "survey", "dimensions", "Monte Carlo", "priors", "estimation", "Guarantees", "selection", "Estimation", "sample", "CUR", "distributions", "features", "Applications", "Measurements", "approximations", "parameter estimation", "optimization method", "Rate", "Metropolis Hastings", "Decompositions", "gradients", "Kernel", "Sampling", "Pairwise", "dimension reduction", "consistency", "Stage", "Domain", "inversion", "Covariates", "transport", "subspace", "signal", "Penalties", "subspaces", "solution", "speed", "Order", "stochastic gradient", "recovery", "Probability", "Gradient", "applications", "Regression", "Case", "Accurate", "backpropagation", "interaction", "complexity", "Tensor", "error", "spaces", "Estimators", "order", "inference", "Distributions", "stochastic", "Consistency", "approximation", "dimension", "Regularization", "Sets", "equation", "properties", "simulations", "analysis", "shot", "Sensing", "fields", "Values", "way", "identification", "flow", "Optimization", "reduction", "Time", "design", "Information", "gradient", "Convergence", "Analysis", "representation", "performance", "Identification", "Approximation", "Inference", "function", "Uncertainty", "Algorithms", "Study", "problems", "Graphs", "algorithms", "Performance", "Bounds", "parameter", "Structure", "Scale", "machine", "systems", "Survey", "optimization", "Features", "machine learning", "method", "Problems", "framework", "Training", "Models"], "x_centroid": 7.902497017321809, "y_centroid": -0.5089525199529035, "size": 193, "top_doc_id": null, "top_doc_content": ["WONDER: Weighted one-shot distributed ridge regression in high\n  dimensions", "Learning the kernel matrix via predictive low-rank approximations", "Fundamental limits for rank-one matrix estimation with groupwise\n  heteroskedasticity", "Random design analysis of ridge regression", "Efficient and principled score estimation with Nystr\\\"om kernel\n  exponential families", "Robust priors for regularized regression", "A novel multivariate performance optimization method based on sparse\n  coding and hyper-predictor learning", "Flat minima generalize for low-rank matrix recovery", "An error bound for Lasso and Group Lasso in high dimensions", "Soft and subspace robust multivariate rank tests based on entropy\n  regularized optimal transport", "Demystifying Orthogonal Monte Carlo and Beyond", "Efficient Statistics for Sparse Graphical Models from Truncated Samples", "On the consistency of inversion-free parameter estimation for Gaussian\n  random fields", "Feedback-Controlled Sequential Lasso Screening", "Performance portability through machine learning guided kernel selection\n  in SYCL libraries", "Multi-dimensional signal approximation with sparse structured priors\n  using split Bregman iterations", "Guarantees of Total Variation Minimization for Signal Recovery", "Relaxed Leverage Sampling for Low-rank Matrix Completion", "Reconstruction of Markov Random Fields from Samples: Some Easy\n  Observations and Algorithms", "Symmetric and antisymmetric properties of solutions to kernel-based\n  machine learning problems", "Approximate Cross-Validation in High Dimensions with Guarantees", "Semi-Separable Hamiltonian Monte Carlo for Inference in Bayesian\n  Hierarchical Models", "The Symmetry of a Simple Optimization Problem in Lasso Screening", "Rate of convergence for geometric inference based on the empirical\n  Christoffel function", "Matrix Completion from $O(n)$ Samples in Linear Time", "Learning deep kernels for exponential family densities", "Design-unbiased statistical learning in survey sampling", "A generalized linear joint trained framework for semi-supervised\n  learning of sparse features", "A survey of sparse representation: algorithms and applications", "On the speed of uniform convergence in Mercer's theorem", "Beyond GAP screening for Lasso by exploiting new dual cutting\n  half-spaces with supplementary material", "Ad Hoc Microphone Array Calibration: Euclidean Distance Matrix\n  Completion Algorithm and Theoretical Guarantees", "A block-sparse Tensor Train Format for sample-efficient high-dimensional\n  Polynomial Regression", "Linear regression without correspondence", "MKL-RT: Multiple Kernel Learning for Ratio-trace Problems via Convex\n  Optimization", "Conformal predictive distributions with kernels", "Consistency of trace norm minimization"], "top_term_id": null, "convex_hull": {"x_coordinates": [7.650182723999023, 7.568476796958836, 7.49594107843504, 7.432674833040283, 7.37877732538721, 7.334347820088467, 7.299319069870814, 7.2693776040881195, 7.240278858090713, 7.2177011108510545, 7.208677048479256, 7.218709761597753, 7.246988393271547, 7.291073155616043, 7.348524258925755, 7.416901913495201, 7.493766329618902, 7.57667894347698, 7.663634003477586, 7.753694543907404, 7.846085676442549, 7.94003251275914, 8.034760164533298, 8.129493743441136, 8.223292725478252, 8.314160748467778, 8.399686893149786, 8.477459258127393, 8.545170086965319, 8.60292044779195, 8.653227751914397, 8.698715059328999, 8.742005430032084, 8.785721924019988, 8.828803194405923, 8.802296794678108, 8.750538258543417, 8.682571718370538, 8.602184123676857, 8.513162423979761, 8.419293568796633, 8.32436450764486, 8.23216219004183, 8.146146933022155, 8.065824822156866, 7.98807417706197, 7.909725945175906, 7.827611073937118, 7.7393151586537, 7.650182723999024], "y_coordinates": [0.27572205662727356, 0.2548175996592494, 0.20151009632205302, 0.1250759772194882, 0.03479167295535883, -0.06006638586653128, -0.15057204175453634, -0.23676396850426096, -0.32508465028691214, -0.4155491058978184, -0.5072525741320167, -0.5990875376913531, -0.6891095316338884, -0.7751581674757523, -0.8550730564917074, -0.9266938099565158, -0.9878600391449406, -1.036413967492818, -1.0711200702698236, -1.0930202300660856, -1.1035016897918777, -1.1039516923574728, -1.0957574806731447, -1.0803062976491673, -1.0586963154940927, -1.030183036525271, -0.993298469749173, -0.9465729101272011, -0.8886227726912086, -0.8200563896805907, -0.7434802278729271, -0.6615881175861607, -0.5770738891382357, -0.4926313728470963, -0.40996758673094036, -0.3197555198154277, -0.2459446559948641, -0.18726458591728673, -0.1402649558645321, -0.10149541211843706, -0.06750560096083774, -0.034845168673570966, -6.376153847331867e-05, 0.04000017426277205, 0.08501196449129798, 0.13231353296673237, 0.17920491826807833, 0.22298615897434032, 0.2599282504471488, 0.27572205662727356]}}, {"topic_id": "bt-5", "name": " Holistic Security Attacks", "lemma_name": null, "term_id": ["Attacks", "capsule", "Holistic Approach", "malware", "Adversarial Classification", "Examples", "Social Media", "box", "detection", "learning models", "Campaigns", "Obfuscation", "Linear Regression", "Perturbations", "improvement", "feature learning", "Learnability", "Improvements", "Diversity", "Complexity", "SHAP", "examples", "G", "Adversaries", "Perception", "techniques", "network", "Subspaces", "samples", "Efficiency", "survey", "effect", "embeddings", "uncertainty", "Benefits", "fidelity", "Estimators", "device", "System", "Systems", "Environments", "channel", "Test", "Detectors", "Assessment", "behavior", "explanation", "support", "analysis", "Features", "Classifiers", "Techniques", "risk", "CNNs", "processing", "Tracking", "level", "Optimization", "Processing", "reduction", "design", "features", "approach", "Data", "information", "models", "Analysis", "stage", "Uncertainty", "image", "feature", "Methods", "attention", "Application", "GAN", "order", "Approach", "machine", "systems", "Image", "Generation", "images", "Survey", "Classification", "machine learning", "graph", "training", "method", "scale", "Training", "Prediction", "Risk", "Models", "prediction", "time", "learning"], "x_centroid": 7.0248341619232555, "y_centroid": 4.979753408902957, "size": 162, "top_doc_id": null, "top_doc_content": ["Reducing the dilution: An analysis of the information sensitiveness of\n  capsule network with a practical improvement method", "Intrusion detection systems using classical machine learning techniques\n  versus integrated unsupervised feature learning and deep neural network", "Towards interpreting ML-based automated malware detection models: a\n  survey", "Improving Transformation-based Defenses against Adversarial Examples\n  with First-order Perturbations", "Detecting Target-Area Link-Flooding DDoS Attacks using Traffic Analysis\n  and Supervised Learning", "Embedding Java Classes with code2vec: Improvements from Variable\n  Obfuscation", "Vulnerability and Transaction behavior based detection of Malicious\n  Smart Contracts", "Exploiting epistemic uncertainty of the deep learning models to generate\n  adversarial samples", "HAPSSA: Holistic Approach to PDF Malware Detection Using Signal and\n  Statistical Analysis", "Towards Consistency in Adversarial Classification", "RADAMS: Resilient and Adaptive Alert and Attention Management Strategy\n  against Informational Denial-of-Service (IDoS) Attacks", "Adversarial Classification via Distributional Robustness with\n  Wasserstein Ambiguity", "I call BS: Fraud Detection in Crowdfunding Campaigns", "Diversity Regularized Adversarial Learning", "A Framework of Randomized Selection Based Certified Defenses Against\n  Data Poisoning Attacks", "A Characterization of Semi-Supervised Adversarially-Robust PAC\n  Learnability", "Generating Adversarial Inputs Using A Black-box Differential Technique", "Identifying and Analyzing Cryptocurrency Manipulations in Social Media", "Transferable Clean-Label Poisoning Attacks on Deep Neural Nets", "EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial\n  Attacks", "Using dynamic routing to extract intermediate features for developing\n  scalable capsule networks", "MixNN: A design for protecting deep learning models", "Detecting Attacks on IoT Devices using Featureless 1D-CNN", "Hunting the Ethereum Smart Contract: Color-inspired Inspection of\n  Potential Attacks", "Adversarial Transfer Attacks With Unknown Data and Class Overlap", "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks", "To believe or not to believe: Validating explanation fidelity for\n  dynamic malware analysis", "A note on hyperparameters in black-box adversarial examples", "Perception Improvement for Free: Exploring Imperceptible Black-box\n  Adversarial Attacks on Image Classification", "Property Inference Attacks on Convolutional Neural Networks: Influence\n  and Implications of Target Model's Complexity", "Obfuscation via Information Density Estimation", "The Odds are Odd: A Statistical Test for Detecting Adversarial Examples", "Certifying Data-Bias Robustness in Linear Regression", "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box\n  Score-Based Query Attacks", "Empirical effect of graph embeddings on fraud detection/ risk mitigation", "Generative Models for Spear Phishing Posts on Social Media", "Holistic Approach to Measure Sample-level Adversarial Vulnerability and its Utility in Building Trustworthy Systems", "When Explainability Meets Adversarial Learning: Detecting Adversarial\n  Examples using SHAP Signatures"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.741167545318603, 6.863602409001236, 6.988823639966958, 7.115244289475252, 7.24127740878562, 7.365336049157549, 7.485833261850535, 7.601182098124072, 7.70979560923765, 7.810086846450762, 7.9004688610229055, 7.979354704213568, 8.045158201694527, 8.096656466627213, 8.133567990610075, 8.155761746759884, 8.163106708193396, 8.155471848027378, 8.132726139378597, 8.094738555363811, 8.041378069099789, 7.972513653703291, 7.888238036975041, 7.791002593340269, 7.684672648081862, 7.573132691973794, 7.46026721579004, 7.348016646460572, 7.22703538791382, 7.098939538903828, 6.967956122258937, 6.838312160807491, 6.714234677377826, 6.599950694798285, 6.49968723589721, 6.4176713235029395, 6.358129980443815, 6.324649989933384, 6.3140395629039405, 6.319029674781596, 6.332295489578934, 6.346512171308537, 6.35541158725688, 6.36408014204158, 6.3845104005271684, 6.422018006227482, 6.467439757173694, 6.531428415196791, 6.625661012065761, 6.741167545318603], "y_coordinates": [4.107577800750733, 4.093312814820237, 4.080418632623211, 4.070350142152096, 4.064562231399345, 4.0645097883574, 4.071647701018711, 4.087430857375725, 4.1133141454208895, 4.15075245314665, 4.201200668545455, 4.2661136796097505, 4.346943553849917, 4.443819231709521, 4.553441065184689, 4.671961338486109, 4.79553233582447, 4.92030634141046, 5.04243563945477, 5.158072514168085, 5.263369249761099, 5.354478130444497, 5.4278823967764955, 5.483553971912417, 5.5235561587416315, 5.549980607899433, 5.564918970021111, 5.571279565970209, 5.575384685254312, 5.5766604896409975, 5.573238075069357, 5.563248537478486, 5.544822972807478, 5.516092476995425, 5.475188145981424, 5.420241075704563, 5.349382362103939, 5.261112100453593, 5.157837186865666, 5.044314414514951, 4.925332743243227, 4.805681132892264, 4.689852983067727, 4.579165825733491, 4.473004984331213, 4.367904794152391, 4.260479567043843, 4.172915494806186, 4.1265765632486175, 4.107577800750733]}}, {"topic_id": "bt-6", "name": " COVID-19 Language", "lemma_name": null, "term_id": ["COVID", "Topic", "Language", "Topic Modeling", "Modeling", "Translation", "language", "Symptoms", "Language Modeling", "emotion", "Sentences", "RNNs", "language models", "Answering", "Questions", "Question", "policy", "Transformers", "Attention", "Models", "Signals", "Text", "Sequence", "Factors", "Impact", "output layer", "Research", "Modelling", "Ontology", "Decision Making", "Lie", "Pairwise", "evolution", "circuit", "mining", "Matrices", "integration", "Adaptation", "cough", "Parsing", "supervision", "stock", "Words", "state", "stream", "sequence models", "product", "domain", "Tuning", "Embeddings", "End", "testing", "Graph", "Case", "backpropagation", "multivariate", "E", "measure", "research", "Efficiency", "Web", "Social Media", "feedback", "Learning", "Overview", "alignment", "outcomes", "Prediction", "term", "Assessment", "t", "layers", "Experts", "sequence", "Process", "predictions", "representations", "Making", "analysis", "Generation", "correlation", "shot", "Interpretability", "Classifiers", "Techniques", "Priors", "source", "policies", "text", "way", "optimization", "quantum", "Processing", "output", "EEG", "Tasks", "matrix", "Representations", "layer", "Approximation", "study", "prediction", "models", "Study", "Methods", "view", "Deep Learning", "Guarantees", "Performance", "Decision", "model", "Scale", "Survey", "Classification", "framework", "scale", "approach"], "x_centroid": 5.026179060825082, "y_centroid": 4.816056179445844, "size": 215, "top_doc_id": null, "top_doc_content": ["Masked Language Modeling for Proteins via Linearly Scalable Long-Context\n  Transformers", "Language Modeling with Sparse Product of Sememe Experts", "Semi-supervised NMF Models for Topic Modeling in Learning Tasks", "A Practical Algorithm for Topic Modeling with Provable Guarantees", "Topic Modeling of Behavioral Modes Using Sensor Data", "Training language models to follow instructions with human feedback", "India nudges to contain COVID-19 pandemic: a reactive public policy\n  analysis using machine-learning based topic modelling", "Teaching language models to support answers with verified quotes", "Causal Modeling of Twitter Activity During COVID-19", "Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space", "Language Models with Transformers", "Neural language representations predict outcomes of scientific research", "Pay Attention to the cough: Early Diagnosis of COVID-19 using\n  Interpretable Symptoms Embeddings with Cough Sound Signal Processing", "Visualizing Attention in Transformer-Based Language Representation\n  Models", "Estimating COVID-19 cases and outbreaks on-stream through phone-calls", "Attention Interpretability Across NLP Tasks", "On the Practical Computational Power of Finite Precision RNNs for\n  Language Recognition", "E-LANG: Energy-Based Joint Inferencing of Super and Swift Language\n  Models", "AxFormer: Accuracy-driven Approximation of Transformers for Faster,\n  Smaller and more Accurate NLP Models", "Contrastive Learning for Many-to-many Multilingual Neural Machine\n  Translation", "Comparative study of variational quantum circuit and quantum\n  backpropagation multilayer perceptron for COVID-19 outbreak predictions", "Sequence-Level Training for Non-Autoregressive Neural Machine\n  Translation", "Explainable and Discourse Topic-aware Neural Language Understanding", "Topic Modelling on Consumer Financial Protection Bureau Data: An\n  Approach Using BERT Based Embeddings", "Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine\n  Translation", "Understanding Transformers for Bot Detection in Twitter", "Asking Questions the Human Way: Scalable Question-Answer Generation from\n  Text Corpus", "Attention-based Neural Bag-of-Features Learning for Sequence Data", "Assessing COVID-19 Impacts on College Students via Automated Processing\n  of Free-form Text", "ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine\n  Translation", "Open-Domain Conversational Search Assistant with Transformers", "Language in Our Time: An Empirical Analysis of Hashtags", "A Scalable Asynchronous Distributed Algorithm for Topic Modeling", "Question Answering Survey: Directions, Challenges, Datasets, Evaluation\n  Matrices", "A framework for optimizing COVID-19 testing policy using a Multi Armed\n  Bandit approach", "Language Transfer for Early Warning of Epidemics from Social Media", "Hyperparameters optimization for Deep Learning based emotion prediction\n  for Human Robot Interaction", "Can Transformers Jump Around Right in Natural Language? Assessing\n  Performance Transfer from SCAN", "DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence\n  Modeling", "Models In a Spelling Bee: Language Models Implicitly Learn the Character\n  Composition of Tokens", "Research on the correlation between text emotion mining and stock market based on deep learning", "Interleaved Sequence RNNs for Fraud Detection", "Unsupervised Paraphrasing without Translation", "Cross-referencing using Fine-grained Topic Modeling", "Language as a matrix product state", "PocketCare: Tracking the Flu with Mobile Phones using Partial\n  Observations of Proximity and Symptoms", "Selection-based Question Answering of an MOOC", "Robust Cross-lingual Embeddings from Parallel Sentences", "Using Bayesian Optimization to Accelerate Virtual Screening for the\n  Discovery of Therapeutics Appropriate for Repurposing for COVID-19", "Open Domain Question Answering Using Web Tables", "Probit Normal Correlated Topic Models", "Towards better decoding and language model integration in sequence to\n  sequence models", "Keyword-based Topic Modeling and Keyword Selection", "VQS: Linking Segmentations to Questions and Answers for Supervised\n  Attention in VQA and Question-Focused Semantic Segmentation", "Using a Novel COVID-19 Calculator to Measure Positive U.S.\n  Socio-Economic Impact of a COVID-19 Pre-Screening Solution (AI/ML)", "Explaining Question Answering Models through Text Generation"], "top_term_id": null, "convex_hull": {"x_coordinates": [4.340503692626955, 4.405480781607342, 4.476416277547685, 4.554547597483811, 4.641112158451546, 4.737347377486716, 4.844488644276743, 4.959288065516153, 5.069967564613983, 5.175645250754494, 5.277505567090863, 5.376732956776265, 5.474438961584367, 5.5712714385053195, 5.66723238044617, 5.758622247264487, 5.839970522277114, 5.905795630104145, 5.950615995365667, 5.968950042681777, 5.957365791375427, 5.920935160118195, 5.866935247542467, 5.8026431561372505, 5.735335988391554, 5.672290846794385, 5.615254042097846, 5.5450059324171, 5.457927527340203, 5.357724695575724, 5.248106569640002, 5.132782282049382, 5.015421481525385, 4.897545164505605, 4.780054295510247, 4.665328530297786, 4.555766173960668, 4.453765531591337, 4.361724908282238, 4.2820426091258135, 4.217116939214511, 4.1693462036407745, 4.1411287074970495, 4.134219632440398, 4.140070222494818, 4.155609707272932, 4.185899061547912, 4.228497397613305, 4.280875384847017, 4.340503692626954], "y_coordinates": [4.379000663757325, 4.256347762304595, 4.135058367848821, 4.025925738416659, 3.9397431320347676, 3.8873038067298027, 3.8793953409713122, 3.9142361054085955, 3.9628289382586948, 4.0185109517849105, 4.079166482841183, 4.142679868281453, 4.207712515608672, 4.27786834285282, 4.35808923560279, 4.448547746002253, 4.547132135672934, 4.651716402198837, 4.760174543163971, 4.8703805561523446, 4.980523161224432, 5.090096882099791, 5.198934855638109, 5.3068702192912705, 5.4137361105111586, 5.519365666749657, 5.623686408722499, 5.726109322029219, 5.821293525042693, 5.902338542233772, 5.962343203205621, 5.994406337561408, 5.991887604441839, 5.9623220156089465, 5.917165831539831, 5.858011520828182, 5.786327380345271, 5.703581706962367, 5.611242797550742, 5.510778948981664, 5.403658458126404, 5.291349621856233, 5.175320737042419, 5.057028628572331, 4.937803269105741, 4.822468214581302, 4.712634751089574, 4.604609709994103, 4.494647033486238, 4.379000663757325]}}, {"topic_id": "bt-7", "name": " Reinforcement Learning", "lemma_name": null, "term_id": ["reinforcement", "reinforcement learning", "agent", "Planning", "Reinforcement Learning", "traffic", "Scenarios", "POMDPs", "Interaction", "charging", "robot", "scenarios", "Following", "agent scenarios", "Tracking", "Policy", "control", "Exploration", "Action", "Cloud Robotics", "behaviors", "Environments", "behavior", "MDPs", "simulations", "Making", "learning", "Network", "Strategies", "Sequence", "AI", "model", "battery", "Intersection", "trade", "implementation", "Line", "Decision Making", "Learn", "game", "Efficient Learning", "Connections", "State", "controllers", "inversion", "Diversity", "Contraction", "G", "Flexibility", "size", "Perception", "UAV", "RL", "Scale", "system", "Problems", "Recommendations", "modal", "dataset", "interaction", "E", "Transfer", "Efficiency", "Vehicles", "plasticity", "Buildings", "environment", "Validation", "outcomes", "temperature", "Error", "End", "Meta Learning", "Distribution", "architecture", "Insights", "Process", "evaluation", "Decision", "simulation", "Recommendation", "Compression", "processing", "policies", "Manipulation", "time", "Survey", "Training", "Reasoning", "Time", "knowledge", "energy", "Tasks", "Experiments", "Approach", "language", "Tuning", "performance", "Identification", "graphs", "resolution", "Data", "Risk", "Modeling", "models", "Machine Learning", "Deep Learning", "problems", "Application", "Generation", "optimization", "training"], "x_centroid": 10.309520691106682, "y_centroid": 2.21896738003505, "size": 283, "top_doc_id": null, "top_doc_content": ["Data-driven control of room temperature and bidirectional EV charging\n  using deep reinforcement learning: simulations and experiments", "Exploration-exploitation trade-off for continuous-time episodic\n  reinforcement learning with linear-convex models", "Towards on-sky adaptive optics control using reinforcement learning", "Approximating a deep reinforcement learning docking agent using linear\n  model trees", "Distributed interference cancellation in multi-agent scenarios", "Definition and evaluation of model-free coordination of electrical\n  vehicle charging with reinforcement learning", "ScheduleNet: Learn to solve multi-agent scheduling problems with\n  reinforcement learning", "Estimating counterfactual treatment outcomes over time in complex\n  multi-agent scenarios", "Optimizing a domestic battery and solar photovoltaic system with deep\n  reinforcement learning", "Time manipulation technique for speeding up reinforcement learning in\n  simulations", "Automating the resolution of flight conflicts: Deep reinforcement\n  learning in service of air traffic controllers", "Boosted Genetic Algorithm using Machine Learning for traffic control\n  optimization", "A dual mode adaptive basal-bolus advisor based on reinforcement learning", "Survey on reinforcement learning for language processing", "Interaction-aware Decision Making with Adaptive Strategies under Merging\n  Scenarios", "Neurosymbolic Reinforcement Learning with Formally Verified Exploration", "LBGP: Learning Based Goal Planning for Autonomous Following in Front", "A Novel Sample-efficient Deep Reinforcement Learning with Episodic\n  Policy Transfer for PID-Based Control in Cardiac Catheterization Robots", "Policy Manifold Search: Exploring the Manifold Hypothesis for\n  Diversity-based Neuroevolution", "Reward Shaping with Recurrent Neural Networks for Speeding up On-Line\n  Policy Learning in Spoken Dialogue Systems", "Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable\n  Optimal Action-Value Functions", "Reinforcement Learning-based Placement of Charging Stations in Urban Road Networks", "QVMix and QVMix-Max: Extending the Deep Quality-Value Family of\n  Algorithms to Cooperative Multi-Agent Reinforcement Learning", "Mitigation of Adversarial Policy Imitation via Constrained Randomization\n  of Policy (CRoP)", "Tracking and Planning with Spatial World Models", "Learning Portable Representations for High-Level Planning", "Learning to Accelerate by the Methods of Step-size Planning", "Voronoi Progressive Widening: Efficient Online Solvers for Continuous\n  State, Action, and Observation POMDPs", "Safer Autonomous Driving in a Stochastic, Partially-Observable\n  Environment by Hierarchical Contingency Planning", "Investigating the impact of free energy based behavior on human in\n  human-agent interaction", "Network Offloading Policies for Cloud Robotics: a Learning-based\n  Approach", "Offline Decentralized Multi-Agent Reinforcement Learning", "A model for traffic incident prediction using emergency braking data", "Visual Learning-based Planning for Continuous High-Dimensional POMDPs", "Action-Sufficient State Representation Learning for Control with\n  Structural Constraints", "Towards biologically plausible Dreaming and Planning", "Robot_gym: accelerated robot training through simulation in the cloud\n  with ROS and Gazebo", "Locality Matters: A Scalable Value Decomposition Approach for\n  Cooperative Multi-Agent Reinforcement Learning", "Learning Reinforced Attentional Representation for End-to-End Visual\n  Tracking", "How to reduce computation time while sparing performance during robot\n  navigation? A neuro-inspired architecture for autonomous shifting between\n  model-based and model-free learning", "Multi-agent Databases via Independent Learning", "Interaction and Conflict Management in AI-assisted Operational Control\n  Loops in 6G", "Reinforcement Learning using Guided Observability", "Deep Interactive Reinforcement Learning for Path Following of Autonomous\n  Underwater Vehicle", "GMOT-40: A Benchmark for Generic Multiple Object Tracking", "INTERACTION Dataset: An INTERnational, Adversarial and Cooperative\n  moTION Dataset in Interactive Driving Scenarios with Semantic Maps", "Distributed Multi-agent Meta Learning for Trajectory Design in Wireless\n  Drone Networks"], "top_term_id": null, "convex_hull": {"x_coordinates": [10.73548126220703, 10.826744761160509, 10.905023505253073, 10.970484240661449, 11.023293713562348, 11.063618665353129, 11.091577228032838, 11.107119303973791, 11.110158427355103, 11.100608132355893, 11.078381953155281, 11.043393423932388, 10.995556078866336, 10.934783452136243, 10.860989077921229, 10.774087069836687, 10.675025715801452, 10.567919757746475, 10.457477617969168, 10.34674901602128, 10.235385302424783, 10.122634872872746, 10.008694968917553, 9.897550957204684, 9.793581916564621, 9.698008670230918, 9.610929765804707, 9.532442405495456, 9.462643791512633, 9.401631126065714, 9.349501611364156, 9.306401684363278, 9.274519661022474, 9.258772776345296, 9.26426854173231, 9.29611446858407, 9.358455090187402, 9.442785987275329, 9.538906824270397, 9.643535615445092, 9.75366042103908, 9.866269301292034, 9.978350316443619, 10.08753653094518, 10.194677893272589, 10.301625239017538, 10.410229723132007, 10.521666525350888, 10.632107951008475, 10.73548126220703], "y_coordinates": [1.3937608003616333, 1.4271951558211213, 1.4992498231064804, 1.6002623305603068, 1.7205702065251935, 1.850511133254005, 1.981988167106353, 2.112321882676547, 2.2400040237135466, 2.3635263339663117, 2.481380557183803, 2.5920584371149813, 2.6940517175088066, 2.7858521421142393, 2.86595145468024, 2.932841618401315, 2.985406261535444, 3.023728219676861, 3.048188906481951, 3.0647442713929878, 3.0774755679012564, 3.086365372094007, 3.0898559393169798, 3.0802407473443396, 3.0496534810468963, 2.9980987866428364, 2.9283782303122337, 2.843296731201847, 2.7456592084584384, 2.6382705812287695, 2.5239357686596, 2.4054641660888794, 2.2858508068760877, 2.1683388248466233, 2.0561886528596744, 1.9526607237744282, 1.861140436838012, 1.7864549415031283, 1.7296166760604288, 1.6869934054410993, 1.6547758191735202, 1.629154606786073, 1.6063204578071373, 1.5827216116731517, 1.5560908082466929, 1.5245604411910234, 1.4862630316898366, 1.441233649094885, 1.4035880705785462, 1.3937608003616333]}}, {"topic_id": "bt-8", "name": " Federated Learning and Privacy", "lemma_name": null, "term_id": ["Federated Learning", "Privacy", "Clients", "attribute", "Obfuscation", "Shot", "Node Classification", "Approximations", "Parsing", "Healthcare", "accuracy", "project", "UAV", "Study", "Devices", "outcomes", "sources", "Bit", "Distributions", "Consistency", "Directions", "Rank", "Experts", "cost", "environments", "shot", "Sensing", "Compression", "Evaluation", "Optimality", "Data", "Information", "information", "Datasets", "Embeddings", "Machine Learning", "Attacks", "images", "Features", "approach", "Models", "Applications", "data", "networks", "Approach", "Training", "Networks", "learning"], "x_centroid": 8.981812784990927, "y_centroid": 5.326373209164837, "size": 127, "top_doc_id": null, "top_doc_content": ["Obfuscation for Privacy-preserving Syntactic Parsing", "Privacy is What We Care About: Experimental Investigation of Federated\n  Learning on Edge Devices", "Federated Learning from Only Unlabeled Data with\n  Class-Conditional-Sharing Clients", "Privacy Preserving Gaze Estimation using Synthetic Images via a\n  Randomized Encoding Based Framework", "Budgeted Online Selection of Candidate IoT Clients to Participate in\n  Federated Learning", "UAV-assisted Online Machine Learning over Multi-Tiered Networks: A\n  Hierarchical Nested Personalized Federated Learning Approach", "Estimating Sparse Discrete Distributions Under Local Privacy and\n  Communication Constraints", "European Court of Human Right Open Data project", "PrivacyNet: Semi-Adversarial Networks for Multi-attribute Face Privacy", "FRAug: Tackling Federated Learning with Non-IID Features via\n  Representation Augmentation", "Noninteractive Locally Private Learning of Linear Models via Polynomial\n  Approximations", "Optimising cost vs accuracy of decentralised analytics in fog computing\n  environments", "Sharing Models or Coresets: A Study based on Membership Inference Attack", "FedVision: An Online Visual Object Detection Platform Powered by\n  Federated Learning", "Locally Differentially Private Frequency Estimation with Consistency", "Two-Bit Aggregation for Communication Efficient and Differentially\n  Private Federated Learning", "Using adversarial images to improve outcomes of federated learning for non-IID data", "LPGNet: Link Private Graph Networks for Node Classification", "MFNets: Data efficient all-at-once learning of multifidelity surrogates\n  as directed networks of information sources", "Federated Data Analytics: A Study on Linear Models", "Practical One-Shot Federated Learning for Cross-Silo Setting", "Federated Learning from Small Datasets", "Privacy-Preserving Machine Learning: Methods, Challenges and Directions", "Comparison of Privacy-Preserving Distributed Deep Learning Methods in\n  Healthcare", "Communication-Efficient ADMM-based Federated Learning"], "top_term_id": null, "convex_hull": {"x_coordinates": [8.005367279052736, 8.013474077139806, 8.029067926711356, 8.053232079815698, 8.087049788501142, 8.131604304816003, 8.187978880808593, 8.25725676852722, 8.34033583616072, 8.431333531320908, 8.518812638680316, 8.601715988843155, 8.68146253693228, 8.759471238070558, 8.837161047380851, 8.915950919986022, 8.997259811008936, 9.082506675572455, 9.173110468799443, 9.27049014581276, 9.376064661735276, 9.490511995319258, 9.600728391208321, 9.681428108406216, 9.706909494641344, 9.669661586589752, 9.62015805365123, 9.577387280648791, 9.527305927244917, 9.468383176747976, 9.40167249397455, 9.328227343741231, 9.249101190864613, 9.165347500161275, 9.078019736447816, 8.988171364540818, 8.896855849256875, 8.805126655412574, 8.714037247824503, 8.624641091309254, 8.538112893356432, 8.456149520137046, 8.37770649576031, 8.300650530454574, 8.222982096247328, 8.143023741930232, 8.068411647179063, 8.023068809822487, 8.005637652987298, 8.005367279052736], "y_coordinates": [5.197000980377198, 5.090794922696939, 4.984087560150257, 4.881295754736531, 4.786836368455142, 4.705126263305475, 4.640582301286909, 4.597621344398825, 4.580407010887764, 4.583840489089655, 4.594249553614614, 4.6085687730572715, 4.626305764092554, 4.646968143395396, 4.670063527640731, 4.695099533503493, 4.721583777658614, 4.749023876781028, 4.776927447545669, 4.804802106627466, 4.832155470701359, 4.858720657696906, 4.888424979118296, 4.928903088774687, 4.987916109432031, 5.067155420531382, 5.148945085718452, 5.2257745798873, 5.301012099995827, 5.374287114705456, 5.44445075729654, 5.510354161049433, 5.570848459244488, 5.624784785162055, 5.67101427208249, 5.708388053286144, 5.735757262053368, 5.751973031664515, 5.75588649539994, 5.7463487865399925, 5.7224131497133754, 5.685609743276795, 5.641195910283203, 5.595268830783557, 5.551388404522009, 5.507685356344946, 5.457382710104705, 5.3869636571910515, 5.2978791116979185, 5.197000980377197]}}, {"topic_id": "bt-9", "name": " Machine Learning", "lemma_name": null, "term_id": ["Transformers", "autoencoders", "process", "bounds", "uncertainties", "Gaussian\n ", "Nonparametric", "process regression", "Gaussian Processes", "retrosynthesis", "processes", "point", "distributions", "Autoencoders", "encoders", "ODEs", "Inference", "distance", "correlation", "case", "reduction", "functions", "output", "energy", "inference", "Measurements", "tissue", "package", "CUR O", "CRFs", "Estimates", "auto", "Change", "particle", "heterogeneity", "DeepONets", "Derivatives", "variables", "transform", "Context", "Neural Network", "machines", "trajectories", "Contraction", "transport", "stability", "similarity", "size", "Technique", "Hardware", "Prospects", "Video", "sensor", "length", "O CUR", "O", "regression", "Regression", "latent", "decision", "Gradients", "Mapping", "software", "Constraints", "mapping", "case study", "Encoders", "samples", "P", "reconstruction", "hardware", "activation", "end", "plasticity", "parameters", "dimensions", "Tensor", "Gap", "e", "Benefits", "Multi", "Dimensions", "imaging data", "fidelity", "Error", "Application", "models", "Signals", "order", "Data", "Models", "Monte Carlo", "regularization", "Systems", "Samples", "Trees", "Test", "architecture", "Rank", "probability", "Insights", "t", "discovery", "measures", "satellite", "sequence", "environments", "Processes", "representations", "support", "prediction", "Bounds", "Structure", "datasets", "series", "self", "Generalization", "risk", "Sequence", "imaging", "Optimality", "time series", "data", "systems", "time", "Optimization", "structure", "Flows", "equations", "gradient", "Experiments", "training", "network", "space", "physics", "Convergence", "box", "CUR", "graphs", "study", "resolution", "function", "Uncertainty", "methods", "Applications", "modeling", "classification", "Neural Networks", "reinforcement learning", "Training", "parameter", "task", "reinforcement", "Classification"], "x_centroid": 6.791178313545559, "y_centroid": 0.40692973426421697, "size": 230, "top_doc_id": null, "top_doc_content": ["Context-dependent self-exciting point processes: models, methods, and\n  risk bounds in high dimensions", "Data-driven discovery of interacting particle systems using Gaussian\n  processes", "On the inability of Gaussian process regression to optimally learn compositional functions", "Probabilistic Riemannian submanifold learning with wrapped Gaussian\n  process latent variable models", "Global inducing point variational posteriors for Bayesian neural\n  networks and deep Gaussian processes", "Local distance preserving auto-encoders using Continuous k-Nearest\n  Neighbours graphs", "Convergence of Gaussian-smoothed optimal transport distance with\n  sub-gamma distributions and dependent samples", "Data-driven determination of the spin Hamiltonian parameters and their\n  uncertainties: The case of the zigzag-chain compound KCu$_4$P$_3$O$_{12}$", "Functional Mixture Discriminant Analysis with hidden process regression\n  for curve classification", "Predicting distributions with Linearizing Belief Networks", "Scheduled denoising autoencoders", "Inference with Hybrid Bio-hardware Neural Networks", "Multi-resolution Multi-task Gaussian Processes", "Insights on representational similarity in neural networks with\n  canonical correlation", "The energy distance for ensemble and scenario reduction", "Variational autoencoders for tissue heterogeneity exploration from\n  (almost) no preprocessed mass spectrometry imaging data", "Learning Interacting Dynamical Systems with Latent Gaussian Process ODEs", "Gating Dropout: Communication-efficient Regularization for Sparsely Activated Transformers", "Nonparametric likelihood-free inference with Jensen-Shannon divergence\n  for simulator-based models with categorical output", "Chasing Collective Variables using Autoencoders and biased trajectories", "Energon: Towards Efficient Acceleration of Transformers Using Dynamic\n  Sparse Attention", "Addressing Some Limitations of Transformers with Feedback Memory", "Nonparametric Modeling of Higher-Order Interactions via Hypergraphons", "On denoising autoencoders trained to minimise binary cross-entropy", "Bounds all around: training energy-based models with bidirectional\n  bounds", "Data Association with Gaussian Processes", "SemiRetro: Semi-template framework boosts deep retrosynthesis prediction", "A Bayesian algorithm for retrosynthesis", "A scalable end-to-end Gaussian process adapter for irregularly sampled\n  time series classification", "Gating Dropout: Communication-efficient Regularization for Sparsely\n  Activated Transformers", "Nonparametric Variational Auto-encoders for Hierarchical Representation\n  Learning", "Hierarchical correlation reconstruction with missing data, for example\n  for biology-inspired neuron", "Preserving physically important variables in optimal event selections: A\n  case study in Higgs physics", "Exact marginal prior distributions of finite Bayesian neural networks", "Transformers Can Do Bayesian Inference", "Intrinsic uncertainties and where to find them", "Learning Interacting Dynamical Systems with Latent Gaussian Process ODEs", "Climbing the WOL: Training for Cheaper Inference", "Change-point Detection Methods for Body-Worn Video", "Are Transformers Effective for Time Series Forecasting?", "Autoencoders for strategic decision support", "Sequential Neural Methods for Likelihood-free Inference", "Block-Recurrent Transformers"], "top_term_id": null, "convex_hull": {"x_coordinates": [6.221706867218017, 6.1479654035200895, 6.087622342589805, 6.040720616745516, 6.007303158305567, 5.987412899588306, 5.981092772912083, 5.988385710595243, 6.008632377682368, 6.037895664403935, 6.071282925239855, 6.10390140322964, 6.133351309302551, 6.182273954288237, 6.274785396319074, 6.3781119506703625, 6.485476563164382, 6.594212589381534, 6.6996329248678945, 6.801711656350912, 6.903994683217467, 7.004476563346834, 7.100916216948487, 7.191706555997823, 7.276693540665145, 7.355925851366651, 7.429452168518537, 7.4973211725369895, 7.559580617038011, 7.6075554968435, 7.6284029887595795, 7.630150807975036, 7.621831640583595, 7.610041631790851, 7.596277654340946, 7.581395990470942, 7.5607383741042815, 7.474028819669722, 7.3675969107385555, 7.260495701973581, 7.152847864649745, 7.044949947931742, 6.937098500984269, 6.829590072972016, 6.7226595875577155, 6.615354176793237, 6.508371876686665, 6.404914306091995, 6.308266551158051, 6.221706867218019], "y_coordinates": [0.9879640936851499, 0.9079615108361949, 0.8153816367326298, 0.7132950624768486, 0.6047723791712452, 0.4928841779182132, 0.3807010498201467, 0.27129358597943926, 0.16683880827340022, 0.06534307762154208, -0.03640307465893407, -0.1416092590482607, -0.2512993675526404, -0.3445424186767806, -0.397503444021888, -0.42768856541628075, -0.4314998961038845, -0.4142215414287618, -0.3843305304445107, -0.35063107790367637, -0.3160103176171582, -0.27697513753973285, -0.22982071476683413, -0.17228346741727832, -0.10540299951860801, -0.03067975504983169, 0.05038582201004237, 0.13629328768200516, 0.22554264376743366, 0.32081983746705417, 0.42663222292163816, 0.5372841282226277, 0.6466031519043423, 0.751600979771744, 0.8559530596102265, 0.9641719669912204, 1.0755952433911924, 1.1291248050897487, 1.139387674535911, 1.1502432493657133, 1.160838578861714, 1.1692851546318634, 1.1736944682841124, 1.1721780114264095, 1.1630434435613501, 1.1485520293253344, 1.128785232155315, 1.0985029553492092, 1.0523331970764807, 0.9879640936851503]}}]