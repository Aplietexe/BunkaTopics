{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad612386-af6e-4c11-ae54-23ced1a7c80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from bunkatopics import Bunka\n",
    "from bunkatopics.functions.clean_text import clean_tweet\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b62615c-2118-4d0b-9bb3-3fc69e03efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rguo123/trump_tweets\")[\"train\"]\n",
    "full_docs = dataset[\"content\"]\n",
    "full_docs = [clean_tweet(x) for x in full_docs]\n",
    "full_docs = [x for x in full_docs if len(x)>50]\n",
    "full_docs = random.sample(full_docs, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbabce8-1550-4b77-b17d-8f0bbb7269ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc48905-382e-4a92-a600-13cc6321b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO      \u001b[0m|\u001b[33m2023-10-20 11:15:48\u001b[0m|\u001b[35m{}\u001b[0m|\u001b[34mfit\u001b[0m|\u001b[1mExtracting Terms\u001b[0m\n",
      "/Users/charlesdedampierre/Desktop/bunka_related_projects/BunkaTopics/.venv/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "100%|███████████████████████████████████████████████████████████████| 500/500 [00:03<00:00, 155.84it/s]\n",
      "\u001b[1mINFO      \u001b[0m|\u001b[33m2023-10-20 11:15:51\u001b[0m|\u001b[35m{}\u001b[0m|\u001b[34mfit\u001b[0m|\u001b[1mEmbedding Documents, this may take few minutes\u001b[0m\n",
      "\u001b[1mINFO      \u001b[0m|\u001b[33m2023-10-20 11:15:53\u001b[0m|\u001b[35m{}\u001b[0m|\u001b[34mfit\u001b[0m|\u001b[1mReducing Dimensions\u001b[0m\n",
      "/Users/charlesdedampierre/Desktop/bunka_related_projects/BunkaTopics/.venv/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "bunka = Bunka(embedding_model=embedding_model)\n",
    "bunka.fit(full_docs)\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "open_ai_generative_model = OpenAI(openai_api_key = os.getenv('OPEN_AI_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239d3f5-5f53-40ee-a9f0-e2f0f71f07d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9a79da-58eb-47b5-9082-6239d2976083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating new labels for clusters: 100%|████████████████████████████████| 10/10 [00:05<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import typing as t \n",
    "from bunkatopics.functions.bourdieu_api import bourdieu_api\n",
    "from bunkatopics.datamodel import TopicParam, TopicGenParam\n",
    "\n",
    "\n",
    "class BourdieuQuery(BaseModel):\n",
    "    x_left_words: t.List[str] = [\"war\"]\n",
    "    x_right_words: t.List[str] = [\"peace\"]\n",
    "    y_top_words: t.List[str] = [\"men\"]\n",
    "    y_bottom_words: t.List[str] = [\"women\"]\n",
    "    radius_size: float = 0.5\n",
    "\n",
    "res = bourdieu_api(\n",
    "            bunka.embedding_model,\n",
    "            bunka.docs,\n",
    "            bunka.terms,\n",
    "            bourdieu_query = BourdieuQuery(),\n",
    "            topic_param = TopicParam(n_clusters = 10),\n",
    "            generative_ai_name=True,\n",
    "            topic_gen_param= TopicGenParam(generative_model = open_ai_generative_model))\n",
    "\n",
    "bourdieu_docs = res[0]\n",
    "bourdieu_topics = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d61c0d-ac28-4d64-a3ae-9a6413eb5998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df2b375-a4b6-4cb9-8f28-9591487620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file_path = \"bourdieu_docs.json\"\n",
    "bourdieu_docs_json = [x.dict() for x in bourdieu_docs]\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(bourdieu_docs_json, json_file)\n",
    "\n",
    "   \n",
    "file_path = \"bourdieu_topics.json\"\n",
    "bourdieu_topics_json = [x.dict() for x in bourdieu_topics]\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(bourdieu_topics_json, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225adc62-bb1b-4e2f-a361-c24bc21f5556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
